{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n"
      ],
      "id": "union-alcohol"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ],
      "id": "floppy-teens"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ],
      "id": "engaged-modem"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ],
      "id": "structured-april"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ],
      "id": "cutting-fountain"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ],
      "id": "entertaining-therapist"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrWFE0qJ46uP",
        "outputId": "db84a24f-ea96-4fe3-ee3e-6f084b2e18d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "nrWFE0qJ46uP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "id": "differential-native"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ],
      "id": "other-married"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ],
      "id": "mexican-newsletter"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "\n",
        "filepath = \"/content/drive/MyDrive/Data folder/pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ],
      "id": "studied-twelve"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ],
      "id": "photographic-carnival"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "undefined-inventory",
        "outputId": "52c767d2-7606-4302-8679-975d0c72621a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "275               2                     100              70              52   \n",
              "367               0                     101              64              17   \n",
              "550               1                     116              70              28   \n",
              "711               5                     126              78              27   \n",
              "407               0                     101              62               0   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "275       57  40.5              0.677   25             0  \n",
              "367        0  21.0              0.252   21             0  \n",
              "550        0  27.4              0.204   21             0  \n",
              "711       22  29.6              0.439   40             0  \n",
              "407        0  21.9              0.336   25             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9ce6fe9-4eeb-4b0a-a6d6-a17610035901\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>70</td>\n",
              "      <td>52</td>\n",
              "      <td>57</td>\n",
              "      <td>40.5</td>\n",
              "      <td>0.677</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "      <td>64</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.252</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>1</td>\n",
              "      <td>116</td>\n",
              "      <td>70</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>27.4</td>\n",
              "      <td>0.204</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>5</td>\n",
              "      <td>126</td>\n",
              "      <td>78</td>\n",
              "      <td>27</td>\n",
              "      <td>22</td>\n",
              "      <td>29.6</td>\n",
              "      <td>0.439</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407</th>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21.9</td>\n",
              "      <td>0.336</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9ce6fe9-4eeb-4b0a-a6d6-a17610035901')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e9ce6fe9-4eeb-4b0a-a6d6-a17610035901 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e9ce6fe9-4eeb-4b0a-a6d6-a17610035901');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8611d4d4-ccc3-4332-919d-8a384453209e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8611d4d4-ccc3-4332-919d-8a384453209e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8611d4d4-ccc3-4332-919d-8a384453209e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ],
      "id": "undefined-inventory"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "systematic-motorcycle",
        "outputId": "aa6a1555-0b85-441e-df12-9f7d98b8bc6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ],
      "id": "systematic-motorcycle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ],
      "id": "collected-lafayette"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ],
      "id": "acquired-parallel"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ],
      "id": "rational-hollow"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acceptable-equity",
        "outputId": "f23bf98b-2389-482e-e949-f97a518f55da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ],
      "id": "acceptable-equity"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ],
      "id": "thick-reconstruction"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ],
      "id": "dramatic-zealand"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "id": "painted-mathematics"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ],
      "id": "previous-electricity"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "id": "found-bowling"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ],
      "id": "level-terminal"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "correct-kingdom",
        "outputId": "e8a52a67-c5f1-47a3-b132-2c92e033ec19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ],
      "id": "correct-kingdom"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ],
      "id": "herbal-anderson"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "happy-prompt",
        "outputId": "02b214f6-2c0a-45be-d017-64ad9ab8a78e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 14ms/step - loss: 0.8674 - accuracy: 0.4774 - val_loss: 0.8803 - val_accuracy: 0.4792\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8252 - accuracy: 0.4965 - val_loss: 0.8382 - val_accuracy: 0.4896\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7907 - accuracy: 0.5226 - val_loss: 0.8034 - val_accuracy: 0.5104\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7621 - accuracy: 0.5417 - val_loss: 0.7741 - val_accuracy: 0.5312\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.5590 - val_loss: 0.7492 - val_accuracy: 0.5521\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7173 - accuracy: 0.5955 - val_loss: 0.7276 - val_accuracy: 0.5885\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6996 - accuracy: 0.6181 - val_loss: 0.7088 - val_accuracy: 0.5833\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.6337 - val_loss: 0.6924 - val_accuracy: 0.6146\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6704 - accuracy: 0.6493 - val_loss: 0.6782 - val_accuracy: 0.6406\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6581 - accuracy: 0.6528 - val_loss: 0.6656 - val_accuracy: 0.6354\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6615 - val_loss: 0.6544 - val_accuracy: 0.6406\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6753 - val_loss: 0.6442 - val_accuracy: 0.6510\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6289 - accuracy: 0.6788 - val_loss: 0.6349 - val_accuracy: 0.6615\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.6892 - val_loss: 0.6265 - val_accuracy: 0.6667\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.6927 - val_loss: 0.6187 - val_accuracy: 0.6823\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.7066 - val_loss: 0.6116 - val_accuracy: 0.6875\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.7153 - val_loss: 0.6048 - val_accuracy: 0.6979\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.7188 - val_loss: 0.5986 - val_accuracy: 0.6979\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7222 - val_loss: 0.5928 - val_accuracy: 0.7083\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7222 - val_loss: 0.5875 - val_accuracy: 0.7031\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.7257 - val_loss: 0.5825 - val_accuracy: 0.7135\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.7292 - val_loss: 0.5779 - val_accuracy: 0.7188\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.7274 - val_loss: 0.5737 - val_accuracy: 0.7240\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7274 - val_loss: 0.5696 - val_accuracy: 0.7240\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7292 - val_loss: 0.5658 - val_accuracy: 0.7240\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7326 - val_loss: 0.5621 - val_accuracy: 0.7240\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7344 - val_loss: 0.5587 - val_accuracy: 0.7240\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7344 - val_loss: 0.5556 - val_accuracy: 0.7240\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7361 - val_loss: 0.5526 - val_accuracy: 0.7240\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7361 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7413 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7413 - val_loss: 0.5445 - val_accuracy: 0.7240\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7413 - val_loss: 0.5420 - val_accuracy: 0.7240\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7448 - val_loss: 0.5396 - val_accuracy: 0.7240\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7431 - val_loss: 0.5373 - val_accuracy: 0.7240\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7413 - val_loss: 0.5351 - val_accuracy: 0.7188\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.7448 - val_loss: 0.5331 - val_accuracy: 0.7188\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5209 - accuracy: 0.7465 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5186 - accuracy: 0.7465 - val_loss: 0.5291 - val_accuracy: 0.7135\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5162 - accuracy: 0.7465 - val_loss: 0.5271 - val_accuracy: 0.7135\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5139 - accuracy: 0.7431 - val_loss: 0.5253 - val_accuracy: 0.7188\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.7465 - val_loss: 0.5237 - val_accuracy: 0.7135\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7483 - val_loss: 0.5220 - val_accuracy: 0.7135\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5076 - accuracy: 0.7483 - val_loss: 0.5205 - val_accuracy: 0.7135\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7448 - val_loss: 0.5189 - val_accuracy: 0.7135\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5036 - accuracy: 0.7500 - val_loss: 0.5176 - val_accuracy: 0.7135\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.7535 - val_loss: 0.5163 - val_accuracy: 0.7135\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7569 - val_loss: 0.5151 - val_accuracy: 0.7135\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4981 - accuracy: 0.7587 - val_loss: 0.5139 - val_accuracy: 0.7188\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7604 - val_loss: 0.5128 - val_accuracy: 0.7292\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4946 - accuracy: 0.7622 - val_loss: 0.5117 - val_accuracy: 0.7292\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4927 - accuracy: 0.7622 - val_loss: 0.5106 - val_accuracy: 0.7292\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.7587 - val_loss: 0.5096 - val_accuracy: 0.7344\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4895 - accuracy: 0.7587 - val_loss: 0.5086 - val_accuracy: 0.7396\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7604 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4861 - accuracy: 0.7587 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7622 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7691 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7708 - val_loss: 0.5044 - val_accuracy: 0.7552\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4803 - accuracy: 0.7726 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7743 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4773 - accuracy: 0.7691 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7708 - val_loss: 0.5017 - val_accuracy: 0.7448\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4749 - accuracy: 0.7726 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4736 - accuracy: 0.7778 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7795 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7795 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7778 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7795 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7778 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7795 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7778 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7760 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7743 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7795 - val_loss: 0.4947 - val_accuracy: 0.7604\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7795 - val_loss: 0.4946 - val_accuracy: 0.7604\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7795 - val_loss: 0.4945 - val_accuracy: 0.7604\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7604\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7812 - val_loss: 0.4942 - val_accuracy: 0.7604\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7830 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7865 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4520 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4516 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4512 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4507 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4503 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7951 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7917 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4467 - accuracy: 0.7899 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7899 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7882 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7917 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7899 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7934 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7865 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7917 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7934 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7934 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7917 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7951 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7951 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7951 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7951 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7951 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7951 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7951 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7934 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7951 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7934 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7882 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7899 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7917 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7865 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7882 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7882 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7934 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7899 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7899 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7917 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7882 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7899 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7899 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7917 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7934 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7917 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7934 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7917 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7951 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7917 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7934 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7917 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7917 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7917 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7917 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7934 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7934 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.5012 - val_accuracy: 0.7656\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n"
      ],
      "id": "happy-prompt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcjMWciZGf-3",
        "outputId": "8a2a0892-004e-411d-9e7d-3868591045ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_prob_nn_1 = model.predict(X_test_norm)\n",
        "y_pred_class_nn_1  = np.argmax(y_pred_prob_nn_1, axis=1)"
      ],
      "id": "WcjMWciZGf-3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tough-catering",
        "outputId": "11ee22b9-f497-4501-d787-52eae642ea93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ],
      "id": "tough-catering"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "combined-zimbabwe",
        "outputId": "5def7126-712c-4bb5-8c38-d53c9350b102"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.46349293],\n",
              "       [0.6444795 ],\n",
              "       [0.3868862 ],\n",
              "       [0.16646963],\n",
              "       [0.14696644],\n",
              "       [0.5131753 ],\n",
              "       [0.03617987],\n",
              "       [0.29909146],\n",
              "       [0.9291484 ],\n",
              "       [0.13563998]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ],
      "id": "combined-zimbabwe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ],
      "id": "going-estonia"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ],
      "id": "supposed-moderator"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ],
      "id": "second-festival"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "eleven-nebraska",
        "outputId": "f4fcdc3f-01af-463b-eb4a-831267d41332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.641\n",
            "roc-auc is 0.819\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "id": "eleven-nebraska"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ],
      "id": "invalid-nevada"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hidden-physics",
        "outputId": "51b44f41-cf39-4cb6-ceff-29f52cee2673"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ],
      "id": "hidden-physics"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "banned-spider",
        "outputId": "b6b69c81-bfd3-4d1f-b894-87c568ab5df8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cf7195ed4e0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "id": "banned-spider"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ],
      "id": "superb-circus"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "#type your answer here"
      ],
      "id": "german-cherry"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ],
      "id": "involved-slovak"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ],
      "id": "pending-publisher"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqu-Z1izGtC_"
      },
      "outputs": [],
      "source": [
        "new_model = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "id": "cqu-Z1izGtC_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "licFq_goGy3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6288444b-830c-4aec-d7b2-f8447af23328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 19ms/step - loss: 0.7377 - accuracy: 0.3837 - val_loss: 0.7151 - val_accuracy: 0.4531\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7180 - accuracy: 0.4462 - val_loss: 0.6995 - val_accuracy: 0.4844\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7024 - accuracy: 0.5208 - val_loss: 0.6871 - val_accuracy: 0.5208\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5764 - val_loss: 0.6768 - val_accuracy: 0.5729\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.6215 - val_loss: 0.6682 - val_accuracy: 0.5885\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.6354 - val_loss: 0.6611 - val_accuracy: 0.6510\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6620 - accuracy: 0.6580 - val_loss: 0.6549 - val_accuracy: 0.6771\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6553 - accuracy: 0.6771 - val_loss: 0.6496 - val_accuracy: 0.7031\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6492 - accuracy: 0.6753 - val_loss: 0.6448 - val_accuracy: 0.7188\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6806 - val_loss: 0.6405 - val_accuracy: 0.7083\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6858 - val_loss: 0.6366 - val_accuracy: 0.7083\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6840 - val_loss: 0.6330 - val_accuracy: 0.7083\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.6875 - val_loss: 0.6296 - val_accuracy: 0.7188\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.6875 - val_loss: 0.6265 - val_accuracy: 0.7135\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.6875 - val_loss: 0.6235 - val_accuracy: 0.7083\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.6858 - val_loss: 0.6206 - val_accuracy: 0.7031\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6155 - accuracy: 0.6858 - val_loss: 0.6179 - val_accuracy: 0.7083\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.6858 - val_loss: 0.6152 - val_accuracy: 0.7031\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.6823 - val_loss: 0.6127 - val_accuracy: 0.7031\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6060 - accuracy: 0.6806 - val_loss: 0.6101 - val_accuracy: 0.7083\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.6788 - val_loss: 0.6076 - val_accuracy: 0.7083\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.6753 - val_loss: 0.6051 - val_accuracy: 0.7031\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.6771 - val_loss: 0.6027 - val_accuracy: 0.7083\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.6753 - val_loss: 0.6003 - val_accuracy: 0.7083\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.6719 - val_loss: 0.5979 - val_accuracy: 0.7083\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.6753 - val_loss: 0.5955 - val_accuracy: 0.7083\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.6736 - val_loss: 0.5931 - val_accuracy: 0.6979\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.6771 - val_loss: 0.5907 - val_accuracy: 0.6979\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.6771 - val_loss: 0.5884 - val_accuracy: 0.6979\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.6788 - val_loss: 0.5861 - val_accuracy: 0.7031\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5749 - accuracy: 0.6806 - val_loss: 0.5837 - val_accuracy: 0.7031\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.6858 - val_loss: 0.5814 - val_accuracy: 0.7031\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.6875 - val_loss: 0.5790 - val_accuracy: 0.7031\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.6927 - val_loss: 0.5767 - val_accuracy: 0.7031\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.6962 - val_loss: 0.5743 - val_accuracy: 0.6979\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.7014 - val_loss: 0.5719 - val_accuracy: 0.6979\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.6979 - val_loss: 0.5696 - val_accuracy: 0.6979\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.6997 - val_loss: 0.5673 - val_accuracy: 0.7031\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.6997 - val_loss: 0.5650 - val_accuracy: 0.7083\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7014 - val_loss: 0.5628 - val_accuracy: 0.7083\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.6997 - val_loss: 0.5606 - val_accuracy: 0.7135\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7049 - val_loss: 0.5585 - val_accuracy: 0.7083\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7049 - val_loss: 0.5564 - val_accuracy: 0.7240\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7083 - val_loss: 0.5543 - val_accuracy: 0.7240\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7083 - val_loss: 0.5523 - val_accuracy: 0.7135\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7101 - val_loss: 0.5503 - val_accuracy: 0.7135\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7118 - val_loss: 0.5484 - val_accuracy: 0.7135\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7135 - val_loss: 0.5466 - val_accuracy: 0.7135\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7153 - val_loss: 0.5448 - val_accuracy: 0.7083\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7205 - val_loss: 0.5431 - val_accuracy: 0.7135\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7222 - val_loss: 0.5414 - val_accuracy: 0.7135\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5193 - accuracy: 0.7240 - val_loss: 0.5398 - val_accuracy: 0.7135\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7222 - val_loss: 0.5383 - val_accuracy: 0.7135\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7257 - val_loss: 0.5368 - val_accuracy: 0.7083\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7240 - val_loss: 0.5354 - val_accuracy: 0.7083\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7240 - val_loss: 0.5340 - val_accuracy: 0.7083\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7292 - val_loss: 0.5327 - val_accuracy: 0.7031\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7326 - val_loss: 0.5315 - val_accuracy: 0.7083\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7326 - val_loss: 0.5303 - val_accuracy: 0.7083\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7344 - val_loss: 0.5291 - val_accuracy: 0.7135\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7344 - val_loss: 0.5280 - val_accuracy: 0.7188\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7326 - val_loss: 0.5269 - val_accuracy: 0.7240\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7326 - val_loss: 0.5258 - val_accuracy: 0.7240\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7361 - val_loss: 0.5248 - val_accuracy: 0.7188\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7431 - val_loss: 0.5238 - val_accuracy: 0.7188\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7431 - val_loss: 0.5228 - val_accuracy: 0.7188\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7465 - val_loss: 0.5219 - val_accuracy: 0.7135\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7500 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7483 - val_loss: 0.5202 - val_accuracy: 0.7188\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7587 - val_loss: 0.5188 - val_accuracy: 0.7240\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7622 - val_loss: 0.5181 - val_accuracy: 0.7240\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.7656 - val_loss: 0.5174 - val_accuracy: 0.7240\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7639 - val_loss: 0.5168 - val_accuracy: 0.7240\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7674 - val_loss: 0.5161 - val_accuracy: 0.7188\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7691 - val_loss: 0.5155 - val_accuracy: 0.7188\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7674 - val_loss: 0.5150 - val_accuracy: 0.7188\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.5144 - val_accuracy: 0.7240\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7708 - val_loss: 0.5139 - val_accuracy: 0.7240\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7726 - val_loss: 0.5134 - val_accuracy: 0.7240\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7726 - val_loss: 0.5129 - val_accuracy: 0.7240\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7726 - val_loss: 0.5125 - val_accuracy: 0.7240\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7708 - val_loss: 0.5120 - val_accuracy: 0.7240\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7726 - val_loss: 0.5116 - val_accuracy: 0.7240\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7760 - val_loss: 0.5112 - val_accuracy: 0.7240\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7726 - val_loss: 0.5109 - val_accuracy: 0.7240\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7743 - val_loss: 0.5105 - val_accuracy: 0.7240\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7743 - val_loss: 0.5102 - val_accuracy: 0.7240\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7743 - val_loss: 0.5099 - val_accuracy: 0.7240\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.5097 - val_accuracy: 0.7240\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7743 - val_loss: 0.5094 - val_accuracy: 0.7240\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.5092 - val_accuracy: 0.7240\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.5089 - val_accuracy: 0.7240\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7795 - val_loss: 0.5087 - val_accuracy: 0.7240\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7760 - val_loss: 0.5085 - val_accuracy: 0.7240\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7726 - val_loss: 0.5083 - val_accuracy: 0.7240\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7743 - val_loss: 0.5082 - val_accuracy: 0.7240\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.5080 - val_accuracy: 0.7240\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7778 - val_loss: 0.5079 - val_accuracy: 0.7292\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7812 - val_loss: 0.5078 - val_accuracy: 0.7292\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7830 - val_loss: 0.5077 - val_accuracy: 0.7292\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7830 - val_loss: 0.5076 - val_accuracy: 0.7240\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7830 - val_loss: 0.5075 - val_accuracy: 0.7240\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7240\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7778 - val_loss: 0.5074 - val_accuracy: 0.7292\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.5073 - val_accuracy: 0.7292\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7292\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7292\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7847 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7830 - val_loss: 0.5072 - val_accuracy: 0.7344\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7830 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7847 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5074 - val_accuracy: 0.7344\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7865 - val_loss: 0.5075 - val_accuracy: 0.7396\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7865 - val_loss: 0.5076 - val_accuracy: 0.7396\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7396\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7865 - val_loss: 0.5077 - val_accuracy: 0.7396\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7396\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.7934 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7934 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7951 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7951 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7951 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7969 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7969 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7969 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.7969 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7951 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7951 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7917 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7951 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7969 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7917 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7934 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7934 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7934 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7917 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7917 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7934 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7917 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7934 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7986 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8038 - val_loss: 0.5131 - val_accuracy: 0.7396\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.5133 - val_accuracy: 0.7396\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.5134 - val_accuracy: 0.7396\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.5135 - val_accuracy: 0.7396\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8038 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8021 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7396\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7986 - val_loss: 0.5142 - val_accuracy: 0.7396\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5144 - val_accuracy: 0.7396\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5145 - val_accuracy: 0.7396\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.5147 - val_accuracy: 0.7396\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8038 - val_loss: 0.5147 - val_accuracy: 0.7396\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5148 - val_accuracy: 0.7396\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7396\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7986 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8056 - val_loss: 0.5149 - val_accuracy: 0.7344\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7986 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8003 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.5152 - val_accuracy: 0.7344\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.5153 - val_accuracy: 0.7344\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7344\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8003 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7986 - val_loss: 0.5161 - val_accuracy: 0.7344\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8021 - val_loss: 0.5162 - val_accuracy: 0.7344\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8003 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8003 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8073 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8003 - val_loss: 0.5165 - val_accuracy: 0.7344\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8038 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7986 - val_loss: 0.5167 - val_accuracy: 0.7344\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8003 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8038 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8056 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8056 - val_loss: 0.5174 - val_accuracy: 0.7344\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8056 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8021 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8073 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8056 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8038 - val_loss: 0.5184 - val_accuracy: 0.7344\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8038 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8038 - val_loss: 0.5187 - val_accuracy: 0.7344\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8108 - val_loss: 0.5187 - val_accuracy: 0.7292\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8056 - val_loss: 0.5187 - val_accuracy: 0.7292\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8056 - val_loss: 0.5188 - val_accuracy: 0.7292\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8073 - val_loss: 0.5189 - val_accuracy: 0.7292\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8073 - val_loss: 0.5190 - val_accuracy: 0.7292\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8038 - val_loss: 0.5191 - val_accuracy: 0.7292\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8056 - val_loss: 0.5192 - val_accuracy: 0.7292\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8038 - val_loss: 0.5193 - val_accuracy: 0.7292\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8038 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8038 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8056 - val_loss: 0.5196 - val_accuracy: 0.7292\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8038 - val_loss: 0.5197 - val_accuracy: 0.7292\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8056 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8056 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8056 - val_loss: 0.5201 - val_accuracy: 0.7240\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8056 - val_loss: 0.5201 - val_accuracy: 0.7240\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8056 - val_loss: 0.5202 - val_accuracy: 0.7240\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8056 - val_loss: 0.5203 - val_accuracy: 0.7240\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8073 - val_loss: 0.5203 - val_accuracy: 0.7240\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8038 - val_loss: 0.5204 - val_accuracy: 0.7240\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8056 - val_loss: 0.5204 - val_accuracy: 0.7240\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8073 - val_loss: 0.5205 - val_accuracy: 0.7240\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8073 - val_loss: 0.5205 - val_accuracy: 0.7240\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8073 - val_loss: 0.5207 - val_accuracy: 0.7240\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8056 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8056 - val_loss: 0.5209 - val_accuracy: 0.7240\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8073 - val_loss: 0.5209 - val_accuracy: 0.7240\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8073 - val_loss: 0.5209 - val_accuracy: 0.7240\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8056 - val_loss: 0.5210 - val_accuracy: 0.7292\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8056 - val_loss: 0.5211 - val_accuracy: 0.7292\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8073 - val_loss: 0.5212 - val_accuracy: 0.7292\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8073 - val_loss: 0.5213 - val_accuracy: 0.7292\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8073 - val_loss: 0.5213 - val_accuracy: 0.7292\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8073 - val_loss: 0.5215 - val_accuracy: 0.7292\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8056 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8073 - val_loss: 0.5217 - val_accuracy: 0.7292\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8073 - val_loss: 0.5218 - val_accuracy: 0.7292\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8073 - val_loss: 0.5219 - val_accuracy: 0.7344\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8073 - val_loss: 0.5220 - val_accuracy: 0.7292\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8073 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8056 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8073 - val_loss: 0.5223 - val_accuracy: 0.7344\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8056 - val_loss: 0.5223 - val_accuracy: 0.7344\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8073 - val_loss: 0.5224 - val_accuracy: 0.7344\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8090 - val_loss: 0.5225 - val_accuracy: 0.7344\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8056 - val_loss: 0.5224 - val_accuracy: 0.7344\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8090 - val_loss: 0.5225 - val_accuracy: 0.7344\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8090 - val_loss: 0.5224 - val_accuracy: 0.7344\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8108 - val_loss: 0.5223 - val_accuracy: 0.7344\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8090 - val_loss: 0.5223 - val_accuracy: 0.7344\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8090 - val_loss: 0.5224 - val_accuracy: 0.7344\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8090 - val_loss: 0.5226 - val_accuracy: 0.7344\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8108 - val_loss: 0.5227 - val_accuracy: 0.7344\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8090 - val_loss: 0.5228 - val_accuracy: 0.7344\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8090 - val_loss: 0.5228 - val_accuracy: 0.7344\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8108 - val_loss: 0.5230 - val_accuracy: 0.7344\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8090 - val_loss: 0.5230 - val_accuracy: 0.7292\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8090 - val_loss: 0.5230 - val_accuracy: 0.7292\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8108 - val_loss: 0.5230 - val_accuracy: 0.7344\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8090 - val_loss: 0.5230 - val_accuracy: 0.7344\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8108 - val_loss: 0.5231 - val_accuracy: 0.7344\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8090 - val_loss: 0.5233 - val_accuracy: 0.7344\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8108 - val_loss: 0.5232 - val_accuracy: 0.7344\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8090 - val_loss: 0.5233 - val_accuracy: 0.7344\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8108 - val_loss: 0.5233 - val_accuracy: 0.7344\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8108 - val_loss: 0.5234 - val_accuracy: 0.7344\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8108 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8090 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8108 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8108 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8108 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8108 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8090 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8125 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8108 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8125 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8108 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8108 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8108 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8108 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8090 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8108 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8090 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8108 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8142 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8108 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8108 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4123 - accuracy: 0.8108 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4122 - accuracy: 0.8108 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8125 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4120 - accuracy: 0.8125 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4120 - accuracy: 0.8108 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8108 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4118 - accuracy: 0.8142 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4116 - accuracy: 0.8142 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8125 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4116 - accuracy: 0.8125 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8125 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.8108 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4113 - accuracy: 0.8108 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8125 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.8108 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4112 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4111 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4109 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4108 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8125 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4106 - accuracy: 0.8142 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8177 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8160 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4104 - accuracy: 0.8160 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8142 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4102 - accuracy: 0.8142 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4102 - accuracy: 0.8160 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8142 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4101 - accuracy: 0.8142 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4102 - accuracy: 0.8142 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4100 - accuracy: 0.8177 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4101 - accuracy: 0.8160 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4098 - accuracy: 0.8160 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4098 - accuracy: 0.8194 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4098 - accuracy: 0.8177 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4098 - accuracy: 0.8177 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4097 - accuracy: 0.8194 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8160 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4095 - accuracy: 0.8177 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4094 - accuracy: 0.8160 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8177 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4093 - accuracy: 0.8177 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.8142 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4090 - accuracy: 0.8177 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4091 - accuracy: 0.8177 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4092 - accuracy: 0.8194 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4090 - accuracy: 0.8160 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4092 - accuracy: 0.8177 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4088 - accuracy: 0.8160 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4088 - accuracy: 0.8229 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4088 - accuracy: 0.8212 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4088 - accuracy: 0.8194 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.8212 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4086 - accuracy: 0.8194 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.4086 - accuracy: 0.8194 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4087 - accuracy: 0.8177 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4085 - accuracy: 0.8212 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.4085 - accuracy: 0.8194 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4082 - accuracy: 0.8194 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.4084 - accuracy: 0.8194 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4085 - accuracy: 0.8194 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4083 - accuracy: 0.8177 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4082 - accuracy: 0.8229 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4081 - accuracy: 0.8177 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4082 - accuracy: 0.8160 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4082 - accuracy: 0.8212 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4080 - accuracy: 0.8177 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4079 - accuracy: 0.8177 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4080 - accuracy: 0.8177 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4079 - accuracy: 0.8177 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4079 - accuracy: 0.8177 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.4078 - accuracy: 0.8177 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4078 - accuracy: 0.8177 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4078 - accuracy: 0.8177 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4077 - accuracy: 0.8160 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8212 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4077 - accuracy: 0.8194 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4076 - accuracy: 0.8160 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.4074 - accuracy: 0.8177 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8177 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8160 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4073 - accuracy: 0.8177 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.8177 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4073 - accuracy: 0.8177 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4073 - accuracy: 0.8160 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4073 - accuracy: 0.8160 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4073 - accuracy: 0.8194 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4071 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4071 - accuracy: 0.8177 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4069 - accuracy: 0.8194 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4069 - accuracy: 0.8177 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4071 - accuracy: 0.8177 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4070 - accuracy: 0.8160 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8177 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4068 - accuracy: 0.8160 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4069 - accuracy: 0.8177 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8194 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4068 - accuracy: 0.8177 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4067 - accuracy: 0.8177 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4066 - accuracy: 0.8177 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4067 - accuracy: 0.8177 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4066 - accuracy: 0.8160 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4065 - accuracy: 0.8177 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4067 - accuracy: 0.8177 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4065 - accuracy: 0.8177 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.8177 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4063 - accuracy: 0.8177 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4064 - accuracy: 0.8160 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4064 - accuracy: 0.8160 - val_loss: 0.5242 - val_accuracy: 0.7396\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8177 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8160 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8160 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8160 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8194 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8177 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8177 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8177 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8177 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8194 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8160 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8177 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8160 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8177 - val_loss: 0.5239 - val_accuracy: 0.7448\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8194 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8229 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8212 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8212 - val_loss: 0.5238 - val_accuracy: 0.7448\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8194 - val_loss: 0.5238 - val_accuracy: 0.7448\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8247 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8229 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8229 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8212 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8194 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8194 - val_loss: 0.5233 - val_accuracy: 0.7344\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8212 - val_loss: 0.5233 - val_accuracy: 0.7344\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8212 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8229 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8194 - val_loss: 0.5232 - val_accuracy: 0.7344\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7396\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8212 - val_loss: 0.5233 - val_accuracy: 0.7500\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8229 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8229 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8247 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8194 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7396\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8229 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8212 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8229 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.8229 - val_loss: 0.5230 - val_accuracy: 0.7396\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8229 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8177 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8194 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.8212 - val_loss: 0.5230 - val_accuracy: 0.7500\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8229 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8247 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8229 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.8194 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8229 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8247 - val_loss: 0.5227 - val_accuracy: 0.7396\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8194 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8212 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8229 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8264 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8212 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8247 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8194 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4039 - accuracy: 0.8264 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4039 - accuracy: 0.8229 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8264 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8229 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8212 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8212 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8247 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8229 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8212 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8264 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8212 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8229 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8229 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8247 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8212 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8194 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8212 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8194 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8212 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8212 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8247 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8247 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8212 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8247 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8229 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8212 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8229 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8247 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8229 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8229 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8229 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8212 - val_loss: 0.5230 - val_accuracy: 0.7448\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8229 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8281 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8264 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8229 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8229 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8229 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8229 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8247 - val_loss: 0.5233 - val_accuracy: 0.7448\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8229 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8264 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8264 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8247 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8212 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8247 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8281 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8281 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8247 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8229 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8229 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8247 - val_loss: 0.5238 - val_accuracy: 0.7396\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8247 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8229 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8299 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8264 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8264 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8264 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8247 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8264 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8247 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8264 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8299 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5243 - val_accuracy: 0.7344\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5243 - val_accuracy: 0.7344\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8264 - val_loss: 0.5244 - val_accuracy: 0.7344\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5242 - val_accuracy: 0.7344\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8264 - val_loss: 0.5243 - val_accuracy: 0.7344\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5244 - val_accuracy: 0.7344\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5242 - val_accuracy: 0.7344\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5243 - val_accuracy: 0.7344\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8299 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8316 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8316 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8281 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8299 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8316 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8299 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8299 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8299 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8299 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8299 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8316 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8264 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8299 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8316 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8316 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8316 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8299 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8299 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8316 - val_loss: 0.5244 - val_accuracy: 0.7344\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8264 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8316 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8299 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8316 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8299 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8299 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8299 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8299 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8281 - val_loss: 0.5243 - val_accuracy: 0.7344\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8247 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8299 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3998 - accuracy: 0.8316 - val_loss: 0.5244 - val_accuracy: 0.7344\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8299 - val_loss: 0.5243 - val_accuracy: 0.7396\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8264 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3997 - accuracy: 0.8316 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8281 - val_loss: 0.5242 - val_accuracy: 0.7344\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8333 - val_loss: 0.5244 - val_accuracy: 0.7344\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8333 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3996 - accuracy: 0.8299 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8299 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8281 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8316 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8281 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8299 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8299 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8281 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8281 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8299 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3992 - accuracy: 0.8299 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8299 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8299 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8299 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8316 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8316 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8316 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8316 - val_loss: 0.5247 - val_accuracy: 0.7396\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8299 - val_loss: 0.5248 - val_accuracy: 0.7396\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8281 - val_loss: 0.5248 - val_accuracy: 0.7396\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8299 - val_loss: 0.5249 - val_accuracy: 0.7396\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8299 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8333 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8316 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8299 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3989 - accuracy: 0.8299 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8299 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8299 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8299 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8299 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8299 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8281 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8316 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3990 - accuracy: 0.8316 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8316 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8299 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8281 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8299 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8281 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8299 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8299 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8316 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8299 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8299 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8299 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8281 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8281 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8264 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8281 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8264 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8281 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8281 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8264 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8281 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8281 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8281 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8316 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8264 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8281 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8316 - val_loss: 0.5259 - val_accuracy: 0.7396\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8281 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8281 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8281 - val_loss: 0.5259 - val_accuracy: 0.7396\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8264 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8281 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8299 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8299 - val_loss: 0.5259 - val_accuracy: 0.7448\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8281 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8264 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8299 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8281 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8281 - val_loss: 0.5259 - val_accuracy: 0.7448\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8281 - val_loss: 0.5257 - val_accuracy: 0.7396\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8299 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8281 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8281 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8281 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8281 - val_loss: 0.5259 - val_accuracy: 0.7396\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8281 - val_loss: 0.5259 - val_accuracy: 0.7396\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8281 - val_loss: 0.5261 - val_accuracy: 0.7396\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8281 - val_loss: 0.5261 - val_accuracy: 0.7396\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8299 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8264 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8281 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8281 - val_loss: 0.5263 - val_accuracy: 0.7448\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8264 - val_loss: 0.5263 - val_accuracy: 0.7396\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8281 - val_loss: 0.5264 - val_accuracy: 0.7448\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8264 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8281 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8281 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8299 - val_loss: 0.5262 - val_accuracy: 0.7396\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8247 - val_loss: 0.5264 - val_accuracy: 0.7396\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8281 - val_loss: 0.5269 - val_accuracy: 0.7396\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8281 - val_loss: 0.5267 - val_accuracy: 0.7396\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8281 - val_loss: 0.5265 - val_accuracy: 0.7396\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8299 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8281 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8281 - val_loss: 0.5265 - val_accuracy: 0.7448\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8281 - val_loss: 0.5267 - val_accuracy: 0.7448\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8264 - val_loss: 0.5269 - val_accuracy: 0.7396\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8281 - val_loss: 0.5269 - val_accuracy: 0.7396\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8264 - val_loss: 0.5268 - val_accuracy: 0.7396\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8281 - val_loss: 0.5269 - val_accuracy: 0.7396\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8281 - val_loss: 0.5270 - val_accuracy: 0.7396\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8299 - val_loss: 0.5270 - val_accuracy: 0.7396\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8264 - val_loss: 0.5270 - val_accuracy: 0.7396\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8281 - val_loss: 0.5266 - val_accuracy: 0.7396\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8281 - val_loss: 0.5267 - val_accuracy: 0.7396\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8299 - val_loss: 0.5267 - val_accuracy: 0.7396\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8281 - val_loss: 0.5269 - val_accuracy: 0.7396\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8281 - val_loss: 0.5268 - val_accuracy: 0.7396\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8264 - val_loss: 0.5271 - val_accuracy: 0.7396\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8281 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8281 - val_loss: 0.5271 - val_accuracy: 0.7396\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8299 - val_loss: 0.5268 - val_accuracy: 0.7396\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8247 - val_loss: 0.5269 - val_accuracy: 0.7396\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8299 - val_loss: 0.5271 - val_accuracy: 0.7396\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8281 - val_loss: 0.5272 - val_accuracy: 0.7396\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3967 - accuracy: 0.8281 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8299 - val_loss: 0.5272 - val_accuracy: 0.7396\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8264 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8299 - val_loss: 0.5272 - val_accuracy: 0.7396\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8281 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8264 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8299 - val_loss: 0.5272 - val_accuracy: 0.7396\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8299 - val_loss: 0.5270 - val_accuracy: 0.7448\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8264 - val_loss: 0.5272 - val_accuracy: 0.7396\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8281 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8281 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8299 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8281 - val_loss: 0.5275 - val_accuracy: 0.7396\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8264 - val_loss: 0.5272 - val_accuracy: 0.7448\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8264 - val_loss: 0.5275 - val_accuracy: 0.7396\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8264 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8264 - val_loss: 0.5277 - val_accuracy: 0.7396\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8264 - val_loss: 0.5278 - val_accuracy: 0.7396\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8299 - val_loss: 0.5275 - val_accuracy: 0.7448\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8264 - val_loss: 0.5274 - val_accuracy: 0.7448\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8264 - val_loss: 0.5276 - val_accuracy: 0.7396\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8264 - val_loss: 0.5277 - val_accuracy: 0.7396\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8264 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8264 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8264 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8247 - val_loss: 0.5278 - val_accuracy: 0.7396\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8281 - val_loss: 0.5276 - val_accuracy: 0.7448\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8264 - val_loss: 0.5279 - val_accuracy: 0.7396\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8247 - val_loss: 0.5280 - val_accuracy: 0.7396\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8264 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8264 - val_loss: 0.5279 - val_accuracy: 0.7396\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8264 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8299 - val_loss: 0.5277 - val_accuracy: 0.7448\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3960 - accuracy: 0.8281 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8264 - val_loss: 0.5282 - val_accuracy: 0.7396\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8264 - val_loss: 0.5284 - val_accuracy: 0.7396\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8264 - val_loss: 0.5283 - val_accuracy: 0.7396\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8281 - val_loss: 0.5282 - val_accuracy: 0.7396\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8264 - val_loss: 0.5281 - val_accuracy: 0.7396\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8264 - val_loss: 0.5281 - val_accuracy: 0.7396\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8264 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8281 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8264 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8247 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8264 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8264 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8281 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8264 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8264 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8264 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8247 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8264 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3955 - accuracy: 0.8264 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3956 - accuracy: 0.8281 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8299 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3953 - accuracy: 0.8264 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8264 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8264 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3956 - accuracy: 0.8281 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3955 - accuracy: 0.8281 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3954 - accuracy: 0.8264 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8264 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3954 - accuracy: 0.8264 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8264 - val_loss: 0.5281 - val_accuracy: 0.7448\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8299 - val_loss: 0.5279 - val_accuracy: 0.7448\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8264 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3954 - accuracy: 0.8264 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8264 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8264 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3951 - accuracy: 0.8264 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8264 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8264 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8281 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8264 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8264 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3952 - accuracy: 0.8264 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8264 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8247 - val_loss: 0.5282 - val_accuracy: 0.7448\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8264 - val_loss: 0.5285 - val_accuracy: 0.7448\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8264 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8264 - val_loss: 0.5283 - val_accuracy: 0.7448\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8264 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8264 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8281 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8264 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8264 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8264 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8281 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8264 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8264 - val_loss: 0.5284 - val_accuracy: 0.7448\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8264 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8264 - val_loss: 0.5289 - val_accuracy: 0.7448\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8281 - val_loss: 0.5287 - val_accuracy: 0.7448\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8247 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8281 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8264 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8264 - val_loss: 0.5291 - val_accuracy: 0.7448\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8264 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8281 - val_loss: 0.5293 - val_accuracy: 0.7448\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8264 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8299 - val_loss: 0.5290 - val_accuracy: 0.7448\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8264 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8281 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8264 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8281 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8264 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8281 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8264 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8281 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8264 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8264 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8264 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8264 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8264 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8281 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8264 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8264 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8264 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8264 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8264 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8264 - val_loss: 0.5297 - val_accuracy: 0.7448\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8264 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8281 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8264 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8299 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8264 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8264 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8281 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8264 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.8264 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8281 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8264 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3937 - accuracy: 0.8264 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.8264 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8264 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8281 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8264 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8264 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8281 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8264 - val_loss: 0.5306 - val_accuracy: 0.7344\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8264 - val_loss: 0.5306 - val_accuracy: 0.7344\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8264 - val_loss: 0.5307 - val_accuracy: 0.7344\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3937 - accuracy: 0.8281 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8247 - val_loss: 0.5306 - val_accuracy: 0.7344\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8264 - val_loss: 0.5308 - val_accuracy: 0.7344\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3937 - accuracy: 0.8264 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8264 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8264 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8264 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8247 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8247 - val_loss: 0.5306 - val_accuracy: 0.7344\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8264 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8264 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8264 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8247 - val_loss: 0.5306 - val_accuracy: 0.7344\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8264 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8264 - val_loss: 0.5301 - val_accuracy: 0.7396\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8247 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8247 - val_loss: 0.5310 - val_accuracy: 0.7344\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8247 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8247 - val_loss: 0.5314 - val_accuracy: 0.7344\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8264 - val_loss: 0.5310 - val_accuracy: 0.7344\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8247 - val_loss: 0.5310 - val_accuracy: 0.7344\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8281 - val_loss: 0.5309 - val_accuracy: 0.7344\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8299 - val_loss: 0.5311 - val_accuracy: 0.7344\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8247 - val_loss: 0.5314 - val_accuracy: 0.7344\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.8281 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3930 - accuracy: 0.8264 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8281 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8299 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8299 - val_loss: 0.5311 - val_accuracy: 0.7344\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8264 - val_loss: 0.5313 - val_accuracy: 0.7344\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8264 - val_loss: 0.5314 - val_accuracy: 0.7344\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8281 - val_loss: 0.5314 - val_accuracy: 0.7344\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8264 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8281 - val_loss: 0.5316 - val_accuracy: 0.7344\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8281 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8299 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8299 - val_loss: 0.5314 - val_accuracy: 0.7344\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8281 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8299 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3925 - accuracy: 0.8281 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8299 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8281 - val_loss: 0.5316 - val_accuracy: 0.7396\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8299 - val_loss: 0.5318 - val_accuracy: 0.7396\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8299 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8299 - val_loss: 0.5317 - val_accuracy: 0.7396\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8299 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8281 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3919 - accuracy: 0.8299 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3918 - accuracy: 0.8299 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8316 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.8299 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3917 - accuracy: 0.8299 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8281 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.8299 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3913 - accuracy: 0.8299 - val_loss: 0.5321 - val_accuracy: 0.7396\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3912 - accuracy: 0.8299 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3913 - accuracy: 0.8299 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3912 - accuracy: 0.8316 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3914 - accuracy: 0.8299 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3911 - accuracy: 0.8299 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3910 - accuracy: 0.8299 - val_loss: 0.5326 - val_accuracy: 0.7448\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8281 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3904 - accuracy: 0.8299 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3906 - accuracy: 0.8316 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3903 - accuracy: 0.8299 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3903 - accuracy: 0.8281 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3902 - accuracy: 0.8281 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3903 - accuracy: 0.8281 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8281 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8281 - val_loss: 0.5338 - val_accuracy: 0.7500\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8281 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8281 - val_loss: 0.5344 - val_accuracy: 0.7500\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8281 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8281 - val_loss: 0.5346 - val_accuracy: 0.7500\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8281 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8281 - val_loss: 0.5348 - val_accuracy: 0.7448\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3897 - accuracy: 0.8281 - val_loss: 0.5347 - val_accuracy: 0.7500\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8281 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8281 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8281 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8299 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8299 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8281 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8299 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8299 - val_loss: 0.5349 - val_accuracy: 0.7552\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8299 - val_loss: 0.5351 - val_accuracy: 0.7552\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8316 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8316 - val_loss: 0.5350 - val_accuracy: 0.7500\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8299 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8299 - val_loss: 0.5353 - val_accuracy: 0.7552\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8316 - val_loss: 0.5355 - val_accuracy: 0.7552\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8299 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8299 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8316 - val_loss: 0.5357 - val_accuracy: 0.7552\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8299 - val_loss: 0.5364 - val_accuracy: 0.7552\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8299 - val_loss: 0.5365 - val_accuracy: 0.7552\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8316 - val_loss: 0.5361 - val_accuracy: 0.7552\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8299 - val_loss: 0.5362 - val_accuracy: 0.7552\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8316 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8299 - val_loss: 0.5363 - val_accuracy: 0.7552\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8299 - val_loss: 0.5363 - val_accuracy: 0.7552\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8316 - val_loss: 0.5364 - val_accuracy: 0.7552\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8299 - val_loss: 0.5367 - val_accuracy: 0.7552\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8316 - val_loss: 0.5367 - val_accuracy: 0.7552\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8299 - val_loss: 0.5368 - val_accuracy: 0.7552\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8333 - val_loss: 0.5367 - val_accuracy: 0.7552\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8316 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8299 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8333 - val_loss: 0.5368 - val_accuracy: 0.7552\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8316 - val_loss: 0.5369 - val_accuracy: 0.7552\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8316 - val_loss: 0.5369 - val_accuracy: 0.7552\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8333 - val_loss: 0.5369 - val_accuracy: 0.7500\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8316 - val_loss: 0.5369 - val_accuracy: 0.7500\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8316 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8316 - val_loss: 0.5373 - val_accuracy: 0.7500\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.8316 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8333 - val_loss: 0.5373 - val_accuracy: 0.7500\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8316 - val_loss: 0.5374 - val_accuracy: 0.7500\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3873 - accuracy: 0.8316 - val_loss: 0.5375 - val_accuracy: 0.7500\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8316 - val_loss: 0.5376 - val_accuracy: 0.7500\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8316 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8316 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8316 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8333 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8333 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8333 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8333 - val_loss: 0.5381 - val_accuracy: 0.7500\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.8333 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8333 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8333 - val_loss: 0.5379 - val_accuracy: 0.7500\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3873 - accuracy: 0.8333 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8316 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8351 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8333 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8299 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8316 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8316 - val_loss: 0.5391 - val_accuracy: 0.7552\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8316 - val_loss: 0.5390 - val_accuracy: 0.7552\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8333 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3868 - accuracy: 0.8316 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8333 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8333 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8316 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8333 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8316 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8333 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8333 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8316 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8351 - val_loss: 0.5390 - val_accuracy: 0.7448\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8333 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8333 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8333 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8333 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8333 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8351 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8333 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8333 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8333 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8333 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8299 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8333 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8316 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8351 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8333 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8333 - val_loss: 0.5400 - val_accuracy: 0.7448\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8333 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8333 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8333 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8351 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8333 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8351 - val_loss: 0.5401 - val_accuracy: 0.7448\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8333 - val_loss: 0.5401 - val_accuracy: 0.7448\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8333 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8351 - val_loss: 0.5399 - val_accuracy: 0.7448\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.8333 - val_loss: 0.5398 - val_accuracy: 0.7448\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3862 - accuracy: 0.8333 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.8333 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8333 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3861 - accuracy: 0.8351 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8351 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.8333 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3863 - accuracy: 0.8351 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3858 - accuracy: 0.8333 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3861 - accuracy: 0.8333 - val_loss: 0.5401 - val_accuracy: 0.7448\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3862 - accuracy: 0.8351 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3861 - accuracy: 0.8351 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3859 - accuracy: 0.8333 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3858 - accuracy: 0.8333 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8333 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8333 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8333 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8368 - val_loss: 0.5404 - val_accuracy: 0.7448\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8351 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.8333 - val_loss: 0.5407 - val_accuracy: 0.7396\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3855 - accuracy: 0.8351 - val_loss: 0.5410 - val_accuracy: 0.7448\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8351 - val_loss: 0.5409 - val_accuracy: 0.7448\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3858 - accuracy: 0.8351 - val_loss: 0.5411 - val_accuracy: 0.7448\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8351 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3858 - accuracy: 0.8333 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8351 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8333 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8333 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8351 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8351 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3853 - accuracy: 0.8351 - val_loss: 0.5412 - val_accuracy: 0.7500\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3855 - accuracy: 0.8351 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3854 - accuracy: 0.8351 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3852 - accuracy: 0.8351 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8351 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3851 - accuracy: 0.8351 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3851 - accuracy: 0.8351 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.5414 - val_accuracy: 0.7500\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8351 - val_loss: 0.5416 - val_accuracy: 0.7500\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8368 - val_loss: 0.5416 - val_accuracy: 0.7448\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3852 - accuracy: 0.8351 - val_loss: 0.5415 - val_accuracy: 0.7448\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3849 - accuracy: 0.8351 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3849 - accuracy: 0.8351 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8351 - val_loss: 0.5416 - val_accuracy: 0.7500\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8368 - val_loss: 0.5415 - val_accuracy: 0.7448\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8333 - val_loss: 0.5416 - val_accuracy: 0.7448\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8316 - val_loss: 0.5421 - val_accuracy: 0.7500\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3849 - accuracy: 0.8333 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8368 - val_loss: 0.5424 - val_accuracy: 0.7500\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8351 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8351 - val_loss: 0.5421 - val_accuracy: 0.7448\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3849 - accuracy: 0.8351 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3849 - accuracy: 0.8351 - val_loss: 0.5424 - val_accuracy: 0.7448\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8351 - val_loss: 0.5427 - val_accuracy: 0.7448\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8351 - val_loss: 0.5427 - val_accuracy: 0.7448\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8368 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.8351 - val_loss: 0.5424 - val_accuracy: 0.7448\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8351 - val_loss: 0.5422 - val_accuracy: 0.7396\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8333 - val_loss: 0.5430 - val_accuracy: 0.7448\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8351 - val_loss: 0.5429 - val_accuracy: 0.7448\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8368 - val_loss: 0.5426 - val_accuracy: 0.7396\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8333 - val_loss: 0.5427 - val_accuracy: 0.7396\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8299 - val_loss: 0.5431 - val_accuracy: 0.7396\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8351 - val_loss: 0.5429 - val_accuracy: 0.7396\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8351 - val_loss: 0.5431 - val_accuracy: 0.7396\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8368 - val_loss: 0.5431 - val_accuracy: 0.7396\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8351 - val_loss: 0.5436 - val_accuracy: 0.7448\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8333 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8333 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8351 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8333 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8351 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8351 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8351 - val_loss: 0.5438 - val_accuracy: 0.7396\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8351 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8351 - val_loss: 0.5443 - val_accuracy: 0.7396\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.8368 - val_loss: 0.5439 - val_accuracy: 0.7344\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8333 - val_loss: 0.5441 - val_accuracy: 0.7344\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8351 - val_loss: 0.5443 - val_accuracy: 0.7344\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8351 - val_loss: 0.5441 - val_accuracy: 0.7344\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3841 - accuracy: 0.8351 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8351 - val_loss: 0.5443 - val_accuracy: 0.7344\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8351 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.8351 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.8368 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8351 - val_loss: 0.5443 - val_accuracy: 0.7344\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3840 - accuracy: 0.8333 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8351 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8351 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8351 - val_loss: 0.5450 - val_accuracy: 0.7396\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8368 - val_loss: 0.5451 - val_accuracy: 0.7396\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8368 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8351 - val_loss: 0.5451 - val_accuracy: 0.7344\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8351 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8368 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8368 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8403 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8368 - val_loss: 0.5454 - val_accuracy: 0.7344\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8385 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8403 - val_loss: 0.5451 - val_accuracy: 0.7292\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8368 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8385 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8351 - val_loss: 0.5462 - val_accuracy: 0.7344\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.8403 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8368 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8351 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3832 - accuracy: 0.8351 - val_loss: 0.5462 - val_accuracy: 0.7396\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8403 - val_loss: 0.5458 - val_accuracy: 0.7344\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.8368 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8351 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8368 - val_loss: 0.5464 - val_accuracy: 0.7396\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8368 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.8351 - val_loss: 0.5465 - val_accuracy: 0.7344\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8368 - val_loss: 0.5471 - val_accuracy: 0.7344\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.8368 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8368 - val_loss: 0.5469 - val_accuracy: 0.7344\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8403 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8385 - val_loss: 0.5466 - val_accuracy: 0.7344\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8351 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8385 - val_loss: 0.5470 - val_accuracy: 0.7344\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8403 - val_loss: 0.5467 - val_accuracy: 0.7292\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8351 - val_loss: 0.5470 - val_accuracy: 0.7292\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8368 - val_loss: 0.5469 - val_accuracy: 0.7292\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.8368 - val_loss: 0.5471 - val_accuracy: 0.7292\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3827 - accuracy: 0.8385 - val_loss: 0.5469 - val_accuracy: 0.7292\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8368 - val_loss: 0.5469 - val_accuracy: 0.7292\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3826 - accuracy: 0.8351 - val_loss: 0.5473 - val_accuracy: 0.7292\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3826 - accuracy: 0.8385 - val_loss: 0.5470 - val_accuracy: 0.7292\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8351 - val_loss: 0.5474 - val_accuracy: 0.7292\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8420 - val_loss: 0.5469 - val_accuracy: 0.7292\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8351 - val_loss: 0.5475 - val_accuracy: 0.7292\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3824 - accuracy: 0.8368 - val_loss: 0.5477 - val_accuracy: 0.7292\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8351 - val_loss: 0.5477 - val_accuracy: 0.7292\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8351 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8385 - val_loss: 0.5481 - val_accuracy: 0.7292\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8368 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8368 - val_loss: 0.5479 - val_accuracy: 0.7292\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3824 - accuracy: 0.8385 - val_loss: 0.5481 - val_accuracy: 0.7292\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8385 - val_loss: 0.5481 - val_accuracy: 0.7292\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8368 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8385 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8351 - val_loss: 0.5482 - val_accuracy: 0.7292\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8368 - val_loss: 0.5482 - val_accuracy: 0.7292\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8368 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8368 - val_loss: 0.5484 - val_accuracy: 0.7292\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8385 - val_loss: 0.5484 - val_accuracy: 0.7240\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8368 - val_loss: 0.5485 - val_accuracy: 0.7240\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3821 - accuracy: 0.8368 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3819 - accuracy: 0.8368 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3816 - accuracy: 0.8385 - val_loss: 0.5487 - val_accuracy: 0.7240\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3819 - accuracy: 0.8351 - val_loss: 0.5489 - val_accuracy: 0.7240\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8368 - val_loss: 0.5487 - val_accuracy: 0.7188\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3818 - accuracy: 0.8368 - val_loss: 0.5489 - val_accuracy: 0.7240\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3816 - accuracy: 0.8368 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.8385 - val_loss: 0.5490 - val_accuracy: 0.7240\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.8368 - val_loss: 0.5491 - val_accuracy: 0.7240\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8368 - val_loss: 0.5495 - val_accuracy: 0.7240\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3814 - accuracy: 0.8368 - val_loss: 0.5496 - val_accuracy: 0.7240\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8368 - val_loss: 0.5496 - val_accuracy: 0.7240\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8368 - val_loss: 0.5496 - val_accuracy: 0.7240\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3814 - accuracy: 0.8385 - val_loss: 0.5496 - val_accuracy: 0.7240\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3814 - accuracy: 0.8368 - val_loss: 0.5500 - val_accuracy: 0.7240\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3815 - accuracy: 0.8403 - val_loss: 0.5500 - val_accuracy: 0.7240\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.8351 - val_loss: 0.5501 - val_accuracy: 0.7240\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3813 - accuracy: 0.8385 - val_loss: 0.5503 - val_accuracy: 0.7240\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8368 - val_loss: 0.5503 - val_accuracy: 0.7240\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.8368 - val_loss: 0.5504 - val_accuracy: 0.7240\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3813 - accuracy: 0.8368 - val_loss: 0.5504 - val_accuracy: 0.7240\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3808 - accuracy: 0.8385 - val_loss: 0.5504 - val_accuracy: 0.7240\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3810 - accuracy: 0.8368 - val_loss: 0.5505 - val_accuracy: 0.7240\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3812 - accuracy: 0.8385 - val_loss: 0.5504 - val_accuracy: 0.7240\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.8385 - val_loss: 0.5505 - val_accuracy: 0.7240\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3813 - accuracy: 0.8368 - val_loss: 0.5508 - val_accuracy: 0.7240\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.8368 - val_loss: 0.5511 - val_accuracy: 0.7240\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.8385 - val_loss: 0.5513 - val_accuracy: 0.7240\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3808 - accuracy: 0.8368 - val_loss: 0.5512 - val_accuracy: 0.7240\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3808 - accuracy: 0.8385 - val_loss: 0.5508 - val_accuracy: 0.7240\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8368 - val_loss: 0.5511 - val_accuracy: 0.7240\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8368 - val_loss: 0.5511 - val_accuracy: 0.7240\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3808 - accuracy: 0.8385 - val_loss: 0.5506 - val_accuracy: 0.7240\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8351 - val_loss: 0.5509 - val_accuracy: 0.7240\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3804 - accuracy: 0.8385 - val_loss: 0.5509 - val_accuracy: 0.7240\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8368 - val_loss: 0.5509 - val_accuracy: 0.7240\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8385 - val_loss: 0.5511 - val_accuracy: 0.7240\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8385 - val_loss: 0.5510 - val_accuracy: 0.7240\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8351 - val_loss: 0.5510 - val_accuracy: 0.7240\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8351 - val_loss: 0.5515 - val_accuracy: 0.7240\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8368 - val_loss: 0.5519 - val_accuracy: 0.7188\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8368 - val_loss: 0.5522 - val_accuracy: 0.7188\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8368 - val_loss: 0.5524 - val_accuracy: 0.7188\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8368 - val_loss: 0.5524 - val_accuracy: 0.7188\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8368 - val_loss: 0.5521 - val_accuracy: 0.7188\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.8368 - val_loss: 0.5523 - val_accuracy: 0.7188\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.8403 - val_loss: 0.5523 - val_accuracy: 0.7188\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8385 - val_loss: 0.5524 - val_accuracy: 0.7240\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8385 - val_loss: 0.5523 - val_accuracy: 0.7240\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8351 - val_loss: 0.5525 - val_accuracy: 0.7240\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8368 - val_loss: 0.5524 - val_accuracy: 0.7240\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.8351 - val_loss: 0.5525 - val_accuracy: 0.7240\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8368 - val_loss: 0.5532 - val_accuracy: 0.7188\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.8351 - val_loss: 0.5533 - val_accuracy: 0.7188\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8385 - val_loss: 0.5528 - val_accuracy: 0.7240\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8351 - val_loss: 0.5530 - val_accuracy: 0.7188\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8385 - val_loss: 0.5528 - val_accuracy: 0.7240\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8385 - val_loss: 0.5528 - val_accuracy: 0.7240\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8403 - val_loss: 0.5528 - val_accuracy: 0.7240\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8351 - val_loss: 0.5530 - val_accuracy: 0.7188\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8368 - val_loss: 0.5532 - val_accuracy: 0.7188\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8368 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8403 - val_loss: 0.5534 - val_accuracy: 0.7188\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.8385 - val_loss: 0.5534 - val_accuracy: 0.7188\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3796 - accuracy: 0.8368 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8403 - val_loss: 0.5533 - val_accuracy: 0.7240\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8351 - val_loss: 0.5535 - val_accuracy: 0.7188\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.8368 - val_loss: 0.5537 - val_accuracy: 0.7188\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8333 - val_loss: 0.5538 - val_accuracy: 0.7188\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8368 - val_loss: 0.5539 - val_accuracy: 0.7188\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8333 - val_loss: 0.5541 - val_accuracy: 0.7188\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.8368 - val_loss: 0.5542 - val_accuracy: 0.7188\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8351 - val_loss: 0.5541 - val_accuracy: 0.7188\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8351 - val_loss: 0.5542 - val_accuracy: 0.7188\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8368 - val_loss: 0.5542 - val_accuracy: 0.7188\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8368 - val_loss: 0.5543 - val_accuracy: 0.7188\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8351 - val_loss: 0.5543 - val_accuracy: 0.7188\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8351 - val_loss: 0.5546 - val_accuracy: 0.7188\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8351 - val_loss: 0.5545 - val_accuracy: 0.7188\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8385 - val_loss: 0.5544 - val_accuracy: 0.7188\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8385 - val_loss: 0.5542 - val_accuracy: 0.7240\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8368 - val_loss: 0.5543 - val_accuracy: 0.7240\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8351 - val_loss: 0.5545 - val_accuracy: 0.7188\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8368 - val_loss: 0.5545 - val_accuracy: 0.7188\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8351 - val_loss: 0.5547 - val_accuracy: 0.7188\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8333 - val_loss: 0.5550 - val_accuracy: 0.7188\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8368 - val_loss: 0.5553 - val_accuracy: 0.7188\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8368 - val_loss: 0.5554 - val_accuracy: 0.7188\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8351 - val_loss: 0.5553 - val_accuracy: 0.7188\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8333 - val_loss: 0.5554 - val_accuracy: 0.7188\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8385 - val_loss: 0.5552 - val_accuracy: 0.7188\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8351 - val_loss: 0.5555 - val_accuracy: 0.7188\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8368 - val_loss: 0.5555 - val_accuracy: 0.7188\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8351 - val_loss: 0.5557 - val_accuracy: 0.7188\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8368 - val_loss: 0.5558 - val_accuracy: 0.7188\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8351 - val_loss: 0.5557 - val_accuracy: 0.7188\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8351 - val_loss: 0.5557 - val_accuracy: 0.7188\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8385 - val_loss: 0.5556 - val_accuracy: 0.7188\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8333 - val_loss: 0.5559 - val_accuracy: 0.7188\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8351 - val_loss: 0.5560 - val_accuracy: 0.7188\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8351 - val_loss: 0.5563 - val_accuracy: 0.7188\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8368 - val_loss: 0.5565 - val_accuracy: 0.7188\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8368 - val_loss: 0.5565 - val_accuracy: 0.7188\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8351 - val_loss: 0.5569 - val_accuracy: 0.7188\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8368 - val_loss: 0.5567 - val_accuracy: 0.7188\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8385 - val_loss: 0.5567 - val_accuracy: 0.7188\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8351 - val_loss: 0.5570 - val_accuracy: 0.7188\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8368 - val_loss: 0.5572 - val_accuracy: 0.7188\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8351 - val_loss: 0.5573 - val_accuracy: 0.7188\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8368 - val_loss: 0.5571 - val_accuracy: 0.7188\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8351 - val_loss: 0.5574 - val_accuracy: 0.7188\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8351 - val_loss: 0.5574 - val_accuracy: 0.7188\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8351 - val_loss: 0.5573 - val_accuracy: 0.7188\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8351 - val_loss: 0.5574 - val_accuracy: 0.7188\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3781 - accuracy: 0.8351 - val_loss: 0.5575 - val_accuracy: 0.7188\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8385 - val_loss: 0.5576 - val_accuracy: 0.7188\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8351 - val_loss: 0.5579 - val_accuracy: 0.7188\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8333 - val_loss: 0.5582 - val_accuracy: 0.7188\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3781 - accuracy: 0.8368 - val_loss: 0.5581 - val_accuracy: 0.7188\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8351 - val_loss: 0.5583 - val_accuracy: 0.7188\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8351 - val_loss: 0.5584 - val_accuracy: 0.7188\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8333 - val_loss: 0.5586 - val_accuracy: 0.7188\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8333 - val_loss: 0.5589 - val_accuracy: 0.7188\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8351 - val_loss: 0.5587 - val_accuracy: 0.7188\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3778 - accuracy: 0.8351 - val_loss: 0.5590 - val_accuracy: 0.7188\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8368 - val_loss: 0.5592 - val_accuracy: 0.7188\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8368 - val_loss: 0.5590 - val_accuracy: 0.7188\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3778 - accuracy: 0.8385 - val_loss: 0.5588 - val_accuracy: 0.7188\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8368 - val_loss: 0.5586 - val_accuracy: 0.7188\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8351 - val_loss: 0.5589 - val_accuracy: 0.7188\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8368 - val_loss: 0.5589 - val_accuracy: 0.7188\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8368 - val_loss: 0.5589 - val_accuracy: 0.7188\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8351 - val_loss: 0.5594 - val_accuracy: 0.7188\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8351 - val_loss: 0.5600 - val_accuracy: 0.7188\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8368 - val_loss: 0.5595 - val_accuracy: 0.7188\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3778 - accuracy: 0.8351 - val_loss: 0.5597 - val_accuracy: 0.7188\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.8351 - val_loss: 0.5595 - val_accuracy: 0.7188\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8333 - val_loss: 0.5597 - val_accuracy: 0.7188\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8333 - val_loss: 0.5599 - val_accuracy: 0.7188\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.8368 - val_loss: 0.5598 - val_accuracy: 0.7188\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8351 - val_loss: 0.5599 - val_accuracy: 0.7188\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.8351 - val_loss: 0.5601 - val_accuracy: 0.7188\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3775 - accuracy: 0.8351 - val_loss: 0.5601 - val_accuracy: 0.7188\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8351 - val_loss: 0.5600 - val_accuracy: 0.7188\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8351 - val_loss: 0.5603 - val_accuracy: 0.7188\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3773 - accuracy: 0.8351 - val_loss: 0.5604 - val_accuracy: 0.7188\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3773 - accuracy: 0.8368 - val_loss: 0.5605 - val_accuracy: 0.7188\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3772 - accuracy: 0.8368 - val_loss: 0.5606 - val_accuracy: 0.7188\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3773 - accuracy: 0.8351 - val_loss: 0.5607 - val_accuracy: 0.7188\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8351 - val_loss: 0.5605 - val_accuracy: 0.7188\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3773 - accuracy: 0.8351 - val_loss: 0.5607 - val_accuracy: 0.7188\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3773 - accuracy: 0.8351 - val_loss: 0.5606 - val_accuracy: 0.7188\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3773 - accuracy: 0.8351 - val_loss: 0.5604 - val_accuracy: 0.7188\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3773 - accuracy: 0.8351 - val_loss: 0.5608 - val_accuracy: 0.7188\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8351 - val_loss: 0.5612 - val_accuracy: 0.7188\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3772 - accuracy: 0.8351 - val_loss: 0.5613 - val_accuracy: 0.7188\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3771 - accuracy: 0.8351 - val_loss: 0.5614 - val_accuracy: 0.7188\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8368 - val_loss: 0.5614 - val_accuracy: 0.7188\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8368 - val_loss: 0.5616 - val_accuracy: 0.7240\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.8351 - val_loss: 0.5622 - val_accuracy: 0.7188\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8385 - val_loss: 0.5618 - val_accuracy: 0.7240\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3767 - accuracy: 0.8351 - val_loss: 0.5619 - val_accuracy: 0.7240\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3768 - accuracy: 0.8351 - val_loss: 0.5620 - val_accuracy: 0.7240\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8351 - val_loss: 0.5623 - val_accuracy: 0.7240\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3768 - accuracy: 0.8351 - val_loss: 0.5625 - val_accuracy: 0.7240\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3765 - accuracy: 0.8351 - val_loss: 0.5623 - val_accuracy: 0.7240\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3767 - accuracy: 0.8403 - val_loss: 0.5618 - val_accuracy: 0.7240\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.3767 - accuracy: 0.8333 - val_loss: 0.5626 - val_accuracy: 0.7240\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3764 - accuracy: 0.8351 - val_loss: 0.5628 - val_accuracy: 0.7240\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3766 - accuracy: 0.8333 - val_loss: 0.5628 - val_accuracy: 0.7240\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3765 - accuracy: 0.8385 - val_loss: 0.5630 - val_accuracy: 0.7240\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.3762 - accuracy: 0.8351 - val_loss: 0.5636 - val_accuracy: 0.7188\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.3764 - accuracy: 0.8403 - val_loss: 0.5634 - val_accuracy: 0.7240\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8368 - val_loss: 0.5634 - val_accuracy: 0.7240\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8385 - val_loss: 0.5634 - val_accuracy: 0.7240\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8403 - val_loss: 0.5634 - val_accuracy: 0.7240\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8385 - val_loss: 0.5637 - val_accuracy: 0.7240\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8333 - val_loss: 0.5640 - val_accuracy: 0.7240\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3764 - accuracy: 0.8333 - val_loss: 0.5647 - val_accuracy: 0.7240\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3762 - accuracy: 0.8368 - val_loss: 0.5646 - val_accuracy: 0.7240\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8403 - val_loss: 0.5641 - val_accuracy: 0.7240\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8368 - val_loss: 0.5642 - val_accuracy: 0.7240\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8351 - val_loss: 0.5644 - val_accuracy: 0.7240\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8333 - val_loss: 0.5644 - val_accuracy: 0.7240\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.8368 - val_loss: 0.5642 - val_accuracy: 0.7240\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8368 - val_loss: 0.5649 - val_accuracy: 0.7240\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8333 - val_loss: 0.5651 - val_accuracy: 0.7240\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8333 - val_loss: 0.5654 - val_accuracy: 0.7240\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8351 - val_loss: 0.5655 - val_accuracy: 0.7240\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8420 - val_loss: 0.5651 - val_accuracy: 0.7240\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8385 - val_loss: 0.5651 - val_accuracy: 0.7240\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8368 - val_loss: 0.5655 - val_accuracy: 0.7240\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8351 - val_loss: 0.5659 - val_accuracy: 0.7240\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8385 - val_loss: 0.5659 - val_accuracy: 0.7240\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8368 - val_loss: 0.5660 - val_accuracy: 0.7240\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8385 - val_loss: 0.5657 - val_accuracy: 0.7240\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8368 - val_loss: 0.5661 - val_accuracy: 0.7240\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.8385 - val_loss: 0.5659 - val_accuracy: 0.7240\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8368 - val_loss: 0.5663 - val_accuracy: 0.7240\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.8385 - val_loss: 0.5667 - val_accuracy: 0.7240\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.8385 - val_loss: 0.5667 - val_accuracy: 0.7240\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8420 - val_loss: 0.5670 - val_accuracy: 0.7240\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.8368 - val_loss: 0.5671 - val_accuracy: 0.7240\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8403 - val_loss: 0.5676 - val_accuracy: 0.7240\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8403 - val_loss: 0.5678 - val_accuracy: 0.7240\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8385 - val_loss: 0.5680 - val_accuracy: 0.7292\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8403 - val_loss: 0.5676 - val_accuracy: 0.7240\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8420 - val_loss: 0.5673 - val_accuracy: 0.7240\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8420 - val_loss: 0.5672 - val_accuracy: 0.7240\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8385 - val_loss: 0.5675 - val_accuracy: 0.7240\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8403 - val_loss: 0.5681 - val_accuracy: 0.7240\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8403 - val_loss: 0.5679 - val_accuracy: 0.7240\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8385 - val_loss: 0.5679 - val_accuracy: 0.7240\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8368 - val_loss: 0.5682 - val_accuracy: 0.7240\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8438 - val_loss: 0.5678 - val_accuracy: 0.7240\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8333 - val_loss: 0.5684 - val_accuracy: 0.7240\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8420 - val_loss: 0.5686 - val_accuracy: 0.7240\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8403 - val_loss: 0.5691 - val_accuracy: 0.7240\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8438 - val_loss: 0.5687 - val_accuracy: 0.7240\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8420 - val_loss: 0.5687 - val_accuracy: 0.7240\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8420 - val_loss: 0.5689 - val_accuracy: 0.7240\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8403 - val_loss: 0.5690 - val_accuracy: 0.7240\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8420 - val_loss: 0.5688 - val_accuracy: 0.7240\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8385 - val_loss: 0.5695 - val_accuracy: 0.7240\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8420 - val_loss: 0.5695 - val_accuracy: 0.7240\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8403 - val_loss: 0.5692 - val_accuracy: 0.7240\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8368 - val_loss: 0.5699 - val_accuracy: 0.7240\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8420 - val_loss: 0.5701 - val_accuracy: 0.7240\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8420 - val_loss: 0.5696 - val_accuracy: 0.7240\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8420 - val_loss: 0.5698 - val_accuracy: 0.7240\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8368 - val_loss: 0.5700 - val_accuracy: 0.7292\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8420 - val_loss: 0.5700 - val_accuracy: 0.7240\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8420 - val_loss: 0.5703 - val_accuracy: 0.7240\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8420 - val_loss: 0.5706 - val_accuracy: 0.7240\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8438 - val_loss: 0.5706 - val_accuracy: 0.7240\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8385 - val_loss: 0.5710 - val_accuracy: 0.7240\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8403 - val_loss: 0.5710 - val_accuracy: 0.7240\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8420 - val_loss: 0.5708 - val_accuracy: 0.7240\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8420 - val_loss: 0.5705 - val_accuracy: 0.7240\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8420 - val_loss: 0.5711 - val_accuracy: 0.7240\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8438 - val_loss: 0.5711 - val_accuracy: 0.7240\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8438 - val_loss: 0.5708 - val_accuracy: 0.7240\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8420 - val_loss: 0.5710 - val_accuracy: 0.7240\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8420 - val_loss: 0.5713 - val_accuracy: 0.7240\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8438 - val_loss: 0.5712 - val_accuracy: 0.7240\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8385 - val_loss: 0.5716 - val_accuracy: 0.7240\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8403 - val_loss: 0.5715 - val_accuracy: 0.7240\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8351 - val_loss: 0.5721 - val_accuracy: 0.7292\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8420 - val_loss: 0.5718 - val_accuracy: 0.7240\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.8403 - val_loss: 0.5715 - val_accuracy: 0.7240\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8420 - val_loss: 0.5725 - val_accuracy: 0.7240\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8438 - val_loss: 0.5726 - val_accuracy: 0.7240\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8420 - val_loss: 0.5730 - val_accuracy: 0.7240\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8455 - val_loss: 0.5727 - val_accuracy: 0.7240\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8420 - val_loss: 0.5727 - val_accuracy: 0.7240\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8420 - val_loss: 0.5729 - val_accuracy: 0.7240\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8455 - val_loss: 0.5723 - val_accuracy: 0.7240\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8403 - val_loss: 0.5728 - val_accuracy: 0.7240\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8420 - val_loss: 0.5734 - val_accuracy: 0.7292\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8438 - val_loss: 0.5732 - val_accuracy: 0.7240\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.8438 - val_loss: 0.5730 - val_accuracy: 0.7240\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8403 - val_loss: 0.5732 - val_accuracy: 0.7240\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3741 - accuracy: 0.8368 - val_loss: 0.5740 - val_accuracy: 0.7292\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8420 - val_loss: 0.5736 - val_accuracy: 0.7292\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3739 - accuracy: 0.8438 - val_loss: 0.5735 - val_accuracy: 0.7292\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8438 - val_loss: 0.5739 - val_accuracy: 0.7240\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3737 - accuracy: 0.8385 - val_loss: 0.5745 - val_accuracy: 0.7292\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3737 - accuracy: 0.8438 - val_loss: 0.5740 - val_accuracy: 0.7240\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.8438 - val_loss: 0.5739 - val_accuracy: 0.7292\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8438 - val_loss: 0.5740 - val_accuracy: 0.7240\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8403 - val_loss: 0.5749 - val_accuracy: 0.7292\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8420 - val_loss: 0.5745 - val_accuracy: 0.7292\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8420 - val_loss: 0.5745 - val_accuracy: 0.7292\n"
          ]
        }
      ],
      "source": [
        "\n",
        "new_model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = new_model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)\n"
      ],
      "id": "licFq_goGy3g"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLX028PCJWo_"
      },
      "outputs": [],
      "source": [
        "#y_pred_class_nn = new_model.predict(X_test_norm)\n",
        "#y_pred_prob_nn = np.argmax(y_pred_class_nn, axis=1)"
      ],
      "id": "YLX028PCJWo_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1XeDtfdUpKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebaf3970-c935-47f9-defa-83a3ceb29e2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_prob_nnew = new_model.predict(X_test_norm)\n",
        "y_pred_class_nnew = (y_pred_prob_nnew > 0.5).astype('int32')"
      ],
      "id": "m1XeDtfdUpKY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRtOZnfJQR8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ea585d-cdab-45b1-b073-24bf6b936af8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "y_pred_class_nnew[:10]"
      ],
      "id": "gRtOZnfJQR8J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hOwBtVlQUX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01801373-57f9-483a-f333-afbe4ab95536"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.84498954],\n",
              "       [0.54498696],\n",
              "       [0.37894908],\n",
              "       [0.09194799],\n",
              "       [0.14860062],\n",
              "       [0.7145625 ],\n",
              "       [0.00742441],\n",
              "       [0.4904466 ],\n",
              "       [0.85841143],\n",
              "       [0.19457255]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "y_pred_prob_nnew[:10]"
      ],
      "id": "2hOwBtVlQUX4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk-XDGyKJ7JY"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, new_model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(new_model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ],
      "id": "Vk-XDGyKJ7JY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP-SYIui5-QH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "outputId": "18b765a5-f744-48b7-b851-1863431a7f59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.729\n",
            "roc-auc is 0.784\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nnew)))#y_pred_prob_nnew\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nnew)))#y_pred_prob_nnew\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nnew, 'NN')"
      ],
      "id": "AP-SYIui5-QH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This model shows worst result even though we've used more than 1 hidden layer, The model shows a moderate level of accuracy, and The ROC-AUC score of 0.801 suggests a satisfactory discrimination ability, indicating that the model performs reasonably well in distinguishing between positive and negative cases."
      ],
      "metadata": {
        "id": "XfaVfvzJ9gfO"
      },
      "id": "XfaVfvzJ9gfO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZVSMMLOO-4x"
      },
      "outputs": [],
      "source": [
        "#print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_nn)))#y_pred_class_nn\n",
        "#print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_nn)))#y_pred_prob_nn\n",
        "\n",
        "#plot_roc(y_test, y_pred_prob_nn, 'NN')"
      ],
      "id": "qZVSMMLOO-4x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esx63sz8LQeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd2e658-831f-499a-8aea-7d6abb04f825"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "run_hist_2.history.keys()"
      ],
      "id": "esx63sz8LQeg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQpzqLw0LTV5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "4dd34386-2eb0-4139-f55b-b03df5149f77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cf71b655600>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "id": "eQpzqLw0LTV5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning rate = 001, epochs = 800,"
      ],
      "metadata": {
        "id": "YNJrLieD_PBv"
      },
      "id": "YNJrLieD_PBv"
    },
    {
      "cell_type": "code",
      "source": [
        "new_model2 = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "-sUvW2538MEj"
      },
      "id": "-sUvW2538MEj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_model2.compile(SGD(lr = .001), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_3 = new_model2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=800)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbrFS2XM8Q_1",
        "outputId": "76a25815-2c3d-4521-bae1-e3217a459e79"
      },
      "id": "XbrFS2XM8Q_1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "18/18 [==============================] - 1s 14ms/step - loss: 0.7897 - accuracy: 0.3715 - val_loss: 0.7313 - val_accuracy: 0.4323\n",
            "Epoch 2/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7428 - accuracy: 0.4115 - val_loss: 0.7004 - val_accuracy: 0.5104\n",
            "Epoch 3/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7134 - accuracy: 0.5208 - val_loss: 0.6812 - val_accuracy: 0.5833\n",
            "Epoch 4/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6950 - accuracy: 0.5938 - val_loss: 0.6704 - val_accuracy: 0.6250\n",
            "Epoch 5/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.6372 - val_loss: 0.6627 - val_accuracy: 0.6510\n",
            "Epoch 6/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6738 - accuracy: 0.6562 - val_loss: 0.6565 - val_accuracy: 0.6510\n",
            "Epoch 7/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6662 - accuracy: 0.6753 - val_loss: 0.6510 - val_accuracy: 0.6562\n",
            "Epoch 8/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.6771 - val_loss: 0.6458 - val_accuracy: 0.6615\n",
            "Epoch 9/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6875 - val_loss: 0.6411 - val_accuracy: 0.6562\n",
            "Epoch 10/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.6979 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
            "Epoch 11/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.7049 - val_loss: 0.6324 - val_accuracy: 0.6719\n",
            "Epoch 12/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.7066 - val_loss: 0.6284 - val_accuracy: 0.6719\n",
            "Epoch 13/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7101 - val_loss: 0.6245 - val_accuracy: 0.6823\n",
            "Epoch 14/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.7118 - val_loss: 0.6208 - val_accuracy: 0.6927\n",
            "Epoch 15/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.7135 - val_loss: 0.6171 - val_accuracy: 0.6979\n",
            "Epoch 16/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6216 - accuracy: 0.7153 - val_loss: 0.6135 - val_accuracy: 0.7031\n",
            "Epoch 17/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.7188 - val_loss: 0.6098 - val_accuracy: 0.7031\n",
            "Epoch 18/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.7205 - val_loss: 0.6062 - val_accuracy: 0.7083\n",
            "Epoch 19/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.7188 - val_loss: 0.6026 - val_accuracy: 0.7083\n",
            "Epoch 20/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.7170 - val_loss: 0.5989 - val_accuracy: 0.7188\n",
            "Epoch 21/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.7135 - val_loss: 0.5952 - val_accuracy: 0.7188\n",
            "Epoch 22/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.7135 - val_loss: 0.5915 - val_accuracy: 0.7188\n",
            "Epoch 23/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7170 - val_loss: 0.5878 - val_accuracy: 0.7240\n",
            "Epoch 24/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.7240 - val_loss: 0.5841 - val_accuracy: 0.7292\n",
            "Epoch 25/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.7240 - val_loss: 0.5803 - val_accuracy: 0.7292\n",
            "Epoch 26/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.7292 - val_loss: 0.5765 - val_accuracy: 0.7292\n",
            "Epoch 27/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.7257 - val_loss: 0.5727 - val_accuracy: 0.7240\n",
            "Epoch 28/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7257 - val_loss: 0.5689 - val_accuracy: 0.7188\n",
            "Epoch 29/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5699 - accuracy: 0.7326 - val_loss: 0.5651 - val_accuracy: 0.7240\n",
            "Epoch 30/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.7326 - val_loss: 0.5613 - val_accuracy: 0.7292\n",
            "Epoch 31/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.7396 - val_loss: 0.5574 - val_accuracy: 0.7344\n",
            "Epoch 32/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.7396 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
            "Epoch 33/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7448 - val_loss: 0.5497 - val_accuracy: 0.7396\n",
            "Epoch 34/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.7465 - val_loss: 0.5461 - val_accuracy: 0.7396\n",
            "Epoch 35/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.7483 - val_loss: 0.5427 - val_accuracy: 0.7448\n",
            "Epoch 36/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7465 - val_loss: 0.5396 - val_accuracy: 0.7448\n",
            "Epoch 37/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7483 - val_loss: 0.5366 - val_accuracy: 0.7448\n",
            "Epoch 38/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7483 - val_loss: 0.5336 - val_accuracy: 0.7448\n",
            "Epoch 39/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7483 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
            "Epoch 40/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7483 - val_loss: 0.5283 - val_accuracy: 0.7500\n",
            "Epoch 41/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7483 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 42/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.7517 - val_loss: 0.5237 - val_accuracy: 0.7552\n",
            "Epoch 43/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7517 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
            "Epoch 44/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7517 - val_loss: 0.5196 - val_accuracy: 0.7552\n",
            "Epoch 45/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7535 - val_loss: 0.5177 - val_accuracy: 0.7552\n",
            "Epoch 46/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7535 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
            "Epoch 47/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7535 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
            "Epoch 48/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7500 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
            "Epoch 49/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7517 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
            "Epoch 50/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5047 - accuracy: 0.7535 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
            "Epoch 51/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7587 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
            "Epoch 52/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7587 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
            "Epoch 53/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7622 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
            "Epoch 54/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7622 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 55/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7622 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 56/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7639 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
            "Epoch 57/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7656 - val_loss: 0.4986 - val_accuracy: 0.7760\n",
            "Epoch 58/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7622 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
            "Epoch 59/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7639 - val_loss: 0.4960 - val_accuracy: 0.7812\n",
            "Epoch 60/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.7604 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 61/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7639 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 62/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7674 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
            "Epoch 63/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7674 - val_loss: 0.4916 - val_accuracy: 0.7812\n",
            "Epoch 64/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7674 - val_loss: 0.4905 - val_accuracy: 0.7865\n",
            "Epoch 65/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7674 - val_loss: 0.4896 - val_accuracy: 0.7865\n",
            "Epoch 66/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7691 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
            "Epoch 67/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7726 - val_loss: 0.4879 - val_accuracy: 0.7917\n",
            "Epoch 68/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7743 - val_loss: 0.4871 - val_accuracy: 0.7917\n",
            "Epoch 69/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7760 - val_loss: 0.4863 - val_accuracy: 0.7969\n",
            "Epoch 70/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7795 - val_loss: 0.4857 - val_accuracy: 0.7917\n",
            "Epoch 71/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7795 - val_loss: 0.4849 - val_accuracy: 0.7917\n",
            "Epoch 72/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7812 - val_loss: 0.4843 - val_accuracy: 0.7917\n",
            "Epoch 73/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7812 - val_loss: 0.4836 - val_accuracy: 0.7969\n",
            "Epoch 74/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7847 - val_loss: 0.4831 - val_accuracy: 0.7969\n",
            "Epoch 75/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7830 - val_loss: 0.4826 - val_accuracy: 0.7969\n",
            "Epoch 76/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7847 - val_loss: 0.4822 - val_accuracy: 0.7969\n",
            "Epoch 77/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7812 - val_loss: 0.4818 - val_accuracy: 0.7917\n",
            "Epoch 78/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7830 - val_loss: 0.4814 - val_accuracy: 0.7917\n",
            "Epoch 79/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7830 - val_loss: 0.4810 - val_accuracy: 0.7917\n",
            "Epoch 80/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7830 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 81/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 82/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7830 - val_loss: 0.4800 - val_accuracy: 0.7865\n",
            "Epoch 83/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4797 - val_accuracy: 0.7865\n",
            "Epoch 84/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 85/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 86/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 87/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7847 - val_loss: 0.4789 - val_accuracy: 0.7865\n",
            "Epoch 88/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.7847 - val_loss: 0.4787 - val_accuracy: 0.7865\n",
            "Epoch 89/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7847 - val_loss: 0.4785 - val_accuracy: 0.7812\n",
            "Epoch 90/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4783 - val_accuracy: 0.7812\n",
            "Epoch 91/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7865 - val_loss: 0.4782 - val_accuracy: 0.7812\n",
            "Epoch 92/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4781 - val_accuracy: 0.7760\n",
            "Epoch 93/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4780 - val_accuracy: 0.7760\n",
            "Epoch 94/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.7899 - val_loss: 0.4779 - val_accuracy: 0.7760\n",
            "Epoch 95/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7899 - val_loss: 0.4778 - val_accuracy: 0.7760\n",
            "Epoch 96/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7899 - val_loss: 0.4778 - val_accuracy: 0.7708\n",
            "Epoch 97/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7899 - val_loss: 0.4777 - val_accuracy: 0.7708\n",
            "Epoch 98/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7899 - val_loss: 0.4777 - val_accuracy: 0.7708\n",
            "Epoch 99/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7899 - val_loss: 0.4776 - val_accuracy: 0.7708\n",
            "Epoch 100/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7899 - val_loss: 0.4775 - val_accuracy: 0.7760\n",
            "Epoch 101/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4589 - accuracy: 0.7882 - val_loss: 0.4774 - val_accuracy: 0.7760\n",
            "Epoch 102/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7865 - val_loss: 0.4773 - val_accuracy: 0.7760\n",
            "Epoch 103/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7847 - val_loss: 0.4773 - val_accuracy: 0.7760\n",
            "Epoch 104/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.7847 - val_loss: 0.4772 - val_accuracy: 0.7812\n",
            "Epoch 105/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.7847 - val_loss: 0.4771 - val_accuracy: 0.7812\n",
            "Epoch 106/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7847 - val_loss: 0.4770 - val_accuracy: 0.7760\n",
            "Epoch 107/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.4769 - val_accuracy: 0.7708\n",
            "Epoch 108/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7847 - val_loss: 0.4768 - val_accuracy: 0.7708\n",
            "Epoch 109/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7847 - val_loss: 0.4767 - val_accuracy: 0.7708\n",
            "Epoch 110/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.7830 - val_loss: 0.4767 - val_accuracy: 0.7760\n",
            "Epoch 111/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4767 - val_accuracy: 0.7812\n",
            "Epoch 112/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.7830 - val_loss: 0.4766 - val_accuracy: 0.7812\n",
            "Epoch 113/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7830 - val_loss: 0.4766 - val_accuracy: 0.7812\n",
            "Epoch 114/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7847 - val_loss: 0.4765 - val_accuracy: 0.7812\n",
            "Epoch 115/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7830 - val_loss: 0.4764 - val_accuracy: 0.7812\n",
            "Epoch 116/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.7847 - val_loss: 0.4764 - val_accuracy: 0.7812\n",
            "Epoch 117/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7847 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
            "Epoch 118/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7812 - val_loss: 0.4763 - val_accuracy: 0.7760\n",
            "Epoch 119/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.4762 - val_accuracy: 0.7760\n",
            "Epoch 120/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7812 - val_loss: 0.4761 - val_accuracy: 0.7760\n",
            "Epoch 121/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7812 - val_loss: 0.4760 - val_accuracy: 0.7760\n",
            "Epoch 122/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7795 - val_loss: 0.4759 - val_accuracy: 0.7760\n",
            "Epoch 123/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7778 - val_loss: 0.4759 - val_accuracy: 0.7760\n",
            "Epoch 124/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7795 - val_loss: 0.4758 - val_accuracy: 0.7760\n",
            "Epoch 125/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7778 - val_loss: 0.4758 - val_accuracy: 0.7760\n",
            "Epoch 126/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7812 - val_loss: 0.4757 - val_accuracy: 0.7760\n",
            "Epoch 127/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7812 - val_loss: 0.4757 - val_accuracy: 0.7760\n",
            "Epoch 128/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7812 - val_loss: 0.4756 - val_accuracy: 0.7760\n",
            "Epoch 129/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7795 - val_loss: 0.4756 - val_accuracy: 0.7760\n",
            "Epoch 130/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7812 - val_loss: 0.4755 - val_accuracy: 0.7760\n",
            "Epoch 131/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7795 - val_loss: 0.4754 - val_accuracy: 0.7760\n",
            "Epoch 132/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7795 - val_loss: 0.4754 - val_accuracy: 0.7760\n",
            "Epoch 133/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.4754 - val_accuracy: 0.7760\n",
            "Epoch 134/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7760\n",
            "Epoch 135/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7778 - val_loss: 0.4754 - val_accuracy: 0.7760\n",
            "Epoch 136/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7760\n",
            "Epoch 137/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7795 - val_loss: 0.4754 - val_accuracy: 0.7760\n",
            "Epoch 138/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7778 - val_loss: 0.4754 - val_accuracy: 0.7760\n",
            "Epoch 139/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.4754 - val_accuracy: 0.7760\n",
            "Epoch 140/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7795 - val_loss: 0.4754 - val_accuracy: 0.7760\n",
            "Epoch 141/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7760\n",
            "Epoch 142/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 143/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 144/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 145/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 146/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 147/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 148/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7812 - val_loss: 0.4755 - val_accuracy: 0.7812\n",
            "Epoch 149/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.4755 - val_accuracy: 0.7812\n",
            "Epoch 150/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7812 - val_loss: 0.4755 - val_accuracy: 0.7812\n",
            "Epoch 151/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7795 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 152/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7812 - val_loss: 0.4755 - val_accuracy: 0.7812\n",
            "Epoch 153/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 154/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 155/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 156/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7812 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 157/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7847 - val_loss: 0.4754 - val_accuracy: 0.7812\n",
            "Epoch 158/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7812 - val_loss: 0.4753 - val_accuracy: 0.7812\n",
            "Epoch 159/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.7830 - val_loss: 0.4753 - val_accuracy: 0.7812\n",
            "Epoch 160/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7812 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 161/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 162/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 163/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7812 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 164/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7812 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 165/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7812 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 166/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7795 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 167/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7795 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 168/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7795 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 169/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 170/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 171/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7795 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 172/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7795 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 173/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7795 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 174/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7760 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 175/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7778 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 176/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7795 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 177/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7812 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 178/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 179/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7795 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 180/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7778 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 181/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7760 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 182/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7795 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 183/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7778 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 184/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7812 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 185/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7795 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 186/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7795 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 187/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7778 - val_loss: 0.4752 - val_accuracy: 0.7812\n",
            "Epoch 188/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7778 - val_loss: 0.4751 - val_accuracy: 0.7760\n",
            "Epoch 189/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7812 - val_loss: 0.4752 - val_accuracy: 0.7760\n",
            "Epoch 190/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7778 - val_loss: 0.4751 - val_accuracy: 0.7812\n",
            "Epoch 191/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7795 - val_loss: 0.4751 - val_accuracy: 0.7760\n",
            "Epoch 192/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.4751 - val_accuracy: 0.7760\n",
            "Epoch 193/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7795 - val_loss: 0.4752 - val_accuracy: 0.7760\n",
            "Epoch 194/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7778 - val_loss: 0.4751 - val_accuracy: 0.7760\n",
            "Epoch 195/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.4752 - val_accuracy: 0.7760\n",
            "Epoch 196/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7778 - val_loss: 0.4752 - val_accuracy: 0.7760\n",
            "Epoch 197/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7795 - val_loss: 0.4752 - val_accuracy: 0.7708\n",
            "Epoch 198/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7795 - val_loss: 0.4753 - val_accuracy: 0.7708\n",
            "Epoch 199/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7795 - val_loss: 0.4753 - val_accuracy: 0.7708\n",
            "Epoch 200/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7743 - val_loss: 0.4752 - val_accuracy: 0.7760\n",
            "Epoch 201/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.4753 - val_accuracy: 0.7708\n",
            "Epoch 202/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7795 - val_loss: 0.4753 - val_accuracy: 0.7708\n",
            "Epoch 203/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7778 - val_loss: 0.4753 - val_accuracy: 0.7708\n",
            "Epoch 204/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7778 - val_loss: 0.4752 - val_accuracy: 0.7708\n",
            "Epoch 205/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7795 - val_loss: 0.4753 - val_accuracy: 0.7708\n",
            "Epoch 206/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7778 - val_loss: 0.4752 - val_accuracy: 0.7708\n",
            "Epoch 207/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7795 - val_loss: 0.4752 - val_accuracy: 0.7708\n",
            "Epoch 208/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7795 - val_loss: 0.4752 - val_accuracy: 0.7708\n",
            "Epoch 209/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.4753 - val_accuracy: 0.7708\n",
            "Epoch 210/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7778 - val_loss: 0.4753 - val_accuracy: 0.7708\n",
            "Epoch 211/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7795 - val_loss: 0.4753 - val_accuracy: 0.7708\n",
            "Epoch 212/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7778 - val_loss: 0.4754 - val_accuracy: 0.7708\n",
            "Epoch 213/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7795 - val_loss: 0.4753 - val_accuracy: 0.7708\n",
            "Epoch 214/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7812 - val_loss: 0.4753 - val_accuracy: 0.7708\n",
            "Epoch 215/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7795 - val_loss: 0.4753 - val_accuracy: 0.7708\n",
            "Epoch 216/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7778 - val_loss: 0.4754 - val_accuracy: 0.7708\n",
            "Epoch 217/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7795 - val_loss: 0.4754 - val_accuracy: 0.7708\n",
            "Epoch 218/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7795 - val_loss: 0.4756 - val_accuracy: 0.7708\n",
            "Epoch 219/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.4756 - val_accuracy: 0.7708\n",
            "Epoch 220/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7795 - val_loss: 0.4756 - val_accuracy: 0.7708\n",
            "Epoch 221/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7795 - val_loss: 0.4757 - val_accuracy: 0.7708\n",
            "Epoch 222/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7778 - val_loss: 0.4757 - val_accuracy: 0.7708\n",
            "Epoch 223/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7778 - val_loss: 0.4757 - val_accuracy: 0.7656\n",
            "Epoch 224/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7795 - val_loss: 0.4758 - val_accuracy: 0.7656\n",
            "Epoch 225/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7778 - val_loss: 0.4759 - val_accuracy: 0.7656\n",
            "Epoch 226/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7778 - val_loss: 0.4759 - val_accuracy: 0.7656\n",
            "Epoch 227/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7778 - val_loss: 0.4760 - val_accuracy: 0.7656\n",
            "Epoch 228/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7778 - val_loss: 0.4760 - val_accuracy: 0.7656\n",
            "Epoch 229/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7760 - val_loss: 0.4761 - val_accuracy: 0.7656\n",
            "Epoch 230/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.4762 - val_accuracy: 0.7656\n",
            "Epoch 231/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7778 - val_loss: 0.4762 - val_accuracy: 0.7656\n",
            "Epoch 232/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7812 - val_loss: 0.4762 - val_accuracy: 0.7656\n",
            "Epoch 233/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7760 - val_loss: 0.4763 - val_accuracy: 0.7656\n",
            "Epoch 234/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7760 - val_loss: 0.4763 - val_accuracy: 0.7656\n",
            "Epoch 235/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7760 - val_loss: 0.4764 - val_accuracy: 0.7656\n",
            "Epoch 236/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7795 - val_loss: 0.4764 - val_accuracy: 0.7656\n",
            "Epoch 237/800\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7795 - val_loss: 0.4765 - val_accuracy: 0.7656\n",
            "Epoch 238/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7812 - val_loss: 0.4766 - val_accuracy: 0.7656\n",
            "Epoch 239/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.7778 - val_loss: 0.4766 - val_accuracy: 0.7656\n",
            "Epoch 240/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7795 - val_loss: 0.4767 - val_accuracy: 0.7656\n",
            "Epoch 241/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7812 - val_loss: 0.4767 - val_accuracy: 0.7656\n",
            "Epoch 242/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7778 - val_loss: 0.4767 - val_accuracy: 0.7656\n",
            "Epoch 243/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7795 - val_loss: 0.4768 - val_accuracy: 0.7656\n",
            "Epoch 244/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7778 - val_loss: 0.4769 - val_accuracy: 0.7656\n",
            "Epoch 245/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.4769 - val_accuracy: 0.7656\n",
            "Epoch 246/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7795 - val_loss: 0.4770 - val_accuracy: 0.7656\n",
            "Epoch 247/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7795 - val_loss: 0.4770 - val_accuracy: 0.7656\n",
            "Epoch 248/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7795 - val_loss: 0.4771 - val_accuracy: 0.7656\n",
            "Epoch 249/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7830 - val_loss: 0.4771 - val_accuracy: 0.7656\n",
            "Epoch 250/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.7812 - val_loss: 0.4771 - val_accuracy: 0.7656\n",
            "Epoch 251/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.4772 - val_accuracy: 0.7656\n",
            "Epoch 252/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.4772 - val_accuracy: 0.7656\n",
            "Epoch 253/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.4772 - val_accuracy: 0.7656\n",
            "Epoch 254/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7812 - val_loss: 0.4772 - val_accuracy: 0.7656\n",
            "Epoch 255/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.4772 - val_accuracy: 0.7656\n",
            "Epoch 256/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.4773 - val_accuracy: 0.7656\n",
            "Epoch 257/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.4773 - val_accuracy: 0.7656\n",
            "Epoch 258/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7812 - val_loss: 0.4773 - val_accuracy: 0.7656\n",
            "Epoch 259/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.4773 - val_accuracy: 0.7656\n",
            "Epoch 260/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.7812 - val_loss: 0.4773 - val_accuracy: 0.7656\n",
            "Epoch 261/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7812 - val_loss: 0.4774 - val_accuracy: 0.7656\n",
            "Epoch 262/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7812 - val_loss: 0.4774 - val_accuracy: 0.7656\n",
            "Epoch 263/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.4774 - val_accuracy: 0.7656\n",
            "Epoch 264/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.7830 - val_loss: 0.4775 - val_accuracy: 0.7656\n",
            "Epoch 265/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7830 - val_loss: 0.4775 - val_accuracy: 0.7656\n",
            "Epoch 266/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7812 - val_loss: 0.4775 - val_accuracy: 0.7656\n",
            "Epoch 267/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.4776 - val_accuracy: 0.7656\n",
            "Epoch 268/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.7830 - val_loss: 0.4776 - val_accuracy: 0.7656\n",
            "Epoch 269/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7830 - val_loss: 0.4777 - val_accuracy: 0.7656\n",
            "Epoch 270/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.7795 - val_loss: 0.4777 - val_accuracy: 0.7656\n",
            "Epoch 271/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7795 - val_loss: 0.4777 - val_accuracy: 0.7656\n",
            "Epoch 272/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.4778 - val_accuracy: 0.7656\n",
            "Epoch 273/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.7812 - val_loss: 0.4779 - val_accuracy: 0.7656\n",
            "Epoch 274/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.7830 - val_loss: 0.4779 - val_accuracy: 0.7656\n",
            "Epoch 275/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7830 - val_loss: 0.4780 - val_accuracy: 0.7656\n",
            "Epoch 276/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.4781 - val_accuracy: 0.7656\n",
            "Epoch 277/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7795 - val_loss: 0.4781 - val_accuracy: 0.7656\n",
            "Epoch 278/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.7812 - val_loss: 0.4782 - val_accuracy: 0.7656\n",
            "Epoch 279/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.7847 - val_loss: 0.4782 - val_accuracy: 0.7656\n",
            "Epoch 280/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4393 - accuracy: 0.7830 - val_loss: 0.4783 - val_accuracy: 0.7656\n",
            "Epoch 281/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.7830 - val_loss: 0.4783 - val_accuracy: 0.7656\n",
            "Epoch 282/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7847 - val_loss: 0.4783 - val_accuracy: 0.7656\n",
            "Epoch 283/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.4784 - val_accuracy: 0.7656\n",
            "Epoch 284/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7795 - val_loss: 0.4784 - val_accuracy: 0.7656\n",
            "Epoch 285/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.4785 - val_accuracy: 0.7656\n",
            "Epoch 286/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7847 - val_loss: 0.4785 - val_accuracy: 0.7656\n",
            "Epoch 287/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.4784 - val_accuracy: 0.7656\n",
            "Epoch 288/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7812 - val_loss: 0.4785 - val_accuracy: 0.7656\n",
            "Epoch 289/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7795 - val_loss: 0.4785 - val_accuracy: 0.7656\n",
            "Epoch 290/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.4786 - val_accuracy: 0.7656\n",
            "Epoch 291/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.4785 - val_accuracy: 0.7656\n",
            "Epoch 292/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7830 - val_loss: 0.4786 - val_accuracy: 0.7656\n",
            "Epoch 293/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.4786 - val_accuracy: 0.7656\n",
            "Epoch 294/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7778 - val_loss: 0.4786 - val_accuracy: 0.7656\n",
            "Epoch 295/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7795 - val_loss: 0.4787 - val_accuracy: 0.7656\n",
            "Epoch 296/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7812 - val_loss: 0.4788 - val_accuracy: 0.7656\n",
            "Epoch 297/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.4789 - val_accuracy: 0.7656\n",
            "Epoch 298/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7795 - val_loss: 0.4790 - val_accuracy: 0.7656\n",
            "Epoch 299/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.4790 - val_accuracy: 0.7656\n",
            "Epoch 300/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7795 - val_loss: 0.4790 - val_accuracy: 0.7656\n",
            "Epoch 301/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7830 - val_loss: 0.4790 - val_accuracy: 0.7656\n",
            "Epoch 302/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7795 - val_loss: 0.4789 - val_accuracy: 0.7656\n",
            "Epoch 303/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.4788 - val_accuracy: 0.7656\n",
            "Epoch 304/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.4787 - val_accuracy: 0.7656\n",
            "Epoch 305/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7795 - val_loss: 0.4787 - val_accuracy: 0.7656\n",
            "Epoch 306/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7795 - val_loss: 0.4787 - val_accuracy: 0.7656\n",
            "Epoch 307/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7795 - val_loss: 0.4786 - val_accuracy: 0.7656\n",
            "Epoch 308/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7795 - val_loss: 0.4787 - val_accuracy: 0.7656\n",
            "Epoch 309/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7795 - val_loss: 0.4787 - val_accuracy: 0.7656\n",
            "Epoch 310/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7795 - val_loss: 0.4786 - val_accuracy: 0.7708\n",
            "Epoch 311/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7795 - val_loss: 0.4786 - val_accuracy: 0.7708\n",
            "Epoch 312/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7795 - val_loss: 0.4786 - val_accuracy: 0.7656\n",
            "Epoch 313/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7795 - val_loss: 0.4786 - val_accuracy: 0.7656\n",
            "Epoch 314/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7795 - val_loss: 0.4785 - val_accuracy: 0.7708\n",
            "Epoch 315/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.4785 - val_accuracy: 0.7708\n",
            "Epoch 316/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7778 - val_loss: 0.4785 - val_accuracy: 0.7708\n",
            "Epoch 317/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7795 - val_loss: 0.4785 - val_accuracy: 0.7708\n",
            "Epoch 318/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7812 - val_loss: 0.4785 - val_accuracy: 0.7708\n",
            "Epoch 319/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7795 - val_loss: 0.4784 - val_accuracy: 0.7708\n",
            "Epoch 320/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7795 - val_loss: 0.4784 - val_accuracy: 0.7708\n",
            "Epoch 321/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7795 - val_loss: 0.4783 - val_accuracy: 0.7708\n",
            "Epoch 322/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7795 - val_loss: 0.4783 - val_accuracy: 0.7760\n",
            "Epoch 323/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7795 - val_loss: 0.4783 - val_accuracy: 0.7760\n",
            "Epoch 324/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.4784 - val_accuracy: 0.7760\n",
            "Epoch 325/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.4784 - val_accuracy: 0.7760\n",
            "Epoch 326/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7795 - val_loss: 0.4784 - val_accuracy: 0.7760\n",
            "Epoch 327/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7795 - val_loss: 0.4784 - val_accuracy: 0.7760\n",
            "Epoch 328/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7795 - val_loss: 0.4785 - val_accuracy: 0.7760\n",
            "Epoch 329/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7778 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
            "Epoch 330/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7795 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
            "Epoch 331/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
            "Epoch 332/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7778 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
            "Epoch 333/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7812 - val_loss: 0.4786 - val_accuracy: 0.7760\n",
            "Epoch 334/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7795 - val_loss: 0.4787 - val_accuracy: 0.7760\n",
            "Epoch 335/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
            "Epoch 336/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
            "Epoch 337/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.4789 - val_accuracy: 0.7760\n",
            "Epoch 338/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.4790 - val_accuracy: 0.7760\n",
            "Epoch 339/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.4791 - val_accuracy: 0.7760\n",
            "Epoch 340/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7812 - val_loss: 0.4792 - val_accuracy: 0.7760\n",
            "Epoch 341/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7795 - val_loss: 0.4792 - val_accuracy: 0.7760\n",
            "Epoch 342/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.4792 - val_accuracy: 0.7760\n",
            "Epoch 343/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.7795 - val_loss: 0.4793 - val_accuracy: 0.7760\n",
            "Epoch 344/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.4793 - val_accuracy: 0.7760\n",
            "Epoch 345/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7795 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
            "Epoch 346/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7812 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
            "Epoch 347/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7795 - val_loss: 0.4794 - val_accuracy: 0.7760\n",
            "Epoch 348/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7812 - val_loss: 0.4795 - val_accuracy: 0.7760\n",
            "Epoch 349/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.4796 - val_accuracy: 0.7760\n",
            "Epoch 350/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.4797 - val_accuracy: 0.7760\n",
            "Epoch 351/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.4797 - val_accuracy: 0.7760\n",
            "Epoch 352/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7812 - val_loss: 0.4797 - val_accuracy: 0.7760\n",
            "Epoch 353/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.4798 - val_accuracy: 0.7760\n",
            "Epoch 354/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7812 - val_loss: 0.4798 - val_accuracy: 0.7760\n",
            "Epoch 355/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.4799 - val_accuracy: 0.7760\n",
            "Epoch 356/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7812 - val_loss: 0.4799 - val_accuracy: 0.7760\n",
            "Epoch 357/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7812 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
            "Epoch 358/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.7812 - val_loss: 0.4799 - val_accuracy: 0.7708\n",
            "Epoch 359/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.4800 - val_accuracy: 0.7760\n",
            "Epoch 360/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
            "Epoch 361/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
            "Epoch 362/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7812 - val_loss: 0.4801 - val_accuracy: 0.7708\n",
            "Epoch 363/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7812 - val_loss: 0.4802 - val_accuracy: 0.7760\n",
            "Epoch 364/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7812 - val_loss: 0.4802 - val_accuracy: 0.7760\n",
            "Epoch 365/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7812 - val_loss: 0.4803 - val_accuracy: 0.7760\n",
            "Epoch 366/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7812 - val_loss: 0.4803 - val_accuracy: 0.7708\n",
            "Epoch 367/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7812 - val_loss: 0.4804 - val_accuracy: 0.7708\n",
            "Epoch 368/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.4805 - val_accuracy: 0.7708\n",
            "Epoch 369/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4805 - val_accuracy: 0.7708\n",
            "Epoch 370/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4806 - val_accuracy: 0.7708\n",
            "Epoch 371/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.4807 - val_accuracy: 0.7760\n",
            "Epoch 372/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.4808 - val_accuracy: 0.7760\n",
            "Epoch 373/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.4808 - val_accuracy: 0.7760\n",
            "Epoch 374/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.4808 - val_accuracy: 0.7760\n",
            "Epoch 375/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.4810 - val_accuracy: 0.7760\n",
            "Epoch 376/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4811 - val_accuracy: 0.7760\n",
            "Epoch 377/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.4811 - val_accuracy: 0.7760\n",
            "Epoch 378/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4812 - val_accuracy: 0.7760\n",
            "Epoch 379/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.4813 - val_accuracy: 0.7760\n",
            "Epoch 380/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.4813 - val_accuracy: 0.7760\n",
            "Epoch 381/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.4814 - val_accuracy: 0.7760\n",
            "Epoch 382/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.4815 - val_accuracy: 0.7760\n",
            "Epoch 383/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7882 - val_loss: 0.4816 - val_accuracy: 0.7760\n",
            "Epoch 384/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.4816 - val_accuracy: 0.7760\n",
            "Epoch 385/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4817 - val_accuracy: 0.7760\n",
            "Epoch 386/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.4817 - val_accuracy: 0.7760\n",
            "Epoch 387/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.4818 - val_accuracy: 0.7760\n",
            "Epoch 388/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.4818 - val_accuracy: 0.7760\n",
            "Epoch 389/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.4819 - val_accuracy: 0.7760\n",
            "Epoch 390/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.4819 - val_accuracy: 0.7760\n",
            "Epoch 391/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.4820 - val_accuracy: 0.7760\n",
            "Epoch 392/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7865 - val_loss: 0.4821 - val_accuracy: 0.7760\n",
            "Epoch 393/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7882 - val_loss: 0.4822 - val_accuracy: 0.7760\n",
            "Epoch 394/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7865 - val_loss: 0.4823 - val_accuracy: 0.7760\n",
            "Epoch 395/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.4823 - val_accuracy: 0.7760\n",
            "Epoch 396/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.4823 - val_accuracy: 0.7760\n",
            "Epoch 397/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.4824 - val_accuracy: 0.7760\n",
            "Epoch 398/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7760\n",
            "Epoch 399/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.4825 - val_accuracy: 0.7760\n",
            "Epoch 400/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.4826 - val_accuracy: 0.7760\n",
            "Epoch 401/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.4826 - val_accuracy: 0.7760\n",
            "Epoch 402/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7882 - val_loss: 0.4826 - val_accuracy: 0.7760\n",
            "Epoch 403/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7882 - val_loss: 0.4826 - val_accuracy: 0.7760\n",
            "Epoch 404/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
            "Epoch 405/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.4828 - val_accuracy: 0.7760\n",
            "Epoch 406/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.4829 - val_accuracy: 0.7760\n",
            "Epoch 407/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.7882 - val_loss: 0.4830 - val_accuracy: 0.7760\n",
            "Epoch 408/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.4831 - val_accuracy: 0.7760\n",
            "Epoch 409/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.4832 - val_accuracy: 0.7760\n",
            "Epoch 410/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.4832 - val_accuracy: 0.7760\n",
            "Epoch 411/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.4833 - val_accuracy: 0.7760\n",
            "Epoch 412/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.4834 - val_accuracy: 0.7708\n",
            "Epoch 413/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4834 - val_accuracy: 0.7760\n",
            "Epoch 414/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.4835 - val_accuracy: 0.7708\n",
            "Epoch 415/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
            "Epoch 416/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.7882 - val_loss: 0.4836 - val_accuracy: 0.7708\n",
            "Epoch 417/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
            "Epoch 418/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.4837 - val_accuracy: 0.7708\n",
            "Epoch 419/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.7882 - val_loss: 0.4838 - val_accuracy: 0.7708\n",
            "Epoch 420/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.4839 - val_accuracy: 0.7708\n",
            "Epoch 421/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.4840 - val_accuracy: 0.7708\n",
            "Epoch 422/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.4841 - val_accuracy: 0.7708\n",
            "Epoch 423/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7882 - val_loss: 0.4842 - val_accuracy: 0.7708\n",
            "Epoch 424/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
            "Epoch 425/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7882 - val_loss: 0.4843 - val_accuracy: 0.7708\n",
            "Epoch 426/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.7882 - val_loss: 0.4844 - val_accuracy: 0.7708\n",
            "Epoch 427/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
            "Epoch 428/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.4845 - val_accuracy: 0.7708\n",
            "Epoch 429/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
            "Epoch 430/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.4846 - val_accuracy: 0.7708\n",
            "Epoch 431/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.4848 - val_accuracy: 0.7708\n",
            "Epoch 432/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.4849 - val_accuracy: 0.7708\n",
            "Epoch 433/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.4850 - val_accuracy: 0.7708\n",
            "Epoch 434/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.4851 - val_accuracy: 0.7708\n",
            "Epoch 435/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.4853 - val_accuracy: 0.7708\n",
            "Epoch 436/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.4854 - val_accuracy: 0.7708\n",
            "Epoch 437/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.4854 - val_accuracy: 0.7708\n",
            "Epoch 438/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.4855 - val_accuracy: 0.7708\n",
            "Epoch 439/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 440/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.4857 - val_accuracy: 0.7708\n",
            "Epoch 441/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.4858 - val_accuracy: 0.7708\n",
            "Epoch 442/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.4859 - val_accuracy: 0.7708\n",
            "Epoch 443/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 444/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.4860 - val_accuracy: 0.7708\n",
            "Epoch 445/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.4862 - val_accuracy: 0.7708\n",
            "Epoch 446/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.4863 - val_accuracy: 0.7708\n",
            "Epoch 447/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.4864 - val_accuracy: 0.7708\n",
            "Epoch 448/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
            "Epoch 449/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.4866 - val_accuracy: 0.7708\n",
            "Epoch 450/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
            "Epoch 451/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
            "Epoch 452/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7708\n",
            "Epoch 453/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
            "Epoch 454/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7708\n",
            "Epoch 455/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 456/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7708\n",
            "Epoch 457/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
            "Epoch 458/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
            "Epoch 459/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
            "Epoch 460/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.4875 - val_accuracy: 0.7708\n",
            "Epoch 461/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.4876 - val_accuracy: 0.7708\n",
            "Epoch 462/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
            "Epoch 463/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.4877 - val_accuracy: 0.7708\n",
            "Epoch 464/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
            "Epoch 465/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
            "Epoch 466/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 467/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7899 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
            "Epoch 468/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
            "Epoch 469/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
            "Epoch 470/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.4882 - val_accuracy: 0.7708\n",
            "Epoch 471/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7708\n",
            "Epoch 472/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7708\n",
            "Epoch 473/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.4885 - val_accuracy: 0.7708\n",
            "Epoch 474/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7708\n",
            "Epoch 475/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.4885 - val_accuracy: 0.7708\n",
            "Epoch 476/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7708\n",
            "Epoch 477/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.4885 - val_accuracy: 0.7708\n",
            "Epoch 478/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.4886 - val_accuracy: 0.7708\n",
            "Epoch 479/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.4886 - val_accuracy: 0.7708\n",
            "Epoch 480/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.4887 - val_accuracy: 0.7708\n",
            "Epoch 481/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 482/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 483/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 484/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 485/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 486/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 487/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 488/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 489/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 490/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 491/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 492/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
            "Epoch 493/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 494/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
            "Epoch 495/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
            "Epoch 496/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
            "Epoch 497/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
            "Epoch 498/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
            "Epoch 499/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
            "Epoch 500/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
            "Epoch 501/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
            "Epoch 502/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
            "Epoch 503/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
            "Epoch 504/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 505/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
            "Epoch 506/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
            "Epoch 507/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
            "Epoch 508/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7899 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
            "Epoch 509/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
            "Epoch 510/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
            "Epoch 511/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
            "Epoch 512/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
            "Epoch 513/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
            "Epoch 514/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
            "Epoch 515/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
            "Epoch 516/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
            "Epoch 517/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7865 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
            "Epoch 518/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
            "Epoch 519/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.7865 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
            "Epoch 520/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
            "Epoch 521/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
            "Epoch 522/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
            "Epoch 523/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
            "Epoch 524/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
            "Epoch 525/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 526/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
            "Epoch 527/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7865 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 528/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
            "Epoch 529/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
            "Epoch 530/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
            "Epoch 531/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
            "Epoch 532/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
            "Epoch 533/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
            "Epoch 534/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
            "Epoch 535/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
            "Epoch 536/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
            "Epoch 537/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
            "Epoch 538/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
            "Epoch 539/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
            "Epoch 540/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
            "Epoch 541/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7882 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
            "Epoch 542/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
            "Epoch 543/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7865 - val_loss: 0.4928 - val_accuracy: 0.7656\n",
            "Epoch 544/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.4929 - val_accuracy: 0.7656\n",
            "Epoch 545/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7882 - val_loss: 0.4929 - val_accuracy: 0.7656\n",
            "Epoch 546/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7865 - val_loss: 0.4930 - val_accuracy: 0.7656\n",
            "Epoch 547/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
            "Epoch 548/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
            "Epoch 549/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
            "Epoch 550/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7882 - val_loss: 0.4932 - val_accuracy: 0.7656\n",
            "Epoch 551/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7882 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
            "Epoch 552/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7882 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
            "Epoch 553/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7882 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
            "Epoch 554/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7882 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
            "Epoch 555/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
            "Epoch 556/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7882 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
            "Epoch 557/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7882 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
            "Epoch 558/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
            "Epoch 559/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
            "Epoch 560/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
            "Epoch 561/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7882 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
            "Epoch 562/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
            "Epoch 563/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7882 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 564/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.7865 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 565/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 566/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4243 - accuracy: 0.7882 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
            "Epoch 567/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4245 - accuracy: 0.7917 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
            "Epoch 568/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.7865 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
            "Epoch 569/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.7882 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
            "Epoch 570/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
            "Epoch 571/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
            "Epoch 572/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
            "Epoch 573/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4240 - accuracy: 0.7882 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
            "Epoch 574/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4241 - accuracy: 0.7882 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
            "Epoch 575/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
            "Epoch 576/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
            "Epoch 577/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
            "Epoch 578/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
            "Epoch 579/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
            "Epoch 580/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7865 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
            "Epoch 581/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
            "Epoch 582/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
            "Epoch 583/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7882 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
            "Epoch 584/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 585/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.7882 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 586/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
            "Epoch 587/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
            "Epoch 588/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
            "Epoch 589/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
            "Epoch 590/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
            "Epoch 591/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
            "Epoch 592/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
            "Epoch 593/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
            "Epoch 594/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
            "Epoch 595/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 596/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.7899 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 597/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 598/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 599/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7882 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
            "Epoch 600/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 601/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
            "Epoch 602/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
            "Epoch 603/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
            "Epoch 604/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
            "Epoch 605/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
            "Epoch 606/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
            "Epoch 607/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
            "Epoch 608/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
            "Epoch 609/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
            "Epoch 610/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
            "Epoch 611/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
            "Epoch 612/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
            "Epoch 613/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 614/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7882 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
            "Epoch 615/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
            "Epoch 616/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.4975 - val_accuracy: 0.7656\n",
            "Epoch 617/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
            "Epoch 618/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7899 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
            "Epoch 619/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
            "Epoch 620/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
            "Epoch 621/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 622/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 623/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 624/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 625/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
            "Epoch 626/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 627/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
            "Epoch 628/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 629/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
            "Epoch 630/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7865 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
            "Epoch 631/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
            "Epoch 632/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
            "Epoch 633/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7865 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
            "Epoch 634/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7882 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 635/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7865 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 636/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 637/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7882 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 638/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7899 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 639/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7882 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 640/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7847 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 641/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7882 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
            "Epoch 642/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7882 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 643/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7847 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 644/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7882 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 645/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.7882 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 646/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.7865 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 647/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7865 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 648/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.7882 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 649/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7882 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 650/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7865 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 651/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7882 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
            "Epoch 652/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 653/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7865 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 654/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7865 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
            "Epoch 655/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7882 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
            "Epoch 656/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7899 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
            "Epoch 657/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
            "Epoch 658/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7899 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
            "Epoch 659/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
            "Epoch 660/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.7899 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
            "Epoch 661/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
            "Epoch 662/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7899 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
            "Epoch 663/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
            "Epoch 664/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7899 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
            "Epoch 665/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
            "Epoch 666/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
            "Epoch 667/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
            "Epoch 668/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
            "Epoch 669/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7899 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
            "Epoch 670/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7899 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
            "Epoch 671/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7882 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
            "Epoch 672/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7899 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
            "Epoch 673/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7899 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
            "Epoch 674/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7899 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
            "Epoch 675/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
            "Epoch 676/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7899 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
            "Epoch 677/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 678/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
            "Epoch 679/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
            "Epoch 680/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
            "Epoch 681/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
            "Epoch 682/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
            "Epoch 683/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
            "Epoch 684/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7760\n",
            "Epoch 685/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7760\n",
            "Epoch 686/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4181 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7760\n",
            "Epoch 687/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7760\n",
            "Epoch 688/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7865 - val_loss: 0.5015 - val_accuracy: 0.7760\n",
            "Epoch 689/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7882 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 690/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7899 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 691/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 692/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7760\n",
            "Epoch 693/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7882 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 694/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7882 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 695/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7899 - val_loss: 0.5019 - val_accuracy: 0.7760\n",
            "Epoch 696/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
            "Epoch 697/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 698/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.7865 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 699/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.7865 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 700/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.7899 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
            "Epoch 701/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.7865 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 702/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.7882 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
            "Epoch 703/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
            "Epoch 704/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.7899 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
            "Epoch 705/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7882 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
            "Epoch 706/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
            "Epoch 707/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 708/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.7865 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 709/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.7917 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 710/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7899 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
            "Epoch 711/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
            "Epoch 712/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
            "Epoch 713/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
            "Epoch 714/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
            "Epoch 715/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.7882 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
            "Epoch 716/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7760\n",
            "Epoch 717/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
            "Epoch 718/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.7882 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
            "Epoch 719/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.7865 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
            "Epoch 720/800\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4162 - accuracy: 0.7899 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
            "Epoch 721/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
            "Epoch 722/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.7882 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
            "Epoch 723/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7847 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
            "Epoch 724/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.7847 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
            "Epoch 725/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.7882 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
            "Epoch 726/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.7865 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
            "Epoch 727/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
            "Epoch 728/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.7847 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
            "Epoch 729/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
            "Epoch 730/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.7865 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
            "Epoch 731/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.7882 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
            "Epoch 732/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.7865 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
            "Epoch 733/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4153 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
            "Epoch 734/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.7882 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
            "Epoch 735/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.7899 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
            "Epoch 736/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5039 - val_accuracy: 0.7760\n",
            "Epoch 737/800\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4151 - accuracy: 0.7865 - val_loss: 0.5041 - val_accuracy: 0.7760\n",
            "Epoch 738/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.7865 - val_loss: 0.5042 - val_accuracy: 0.7760\n",
            "Epoch 739/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.7882 - val_loss: 0.5043 - val_accuracy: 0.7760\n",
            "Epoch 740/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.7865 - val_loss: 0.5042 - val_accuracy: 0.7760\n",
            "Epoch 741/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.7899 - val_loss: 0.5043 - val_accuracy: 0.7760\n",
            "Epoch 742/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.7865 - val_loss: 0.5044 - val_accuracy: 0.7760\n",
            "Epoch 743/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.7882 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
            "Epoch 744/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.7882 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
            "Epoch 745/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.7882 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
            "Epoch 746/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.7882 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
            "Epoch 747/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
            "Epoch 748/800\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.7865 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
            "Epoch 749/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.7865 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
            "Epoch 750/800\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7760\n",
            "Epoch 751/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.7882 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
            "Epoch 752/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.7865 - val_loss: 0.5047 - val_accuracy: 0.7760\n",
            "Epoch 753/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
            "Epoch 754/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.7865 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
            "Epoch 755/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
            "Epoch 756/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.7865 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
            "Epoch 757/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.7899 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
            "Epoch 758/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.7847 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
            "Epoch 759/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
            "Epoch 760/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.7917 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
            "Epoch 761/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
            "Epoch 762/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
            "Epoch 763/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.7917 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
            "Epoch 764/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.7917 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
            "Epoch 765/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.7899 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
            "Epoch 766/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.7917 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
            "Epoch 767/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.7899 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
            "Epoch 768/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.7917 - val_loss: 0.5053 - val_accuracy: 0.7760\n",
            "Epoch 769/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.7882 - val_loss: 0.5055 - val_accuracy: 0.7760\n",
            "Epoch 770/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.7934 - val_loss: 0.5054 - val_accuracy: 0.7760\n",
            "Epoch 771/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.7899 - val_loss: 0.5054 - val_accuracy: 0.7760\n",
            "Epoch 772/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.7934 - val_loss: 0.5055 - val_accuracy: 0.7760\n",
            "Epoch 773/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.7934 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 774/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 775/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.7934 - val_loss: 0.5057 - val_accuracy: 0.7760\n",
            "Epoch 776/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.7917 - val_loss: 0.5058 - val_accuracy: 0.7760\n",
            "Epoch 777/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.7917 - val_loss: 0.5058 - val_accuracy: 0.7760\n",
            "Epoch 778/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7760\n",
            "Epoch 779/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7760\n",
            "Epoch 780/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.7917 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 781/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7917 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 782/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.7917 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 783/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7934 - val_loss: 0.5063 - val_accuracy: 0.7760\n",
            "Epoch 784/800\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.7934 - val_loss: 0.5063 - val_accuracy: 0.7760\n",
            "Epoch 785/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.7917 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
            "Epoch 786/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7899 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
            "Epoch 787/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.7917 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
            "Epoch 788/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.7917 - val_loss: 0.5064 - val_accuracy: 0.7760\n",
            "Epoch 789/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7917 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
            "Epoch 790/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.7934 - val_loss: 0.5068 - val_accuracy: 0.7760\n",
            "Epoch 791/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7917 - val_loss: 0.5066 - val_accuracy: 0.7760\n",
            "Epoch 792/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.7934 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
            "Epoch 793/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.7917 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
            "Epoch 794/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.7917 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
            "Epoch 795/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.7934 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
            "Epoch 796/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7917 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 797/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.7934 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
            "Epoch 798/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.7899 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 799/800\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.7899 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 800/800\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7917 - val_loss: 0.5073 - val_accuracy: 0.7708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nnew1 = new_model2.predict(X_test_norm)\n",
        "y_pred_class_nnew1 = (y_pred_prob_nnew1 > 0.5).astype('int32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGyTGtk58quD",
        "outputId": "501c8c56-c2fa-4eb0-ed12-cff18ace1810"
      },
      "id": "KGyTGtk58quD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nnew1[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbgNVaZZ81n1",
        "outputId": "8adfd488-7477-4912-b783-564eb2f79225"
      },
      "id": "SbgNVaZZ81n1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nnew1[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3qjB83o82C0",
        "outputId": "45f0f0b2-df5f-4636-b6d9-01175d109470"
      },
      "id": "i3qjB83o82C0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6447143 ],\n",
              "       [0.762542  ],\n",
              "       [0.3831105 ],\n",
              "       [0.11248234],\n",
              "       [0.24771403],\n",
              "       [0.53396714],\n",
              "       [0.01348655],\n",
              "       [0.45988557],\n",
              "       [0.887487  ],\n",
              "       [0.1467733 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc(y_test, y_pred, new_model_name1):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(new_model_name1),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ],
      "metadata": {
        "id": "K-8VuEds87mo"
      },
      "id": "K-8VuEds87mo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nnew1)))#y_pred_prob_nnew\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nnew1)))#y_pred_prob_nnew\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nnew1, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "LBcE402T9CLE",
        "outputId": "aa8d5afc-d9f8-49e6-b485-881c9ce4751d"
      },
      "id": "LBcE402T9CLE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.771\n",
            "roc-auc is 0.827\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The accuracy of this model, which stands at 74.5%, indicates that the predictions it made were partially accurate. It received an ROC-AUC score of 0.803 in this regard. Higher scores indicate a better separation across classes. This evaluates the model's ability to distinguish between positive and negative examples. Overall, though, this model could be better.\n"
      ],
      "metadata": {
        "id": "p4wf6BW-_AoF"
      },
      "id": "p4wf6BW-_AoF"
    },
    {
      "cell_type": "code",
      "source": [
        "run_hist_3.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nqQ1flY9CvY",
        "outputId": "92408412-2887-49c4-9c4b-5d1ed8367170"
      },
      "id": "7nqQ1flY9CvY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(run_hist_3.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_3.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "ELQMl48k9Fbr",
        "outputId": "4d523759-9dcc-47ee-e4cc-12ec4764769e"
      },
      "id": "ELQMl48k9Fbr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cf71b44f550>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_3.history['accuracy'], 'y', label = 'Train Accuracy')\n",
        "ax.plot(run_hist_3.history['val_accuracy'], 'g', label = 'Val Accuracy')\n",
        "plt.title(\"Model 2 Accuracy Graph\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "NfM1COUE-NDd",
        "outputId": "3e853c15-22c3-467c-bb21-0fd67dddf00c"
      },
      "id": "NfM1COUE-NDd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cf71b361450>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdGXHZknJ1NN"
      },
      "outputs": [],
      "source": [
        "#y_pred_prob_nn_1 = model.predict(X_test_norm)\n",
        "#y_pred_class_nn_1  = np.argmax(y_pred_prob_nn_1, axis=1)"
      ],
      "id": "WdGXHZknJ1NN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model 3. 1 hidden layer, lr = 002, epoch = 1500"
      ],
      "metadata": {
        "id": "qQPJYYbpA5sV"
      },
      "id": "qQPJYYbpA5sV"
    },
    {
      "cell_type": "code",
      "source": [
        "new_model3 = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "IMaI4KuZAIpk"
      },
      "id": "IMaI4KuZAIpk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_model3.compile(SGD(lr = .002), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_4 = new_model3.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcTHdQCnAM4O",
        "outputId": "3485e80c-95cf-4f59-c545-1e625a4e8dfc"
      },
      "id": "kcTHdQCnAM4O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 12ms/step - loss: 0.6218 - accuracy: 0.6962 - val_loss: 0.5952 - val_accuracy: 0.7135\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.7066 - val_loss: 0.5894 - val_accuracy: 0.7188\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6051 - accuracy: 0.7066 - val_loss: 0.5842 - val_accuracy: 0.7292\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5977 - accuracy: 0.7135 - val_loss: 0.5796 - val_accuracy: 0.7344\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.7118 - val_loss: 0.5754 - val_accuracy: 0.7604\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.7118 - val_loss: 0.5716 - val_accuracy: 0.7604\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.7135 - val_loss: 0.5682 - val_accuracy: 0.7604\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7188 - val_loss: 0.5652 - val_accuracy: 0.7656\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7222 - val_loss: 0.5623 - val_accuracy: 0.7656\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.7240 - val_loss: 0.5597 - val_accuracy: 0.7604\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7257 - val_loss: 0.5572 - val_accuracy: 0.7656\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7274 - val_loss: 0.5548 - val_accuracy: 0.7708\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7292 - val_loss: 0.5525 - val_accuracy: 0.7656\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7309 - val_loss: 0.5504 - val_accuracy: 0.7656\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5466 - accuracy: 0.7326 - val_loss: 0.5485 - val_accuracy: 0.7656\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7361 - val_loss: 0.5467 - val_accuracy: 0.7604\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7344 - val_loss: 0.5451 - val_accuracy: 0.7656\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7378 - val_loss: 0.5435 - val_accuracy: 0.7656\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7413 - val_loss: 0.5421 - val_accuracy: 0.7656\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7396 - val_loss: 0.5407 - val_accuracy: 0.7656\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7378 - val_loss: 0.5394 - val_accuracy: 0.7604\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7396 - val_loss: 0.5381 - val_accuracy: 0.7656\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7361 - val_loss: 0.5370 - val_accuracy: 0.7656\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7378 - val_loss: 0.5359 - val_accuracy: 0.7708\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7361 - val_loss: 0.5348 - val_accuracy: 0.7760\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7396 - val_loss: 0.5339 - val_accuracy: 0.7760\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7431 - val_loss: 0.5329 - val_accuracy: 0.7760\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7431 - val_loss: 0.5320 - val_accuracy: 0.7708\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7483 - val_loss: 0.5311 - val_accuracy: 0.7708\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7517 - val_loss: 0.5302 - val_accuracy: 0.7708\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7500 - val_loss: 0.5294 - val_accuracy: 0.7708\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7552 - val_loss: 0.5287 - val_accuracy: 0.7708\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7552 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7569 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7604 - val_loss: 0.5264 - val_accuracy: 0.7656\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7674 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7656 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7674 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7691 - val_loss: 0.5235 - val_accuracy: 0.7656\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7708 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7726 - val_loss: 0.5221 - val_accuracy: 0.7708\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7760 - val_loss: 0.5214 - val_accuracy: 0.7708\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7760 - val_loss: 0.5208 - val_accuracy: 0.7708\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7778 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7760 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7778 - val_loss: 0.5188 - val_accuracy: 0.7708\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7760 - val_loss: 0.5182 - val_accuracy: 0.7708\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7760 - val_loss: 0.5176 - val_accuracy: 0.7708\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7760 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7760 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7760 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7760 - val_loss: 0.5153 - val_accuracy: 0.7760\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7760 - val_loss: 0.5147 - val_accuracy: 0.7760\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7778 - val_loss: 0.5141 - val_accuracy: 0.7760\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7795 - val_loss: 0.5136 - val_accuracy: 0.7708\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7812 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7812 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7812 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7760 - val_loss: 0.5116 - val_accuracy: 0.7760\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7743 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7726 - val_loss: 0.5106 - val_accuracy: 0.7760\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7743 - val_loss: 0.5102 - val_accuracy: 0.7760\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7708 - val_loss: 0.5098 - val_accuracy: 0.7760\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7708 - val_loss: 0.5093 - val_accuracy: 0.7760\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7708 - val_loss: 0.5088 - val_accuracy: 0.7812\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7674 - val_loss: 0.5084 - val_accuracy: 0.7812\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7674 - val_loss: 0.5081 - val_accuracy: 0.7812\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7674 - val_loss: 0.5077 - val_accuracy: 0.7812\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.7674 - val_loss: 0.5074 - val_accuracy: 0.7812\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7674 - val_loss: 0.5070 - val_accuracy: 0.7812\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7674 - val_loss: 0.5067 - val_accuracy: 0.7812\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7691 - val_loss: 0.5064 - val_accuracy: 0.7812\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7691 - val_loss: 0.5061 - val_accuracy: 0.7812\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7674 - val_loss: 0.5058 - val_accuracy: 0.7760\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7691 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7674 - val_loss: 0.5052 - val_accuracy: 0.7760\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7691 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7674 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7674 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7674 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7691 - val_loss: 0.5037 - val_accuracy: 0.7708\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7708 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7674 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7674 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7708 - val_loss: 0.5024 - val_accuracy: 0.7760\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7708 - val_loss: 0.5022 - val_accuracy: 0.7760\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7708 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7726 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7726 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7743 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7812 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7847 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4565 - accuracy: 0.7795 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7795 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4555 - accuracy: 0.7795 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7795 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7812 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7812 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.7812 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7812 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.7812 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.7812 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.7830 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7830 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7865 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7865 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7899 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7865 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7847 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7847 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7882 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7865 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7882 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7865 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7865 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7865 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7865 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7865 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.7847 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7865 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7865 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7865 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7882 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7865 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7865 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7882 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7882 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7882 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7899 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7882 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7899 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7882 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7899 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7899 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7899 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7899 - val_loss: 0.4941 - val_accuracy: 0.7812\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7899 - val_loss: 0.4941 - val_accuracy: 0.7812\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7917 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7917 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7917 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7917 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7917 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7917 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7917 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7917 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7917 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7917 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7986 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7951 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7986 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7986 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7986 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7986 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7986 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8003 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8038 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8038 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8038 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.8021 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8038 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8038 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.8056 - val_loss: 0.4946 - val_accuracy: 0.7760\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.8073 - val_loss: 0.4947 - val_accuracy: 0.7760\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8056 - val_loss: 0.4947 - val_accuracy: 0.7760\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8056 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.8056 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8056 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.8073 - val_loss: 0.4949 - val_accuracy: 0.7760\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.8073 - val_loss: 0.4949 - val_accuracy: 0.7760\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.8073 - val_loss: 0.4949 - val_accuracy: 0.7760\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8056 - val_loss: 0.4950 - val_accuracy: 0.7760\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.8073 - val_loss: 0.4950 - val_accuracy: 0.7760\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8090 - val_loss: 0.4951 - val_accuracy: 0.7760\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8073 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8073 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8073 - val_loss: 0.4953 - val_accuracy: 0.7760\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8073 - val_loss: 0.4953 - val_accuracy: 0.7760\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8056 - val_loss: 0.4954 - val_accuracy: 0.7760\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8073 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.8073 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.8073 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8090 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4225 - accuracy: 0.8090 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8038 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8038 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8090 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8073 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8056 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8090 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8090 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8073 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8073 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8090 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8073 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8090 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8073 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8090 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8056 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8056 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8056 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8073 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8073 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8073 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8073 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8056 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8073 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8073 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8090 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8056 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8090 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8090 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8090 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8073 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8108 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8108 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8090 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8108 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8090 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8108 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8108 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8108 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8108 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.8108 - val_loss: 0.4975 - val_accuracy: 0.7656\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.8108 - val_loss: 0.4975 - val_accuracy: 0.7656\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8108 - val_loss: 0.4976 - val_accuracy: 0.7656\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8108 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.8108 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.8108 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8090 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8108 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8090 - val_loss: 0.4979 - val_accuracy: 0.7656\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.4980 - val_accuracy: 0.7656\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8108 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8108 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8108 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8090 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8108 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8108 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8108 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8108 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8090 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8108 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8090 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8090 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.8108 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8108 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8090 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8090 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8108 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8090 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8073 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8073 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8073 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8073 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8073 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8090 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8073 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.8073 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8090 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8073 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8073 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8090 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8073 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8073 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8073 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8073 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8073 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8073 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4182 - accuracy: 0.8073 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8073 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8073 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8073 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8073 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8073 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8073 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8073 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8073 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8073 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8073 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8073 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8073 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8090 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8090 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8090 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8090 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8090 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8090 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.8090 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8090 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8090 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8090 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8090 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8090 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8090 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8090 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8090 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8090 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8090 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8090 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8090 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8090 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8090 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8090 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8090 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8090 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8090 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8090 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8090 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8090 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8090 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8090 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.8090 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4163 - accuracy: 0.8073 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8090 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.8108 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.8090 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8090 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8073 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8073 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8108 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.8090 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8090 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.8073 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8090 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4157 - accuracy: 0.8090 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8073 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8073 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4156 - accuracy: 0.8090 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8090 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8090 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8073 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.8073 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8090 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8090 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8108 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8073 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.8090 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8108 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8108 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8090 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8108 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8090 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8108 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8125 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8090 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8090 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8125 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8108 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8125 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8125 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8125 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8125 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8125 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8125 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8108 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.8142 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8142 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8142 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8142 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8142 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8142 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8142 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8142 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8142 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8142 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8142 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8142 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8142 - val_loss: 0.5039 - val_accuracy: 0.7760\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8142 - val_loss: 0.5039 - val_accuracy: 0.7708\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8142 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8142 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8160 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8142 - val_loss: 0.5041 - val_accuracy: 0.7708\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8160 - val_loss: 0.5041 - val_accuracy: 0.7708\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8142 - val_loss: 0.5042 - val_accuracy: 0.7708\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8142 - val_loss: 0.5042 - val_accuracy: 0.7708\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8160 - val_loss: 0.5042 - val_accuracy: 0.7708\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8160 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8160 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8160 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.8160 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8160 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8160 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8177 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8160 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8160 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8160 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8160 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8160 - val_loss: 0.5047 - val_accuracy: 0.7760\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8160 - val_loss: 0.5047 - val_accuracy: 0.7760\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8160 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8160 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8160 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8160 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8160 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8160 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.8160 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8160 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8160 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8160 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8160 - val_loss: 0.5052 - val_accuracy: 0.7760\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8142 - val_loss: 0.5052 - val_accuracy: 0.7760\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8160 - val_loss: 0.5053 - val_accuracy: 0.7760\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8142 - val_loss: 0.5053 - val_accuracy: 0.7760\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8142 - val_loss: 0.5053 - val_accuracy: 0.7760\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8160 - val_loss: 0.5054 - val_accuracy: 0.7760\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8142 - val_loss: 0.5054 - val_accuracy: 0.7760\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8177 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8177 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8177 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8160 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8160 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8160 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8177 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8160 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8160 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8142 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8177 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8160 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8160 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8142 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8160 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8160 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8194 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8160 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8160 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8160 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8177 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8177 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8177 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8177 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8160 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8160 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8160 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8177 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8160 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8177 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8177 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8160 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8177 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8177 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8160 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8160 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8177 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8177 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8177 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8177 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8160 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8160 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8177 - val_loss: 0.5080 - val_accuracy: 0.7708\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8177 - val_loss: 0.5081 - val_accuracy: 0.7708\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8177 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8177 - val_loss: 0.5082 - val_accuracy: 0.7708\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8177 - val_loss: 0.5083 - val_accuracy: 0.7708\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8160 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8142 - val_loss: 0.5084 - val_accuracy: 0.7708\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8177 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8160 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8142 - val_loss: 0.5085 - val_accuracy: 0.7708\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8142 - val_loss: 0.5086 - val_accuracy: 0.7708\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8142 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8160 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8160 - val_loss: 0.5088 - val_accuracy: 0.7708\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8160 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8142 - val_loss: 0.5089 - val_accuracy: 0.7708\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8160 - val_loss: 0.5090 - val_accuracy: 0.7708\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8142 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4102 - accuracy: 0.8125 - val_loss: 0.5091 - val_accuracy: 0.7708\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4101 - accuracy: 0.8125 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8160 - val_loss: 0.5092 - val_accuracy: 0.7708\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.8160 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.8125 - val_loss: 0.5093 - val_accuracy: 0.7708\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8142 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8160 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8160 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4100 - accuracy: 0.8142 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8125 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8142 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4100 - accuracy: 0.8125 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4099 - accuracy: 0.8160 - val_loss: 0.5098 - val_accuracy: 0.7708\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.8125 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8125 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8125 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8125 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4097 - accuracy: 0.8125 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8125 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8142 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8142 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4096 - accuracy: 0.8125 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8125 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8108 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8125 - val_loss: 0.5104 - val_accuracy: 0.7708\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8125 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8125 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8125 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8125 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8142 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8125 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8125 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8142 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8142 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8125 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8142 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8125 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8125 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8125 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8125 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8125 - val_loss: 0.5112 - val_accuracy: 0.7708\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8125 - val_loss: 0.5113 - val_accuracy: 0.7708\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8142 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8142 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8125 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8142 - val_loss: 0.5114 - val_accuracy: 0.7708\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8142 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8177 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8142 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8142 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8142 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8142 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8142 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8160 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5119 - val_accuracy: 0.7708\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8142 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8142 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8142 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8142 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8142 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8142 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8142 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8142 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8160 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8160 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8160 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8142 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8177 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8142 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8160 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8160 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8142 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8160 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8160 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8160 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8160 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8177 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8160 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8160 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8177 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8177 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8160 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.8160 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8142 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8160 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8177 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8160 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8177 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8160 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8177 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8160 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8160 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8194 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8160 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8194 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8194 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8194 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8177 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8160 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8194 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8177 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8194 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8194 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8194 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8177 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8194 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8212 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8194 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8194 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8212 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8194 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8194 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8194 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8194 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8177 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8212 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8212 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8212 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8212 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8194 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8212 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8194 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8194 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8212 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8212 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8212 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8212 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8194 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8194 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8194 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8212 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8194 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8194 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8212 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8212 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8212 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8194 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8212 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8229 - val_loss: 0.5158 - val_accuracy: 0.7656\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8212 - val_loss: 0.5159 - val_accuracy: 0.7656\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8212 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4060 - accuracy: 0.8212 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8212 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8212 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8212 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8229 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8212 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8194 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8212 - val_loss: 0.5168 - val_accuracy: 0.7656\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8212 - val_loss: 0.5169 - val_accuracy: 0.7656\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8194 - val_loss: 0.5170 - val_accuracy: 0.7656\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8194 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8177 - val_loss: 0.5172 - val_accuracy: 0.7656\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8194 - val_loss: 0.5172 - val_accuracy: 0.7656\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8194 - val_loss: 0.5173 - val_accuracy: 0.7656\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8212 - val_loss: 0.5174 - val_accuracy: 0.7656\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8194 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8194 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8212 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8212 - val_loss: 0.5177 - val_accuracy: 0.7656\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.8212 - val_loss: 0.5178 - val_accuracy: 0.7656\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8212 - val_loss: 0.5179 - val_accuracy: 0.7656\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8212 - val_loss: 0.5179 - val_accuracy: 0.7708\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8194 - val_loss: 0.5180 - val_accuracy: 0.7708\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8212 - val_loss: 0.5180 - val_accuracy: 0.7708\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8212 - val_loss: 0.5181 - val_accuracy: 0.7708\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8194 - val_loss: 0.5181 - val_accuracy: 0.7708\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8212 - val_loss: 0.5182 - val_accuracy: 0.7708\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8212 - val_loss: 0.5182 - val_accuracy: 0.7708\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8212 - val_loss: 0.5182 - val_accuracy: 0.7708\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8177 - val_loss: 0.5183 - val_accuracy: 0.7708\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8194 - val_loss: 0.5184 - val_accuracy: 0.7708\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8212 - val_loss: 0.5184 - val_accuracy: 0.7708\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.8212 - val_loss: 0.5184 - val_accuracy: 0.7708\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8212 - val_loss: 0.5185 - val_accuracy: 0.7708\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8212 - val_loss: 0.5185 - val_accuracy: 0.7708\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8212 - val_loss: 0.5186 - val_accuracy: 0.7708\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.8212 - val_loss: 0.5186 - val_accuracy: 0.7708\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.8212 - val_loss: 0.5187 - val_accuracy: 0.7708\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.8212 - val_loss: 0.5187 - val_accuracy: 0.7708\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8194 - val_loss: 0.5188 - val_accuracy: 0.7708\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8194 - val_loss: 0.5189 - val_accuracy: 0.7708\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8212 - val_loss: 0.5190 - val_accuracy: 0.7708\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8177 - val_loss: 0.5191 - val_accuracy: 0.7708\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8194 - val_loss: 0.5191 - val_accuracy: 0.7708\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.5191 - val_accuracy: 0.7708\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.5192 - val_accuracy: 0.7708\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8212 - val_loss: 0.5192 - val_accuracy: 0.7708\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8194 - val_loss: 0.5193 - val_accuracy: 0.7708\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8212 - val_loss: 0.5193 - val_accuracy: 0.7708\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8212 - val_loss: 0.5193 - val_accuracy: 0.7708\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8194 - val_loss: 0.5193 - val_accuracy: 0.7708\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8194 - val_loss: 0.5193 - val_accuracy: 0.7708\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.5194 - val_accuracy: 0.7708\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8194 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8212 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8212 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8212 - val_loss: 0.5195 - val_accuracy: 0.7708\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8212 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8194 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8212 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8194 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8212 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8194 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8212 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8212 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8194 - val_loss: 0.5200 - val_accuracy: 0.7708\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8212 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8194 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8229 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8194 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8212 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8212 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8212 - val_loss: 0.5201 - val_accuracy: 0.7708\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8194 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8194 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8212 - val_loss: 0.5202 - val_accuracy: 0.7708\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8194 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8177 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8212 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8194 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8194 - val_loss: 0.5203 - val_accuracy: 0.7708\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.5204 - val_accuracy: 0.7656\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.5205 - val_accuracy: 0.7708\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8212 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8194 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8212 - val_loss: 0.5204 - val_accuracy: 0.7656\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8212 - val_loss: 0.5204 - val_accuracy: 0.7656\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8212 - val_loss: 0.5204 - val_accuracy: 0.7656\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8212 - val_loss: 0.5204 - val_accuracy: 0.7656\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8212 - val_loss: 0.5204 - val_accuracy: 0.7656\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8194 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8212 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8212 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8212 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8212 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8212 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8194 - val_loss: 0.5206 - val_accuracy: 0.7656\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8212 - val_loss: 0.5206 - val_accuracy: 0.7656\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8212 - val_loss: 0.5206 - val_accuracy: 0.7656\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8212 - val_loss: 0.5206 - val_accuracy: 0.7656\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8212 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8212 - val_loss: 0.5206 - val_accuracy: 0.7656\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8212 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8212 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8212 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8212 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8212 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8212 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8212 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8212 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8212 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8212 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8212 - val_loss: 0.5208 - val_accuracy: 0.7656\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8212 - val_loss: 0.5208 - val_accuracy: 0.7656\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8212 - val_loss: 0.5208 - val_accuracy: 0.7656\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8194 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8212 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.8212 - val_loss: 0.5208 - val_accuracy: 0.7656\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8212 - val_loss: 0.5208 - val_accuracy: 0.7656\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8212 - val_loss: 0.5208 - val_accuracy: 0.7656\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8212 - val_loss: 0.5209 - val_accuracy: 0.7656\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8212 - val_loss: 0.5210 - val_accuracy: 0.7656\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8212 - val_loss: 0.5210 - val_accuracy: 0.7656\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8194 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8194 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8212 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8212 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8229 - val_loss: 0.5212 - val_accuracy: 0.7656\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.5212 - val_accuracy: 0.7656\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.5213 - val_accuracy: 0.7656\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8194 - val_loss: 0.5213 - val_accuracy: 0.7656\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8229 - val_loss: 0.5214 - val_accuracy: 0.7656\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8212 - val_loss: 0.5214 - val_accuracy: 0.7656\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.5214 - val_accuracy: 0.7656\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8212 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8229 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8212 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8177 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8212 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8212 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8194 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8194 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8229 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8194 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8229 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8229 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8194 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8177 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8194 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8194 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8177 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8212 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8194 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8194 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4019 - accuracy: 0.8177 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8177 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8177 - val_loss: 0.5222 - val_accuracy: 0.7656\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8177 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4017 - accuracy: 0.8177 - val_loss: 0.5222 - val_accuracy: 0.7656\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8177 - val_loss: 0.5222 - val_accuracy: 0.7656\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8212 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8177 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8177 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4017 - accuracy: 0.8177 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4018 - accuracy: 0.8177 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8177 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8194 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4017 - accuracy: 0.8177 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8177 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4016 - accuracy: 0.8177 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4015 - accuracy: 0.8177 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8194 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8194 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8177 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4016 - accuracy: 0.8177 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8177 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.8194 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.8177 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.8194 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.8177 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8177 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4014 - accuracy: 0.8194 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.8177 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.8194 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.8212 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8177 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8177 - val_loss: 0.5229 - val_accuracy: 0.7656\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4012 - accuracy: 0.8194 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4012 - accuracy: 0.8177 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4013 - accuracy: 0.8177 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4012 - accuracy: 0.8177 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4011 - accuracy: 0.8194 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8177 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8194 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8177 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8177 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8177 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8177 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8177 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8212 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8177 - val_loss: 0.5233 - val_accuracy: 0.7604\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8194 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8177 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8177 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8177 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8177 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8177 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8194 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8177 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8194 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8194 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8177 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8194 - val_loss: 0.5237 - val_accuracy: 0.7604\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8194 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8212 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8177 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8229 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8212 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8177 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8177 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8177 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8194 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8177 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8212 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8212 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8212 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8212 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8177 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8212 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8212 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8194 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8212 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8194 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8177 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8194 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8212 - val_loss: 0.5243 - val_accuracy: 0.7656\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8177 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8212 - val_loss: 0.5243 - val_accuracy: 0.7656\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8177 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8177 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8177 - val_loss: 0.5243 - val_accuracy: 0.7656\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8212 - val_loss: 0.5243 - val_accuracy: 0.7656\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8160 - val_loss: 0.5243 - val_accuracy: 0.7656\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8194 - val_loss: 0.5243 - val_accuracy: 0.7656\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8229 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8212 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8212 - val_loss: 0.5245 - val_accuracy: 0.7656\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8212 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8177 - val_loss: 0.5244 - val_accuracy: 0.7656\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8212 - val_loss: 0.5245 - val_accuracy: 0.7656\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8229 - val_loss: 0.5246 - val_accuracy: 0.7656\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8194 - val_loss: 0.5246 - val_accuracy: 0.7656\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8212 - val_loss: 0.5245 - val_accuracy: 0.7656\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8194 - val_loss: 0.5246 - val_accuracy: 0.7656\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8229 - val_loss: 0.5246 - val_accuracy: 0.7656\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8212 - val_loss: 0.5246 - val_accuracy: 0.7656\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8194 - val_loss: 0.5246 - val_accuracy: 0.7656\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8194 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8212 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8229 - val_loss: 0.5248 - val_accuracy: 0.7656\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8212 - val_loss: 0.5248 - val_accuracy: 0.7656\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8212 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8212 - val_loss: 0.5247 - val_accuracy: 0.7656\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8212 - val_loss: 0.5248 - val_accuracy: 0.7656\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8212 - val_loss: 0.5248 - val_accuracy: 0.7656\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8212 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8212 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8229 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8229 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8229 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8212 - val_loss: 0.5250 - val_accuracy: 0.7656\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8212 - val_loss: 0.5250 - val_accuracy: 0.7656\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8229 - val_loss: 0.5250 - val_accuracy: 0.7656\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5250 - val_accuracy: 0.7656\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5250 - val_accuracy: 0.7656\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5250 - val_accuracy: 0.7656\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8229 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8229 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8212 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8229 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8229 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8229 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3989 - accuracy: 0.8229 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3989 - accuracy: 0.8229 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8212 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8229 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.8212 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8229 - val_loss: 0.5256 - val_accuracy: 0.7656\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8212 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3988 - accuracy: 0.8212 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8229 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3988 - accuracy: 0.8229 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8229 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8229 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8229 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8229 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3987 - accuracy: 0.8229 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8229 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3987 - accuracy: 0.8229 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8229 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8229 - val_loss: 0.5260 - val_accuracy: 0.7656\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8229 - val_loss: 0.5260 - val_accuracy: 0.7656\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8229 - val_loss: 0.5260 - val_accuracy: 0.7656\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3985 - accuracy: 0.8229 - val_loss: 0.5260 - val_accuracy: 0.7656\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8229 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8229 - val_loss: 0.5260 - val_accuracy: 0.7656\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.8229 - val_loss: 0.5262 - val_accuracy: 0.7656\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8229 - val_loss: 0.5262 - val_accuracy: 0.7656\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8229 - val_loss: 0.5262 - val_accuracy: 0.7656\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8229 - val_loss: 0.5262 - val_accuracy: 0.7656\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8229 - val_loss: 0.5262 - val_accuracy: 0.7656\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8229 - val_loss: 0.5262 - val_accuracy: 0.7656\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8229 - val_loss: 0.5263 - val_accuracy: 0.7656\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8229 - val_loss: 0.5264 - val_accuracy: 0.7656\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8229 - val_loss: 0.5263 - val_accuracy: 0.7656\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5265 - val_accuracy: 0.7656\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5264 - val_accuracy: 0.7656\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5265 - val_accuracy: 0.7656\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5266 - val_accuracy: 0.7656\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5266 - val_accuracy: 0.7656\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8229 - val_loss: 0.5267 - val_accuracy: 0.7656\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5267 - val_accuracy: 0.7656\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5267 - val_accuracy: 0.7656\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.5267 - val_accuracy: 0.7656\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8229 - val_loss: 0.5268 - val_accuracy: 0.7656\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8229 - val_loss: 0.5269 - val_accuracy: 0.7656\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8229 - val_loss: 0.5269 - val_accuracy: 0.7656\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8229 - val_loss: 0.5269 - val_accuracy: 0.7656\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8229 - val_loss: 0.5270 - val_accuracy: 0.7656\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8229 - val_loss: 0.5270 - val_accuracy: 0.7656\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8229 - val_loss: 0.5270 - val_accuracy: 0.7656\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8229 - val_loss: 0.5271 - val_accuracy: 0.7656\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8229 - val_loss: 0.5271 - val_accuracy: 0.7656\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8229 - val_loss: 0.5271 - val_accuracy: 0.7656\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8247 - val_loss: 0.5272 - val_accuracy: 0.7656\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8229 - val_loss: 0.5272 - val_accuracy: 0.7656\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8229 - val_loss: 0.5273 - val_accuracy: 0.7656\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8247 - val_loss: 0.5273 - val_accuracy: 0.7656\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8229 - val_loss: 0.5273 - val_accuracy: 0.7656\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8229 - val_loss: 0.5274 - val_accuracy: 0.7656\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8229 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8229 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8229 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8247 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8247 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8212 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8229 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8247 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8229 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8247 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8229 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8247 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8229 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8229 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8212 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8229 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8229 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8229 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8229 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8229 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8212 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8212 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8212 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8212 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8229 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8229 - val_loss: 0.5286 - val_accuracy: 0.7656\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8212 - val_loss: 0.5287 - val_accuracy: 0.7656\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8229 - val_loss: 0.5287 - val_accuracy: 0.7656\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8229 - val_loss: 0.5288 - val_accuracy: 0.7656\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8229 - val_loss: 0.5287 - val_accuracy: 0.7656\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8229 - val_loss: 0.5287 - val_accuracy: 0.7656\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8229 - val_loss: 0.5288 - val_accuracy: 0.7656\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8212 - val_loss: 0.5288 - val_accuracy: 0.7656\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8194 - val_loss: 0.5289 - val_accuracy: 0.7656\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8229 - val_loss: 0.5290 - val_accuracy: 0.7656\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8212 - val_loss: 0.5290 - val_accuracy: 0.7656\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8212 - val_loss: 0.5290 - val_accuracy: 0.7656\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8212 - val_loss: 0.5290 - val_accuracy: 0.7656\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8229 - val_loss: 0.5291 - val_accuracy: 0.7656\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8212 - val_loss: 0.5291 - val_accuracy: 0.7656\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8212 - val_loss: 0.5292 - val_accuracy: 0.7656\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 0.5292 - val_accuracy: 0.7656\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 0.5294 - val_accuracy: 0.7656\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8194 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8212 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8212 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5294 - val_accuracy: 0.7656\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5295 - val_accuracy: 0.7656\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5295 - val_accuracy: 0.7656\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5296 - val_accuracy: 0.7708\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5297 - val_accuracy: 0.7708\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8194 - val_loss: 0.5298 - val_accuracy: 0.7708\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5298 - val_accuracy: 0.7708\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5298 - val_accuracy: 0.7708\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5299 - val_accuracy: 0.7708\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8194 - val_loss: 0.5299 - val_accuracy: 0.7708\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5299 - val_accuracy: 0.7708\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5300 - val_accuracy: 0.7708\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8194 - val_loss: 0.5300 - val_accuracy: 0.7708\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5300 - val_accuracy: 0.7708\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5300 - val_accuracy: 0.7708\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8194 - val_loss: 0.5301 - val_accuracy: 0.7708\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5302 - val_accuracy: 0.7708\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5302 - val_accuracy: 0.7708\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5303 - val_accuracy: 0.7708\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5303 - val_accuracy: 0.7708\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5303 - val_accuracy: 0.7708\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8194 - val_loss: 0.5304 - val_accuracy: 0.7708\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5304 - val_accuracy: 0.7708\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8194 - val_loss: 0.5305 - val_accuracy: 0.7708\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5305 - val_accuracy: 0.7708\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5307 - val_accuracy: 0.7708\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5307 - val_accuracy: 0.7708\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5307 - val_accuracy: 0.7708\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8194 - val_loss: 0.5306 - val_accuracy: 0.7708\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8194 - val_loss: 0.5307 - val_accuracy: 0.7708\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8194 - val_loss: 0.5308 - val_accuracy: 0.7708\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5309 - val_accuracy: 0.7708\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5309 - val_accuracy: 0.7708\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5310 - val_accuracy: 0.7708\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5311 - val_accuracy: 0.7708\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5310 - val_accuracy: 0.7708\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5310 - val_accuracy: 0.7708\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5310 - val_accuracy: 0.7708\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5311 - val_accuracy: 0.7708\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5311 - val_accuracy: 0.7708\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5312 - val_accuracy: 0.7708\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5312 - val_accuracy: 0.7708\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5313 - val_accuracy: 0.7708\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8194 - val_loss: 0.5314 - val_accuracy: 0.7708\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5315 - val_accuracy: 0.7708\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8177 - val_loss: 0.5316 - val_accuracy: 0.7708\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5316 - val_accuracy: 0.7708\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5316 - val_accuracy: 0.7708\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5317 - val_accuracy: 0.7708\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5316 - val_accuracy: 0.7708\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5316 - val_accuracy: 0.7708\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8194 - val_loss: 0.5316 - val_accuracy: 0.7708\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8177 - val_loss: 0.5317 - val_accuracy: 0.7708\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8177 - val_loss: 0.5318 - val_accuracy: 0.7708\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8177 - val_loss: 0.5319 - val_accuracy: 0.7708\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5319 - val_accuracy: 0.7708\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8177 - val_loss: 0.5320 - val_accuracy: 0.7708\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3962 - accuracy: 0.8177 - val_loss: 0.5320 - val_accuracy: 0.7708\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8177 - val_loss: 0.5320 - val_accuracy: 0.7708\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8177 - val_loss: 0.5321 - val_accuracy: 0.7708\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8177 - val_loss: 0.5321 - val_accuracy: 0.7708\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8194 - val_loss: 0.5321 - val_accuracy: 0.7708\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8177 - val_loss: 0.5322 - val_accuracy: 0.7708\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8177 - val_loss: 0.5322 - val_accuracy: 0.7708\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3961 - accuracy: 0.8177 - val_loss: 0.5321 - val_accuracy: 0.7708\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8177 - val_loss: 0.5322 - val_accuracy: 0.7708\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5321 - val_accuracy: 0.7708\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3960 - accuracy: 0.8177 - val_loss: 0.5321 - val_accuracy: 0.7708\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8194 - val_loss: 0.5322 - val_accuracy: 0.7708\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8177 - val_loss: 0.5323 - val_accuracy: 0.7708\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8177 - val_loss: 0.5323 - val_accuracy: 0.7708\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8177 - val_loss: 0.5324 - val_accuracy: 0.7708\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5324 - val_accuracy: 0.7708\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5324 - val_accuracy: 0.7708\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8177 - val_loss: 0.5325 - val_accuracy: 0.7708\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5326 - val_accuracy: 0.7708\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5326 - val_accuracy: 0.7708\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5327 - val_accuracy: 0.7708\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5326 - val_accuracy: 0.7708\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5326 - val_accuracy: 0.7708\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5327 - val_accuracy: 0.7708\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5326 - val_accuracy: 0.7708\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8194 - val_loss: 0.5327 - val_accuracy: 0.7708\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8177 - val_loss: 0.5327 - val_accuracy: 0.7708\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8177 - val_loss: 0.5328 - val_accuracy: 0.7708\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5328 - val_accuracy: 0.7708\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5329 - val_accuracy: 0.7708\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5330 - val_accuracy: 0.7708\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5330 - val_accuracy: 0.7708\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5330 - val_accuracy: 0.7708\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5331 - val_accuracy: 0.7708\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5331 - val_accuracy: 0.7708\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5331 - val_accuracy: 0.7656\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5332 - val_accuracy: 0.7708\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5333 - val_accuracy: 0.7708\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5334 - val_accuracy: 0.7708\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5334 - val_accuracy: 0.7708\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8177 - val_loss: 0.5334 - val_accuracy: 0.7708\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5336 - val_accuracy: 0.7708\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5337 - val_accuracy: 0.7708\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5337 - val_accuracy: 0.7708\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5338 - val_accuracy: 0.7708\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5336 - val_accuracy: 0.7656\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8177 - val_loss: 0.5337 - val_accuracy: 0.7656\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5337 - val_accuracy: 0.7656\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5338 - val_accuracy: 0.7708\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5338 - val_accuracy: 0.7656\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5337 - val_accuracy: 0.7656\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5338 - val_accuracy: 0.7656\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5338 - val_accuracy: 0.7656\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5339 - val_accuracy: 0.7656\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5340 - val_accuracy: 0.7656\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5341 - val_accuracy: 0.7656\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5342 - val_accuracy: 0.7656\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5341 - val_accuracy: 0.7656\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5342 - val_accuracy: 0.7656\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5343 - val_accuracy: 0.7656\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8177 - val_loss: 0.5342 - val_accuracy: 0.7656\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8177 - val_loss: 0.5343 - val_accuracy: 0.7656\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5344 - val_accuracy: 0.7656\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5344 - val_accuracy: 0.7656\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8177 - val_loss: 0.5344 - val_accuracy: 0.7656\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8177 - val_loss: 0.5344 - val_accuracy: 0.7656\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8177 - val_loss: 0.5344 - val_accuracy: 0.7656\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5345 - val_accuracy: 0.7656\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8177 - val_loss: 0.5345 - val_accuracy: 0.7656\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5345 - val_accuracy: 0.7656\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5344 - val_accuracy: 0.7656\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5345 - val_accuracy: 0.7656\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5345 - val_accuracy: 0.7656\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5346 - val_accuracy: 0.7656\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5346 - val_accuracy: 0.7656\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5346 - val_accuracy: 0.7656\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5347 - val_accuracy: 0.7656\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5348 - val_accuracy: 0.7656\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5348 - val_accuracy: 0.7656\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5347 - val_accuracy: 0.7656\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5348 - val_accuracy: 0.7656\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8177 - val_loss: 0.5347 - val_accuracy: 0.7656\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5347 - val_accuracy: 0.7656\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5348 - val_accuracy: 0.7656\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8194 - val_loss: 0.5348 - val_accuracy: 0.7656\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8177 - val_loss: 0.5349 - val_accuracy: 0.7656\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8177 - val_loss: 0.5349 - val_accuracy: 0.7656\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8177 - val_loss: 0.5350 - val_accuracy: 0.7656\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5351 - val_accuracy: 0.7656\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8194 - val_loss: 0.5351 - val_accuracy: 0.7656\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8177 - val_loss: 0.5351 - val_accuracy: 0.7656\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8177 - val_loss: 0.5351 - val_accuracy: 0.7656\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8177 - val_loss: 0.5352 - val_accuracy: 0.7656\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8194 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8194 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8177 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8194 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8194 - val_loss: 0.5354 - val_accuracy: 0.7656\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8177 - val_loss: 0.5354 - val_accuracy: 0.7656\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8194 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8177 - val_loss: 0.5352 - val_accuracy: 0.7656\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8177 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8194 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8194 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 0.5354 - val_accuracy: 0.7656\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8177 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 0.5354 - val_accuracy: 0.7656\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 0.5352 - val_accuracy: 0.7656\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8194 - val_loss: 0.5352 - val_accuracy: 0.7656\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 0.5352 - val_accuracy: 0.7656\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5353 - val_accuracy: 0.7656\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5354 - val_accuracy: 0.7656\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7656\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7656\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7656\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8194 - val_loss: 0.5357 - val_accuracy: 0.7656\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5357 - val_accuracy: 0.7656\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7656\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7656\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7656\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3948 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7656\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.8194 - val_loss: 0.5356 - val_accuracy: 0.7656\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8194 - val_loss: 0.5357 - val_accuracy: 0.7656\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8194 - val_loss: 0.5357 - val_accuracy: 0.7656\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8194 - val_loss: 0.5357 - val_accuracy: 0.7656\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8212 - val_loss: 0.5358 - val_accuracy: 0.7656\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8194 - val_loss: 0.5358 - val_accuracy: 0.7656\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8194 - val_loss: 0.5358 - val_accuracy: 0.7656\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5359 - val_accuracy: 0.7656\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5359 - val_accuracy: 0.7656\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8212 - val_loss: 0.5359 - val_accuracy: 0.7656\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8194 - val_loss: 0.5360 - val_accuracy: 0.7656\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8212 - val_loss: 0.5360 - val_accuracy: 0.7656\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5359 - val_accuracy: 0.7656\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5359 - val_accuracy: 0.7656\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5359 - val_accuracy: 0.7656\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3945 - accuracy: 0.8212 - val_loss: 0.5360 - val_accuracy: 0.7656\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8212 - val_loss: 0.5360 - val_accuracy: 0.7656\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8194 - val_loss: 0.5360 - val_accuracy: 0.7656\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3945 - accuracy: 0.8212 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3945 - accuracy: 0.8194 - val_loss: 0.5363 - val_accuracy: 0.7656\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8212 - val_loss: 0.5362 - val_accuracy: 0.7656\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8194 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8194 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8194 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8212 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.8194 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8194 - val_loss: 0.5362 - val_accuracy: 0.7656\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8194 - val_loss: 0.5362 - val_accuracy: 0.7656\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8194 - val_loss: 0.5362 - val_accuracy: 0.7656\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8194 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8194 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8194 - val_loss: 0.5360 - val_accuracy: 0.7656\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8194 - val_loss: 0.5360 - val_accuracy: 0.7656\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8194 - val_loss: 0.5360 - val_accuracy: 0.7656\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8194 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8194 - val_loss: 0.5362 - val_accuracy: 0.7656\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8194 - val_loss: 0.5363 - val_accuracy: 0.7656\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8194 - val_loss: 0.5363 - val_accuracy: 0.7656\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8194 - val_loss: 0.5364 - val_accuracy: 0.7656\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8194 - val_loss: 0.5364 - val_accuracy: 0.7656\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8194 - val_loss: 0.5364 - val_accuracy: 0.7656\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8194 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3943 - accuracy: 0.8194 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8194 - val_loss: 0.5364 - val_accuracy: 0.7656\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8194 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8194 - val_loss: 0.5366 - val_accuracy: 0.7656\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8194 - val_loss: 0.5366 - val_accuracy: 0.7656\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8194 - val_loss: 0.5366 - val_accuracy: 0.7656\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8194 - val_loss: 0.5366 - val_accuracy: 0.7656\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8194 - val_loss: 0.5366 - val_accuracy: 0.7656\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8194 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8194 - val_loss: 0.5366 - val_accuracy: 0.7656\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8194 - val_loss: 0.5368 - val_accuracy: 0.7656\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5367 - val_accuracy: 0.7656\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5367 - val_accuracy: 0.7656\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5367 - val_accuracy: 0.7656\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5367 - val_accuracy: 0.7656\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5368 - val_accuracy: 0.7656\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8194 - val_loss: 0.5369 - val_accuracy: 0.7656\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8194 - val_loss: 0.5370 - val_accuracy: 0.7656\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8194 - val_loss: 0.5370 - val_accuracy: 0.7656\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5370 - val_accuracy: 0.7656\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8194 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8194 - val_loss: 0.5370 - val_accuracy: 0.7656\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8194 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8194 - val_loss: 0.5370 - val_accuracy: 0.7656\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8194 - val_loss: 0.5370 - val_accuracy: 0.7656\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8194 - val_loss: 0.5370 - val_accuracy: 0.7656\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8194 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8194 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8194 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8194 - val_loss: 0.5370 - val_accuracy: 0.7656\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5372 - val_accuracy: 0.7656\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8194 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8194 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8194 - val_loss: 0.5370 - val_accuracy: 0.7656\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5372 - val_accuracy: 0.7656\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8212 - val_loss: 0.5372 - val_accuracy: 0.7656\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5372 - val_accuracy: 0.7656\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8212 - val_loss: 0.5371 - val_accuracy: 0.7656\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8212 - val_loss: 0.5372 - val_accuracy: 0.7656\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5374 - val_accuracy: 0.7656\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5374 - val_accuracy: 0.7656\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5374 - val_accuracy: 0.7656\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8229 - val_loss: 0.5375 - val_accuracy: 0.7656\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8212 - val_loss: 0.5374 - val_accuracy: 0.7656\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5374 - val_accuracy: 0.7656\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5374 - val_accuracy: 0.7656\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8212 - val_loss: 0.5374 - val_accuracy: 0.7656\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8212 - val_loss: 0.5375 - val_accuracy: 0.7656\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8229 - val_loss: 0.5375 - val_accuracy: 0.7656\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5375 - val_accuracy: 0.7656\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8212 - val_loss: 0.5375 - val_accuracy: 0.7656\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5376 - val_accuracy: 0.7656\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5376 - val_accuracy: 0.7656\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8212 - val_loss: 0.5376 - val_accuracy: 0.7656\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8229 - val_loss: 0.5376 - val_accuracy: 0.7656\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8212 - val_loss: 0.5376 - val_accuracy: 0.7656\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5377 - val_accuracy: 0.7656\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8212 - val_loss: 0.5377 - val_accuracy: 0.7656\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5378 - val_accuracy: 0.7604\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8212 - val_loss: 0.5377 - val_accuracy: 0.7656\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8212 - val_loss: 0.5377 - val_accuracy: 0.7656\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8212 - val_loss: 0.5376 - val_accuracy: 0.7656\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8212 - val_loss: 0.5377 - val_accuracy: 0.7656\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8212 - val_loss: 0.5377 - val_accuracy: 0.7656\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8229 - val_loss: 0.5377 - val_accuracy: 0.7656\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8229 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8229 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8212 - val_loss: 0.5378 - val_accuracy: 0.7656\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8229 - val_loss: 0.5378 - val_accuracy: 0.7604\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8229 - val_loss: 0.5380 - val_accuracy: 0.7604\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8212 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8212 - val_loss: 0.5378 - val_accuracy: 0.7656\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8229 - val_loss: 0.5379 - val_accuracy: 0.7656\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8212 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8212 - val_loss: 0.5380 - val_accuracy: 0.7604\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8229 - val_loss: 0.5380 - val_accuracy: 0.7604\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8212 - val_loss: 0.5381 - val_accuracy: 0.7604\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8212 - val_loss: 0.5380 - val_accuracy: 0.7604\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8229 - val_loss: 0.5379 - val_accuracy: 0.7656\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8229 - val_loss: 0.5378 - val_accuracy: 0.7656\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8229 - val_loss: 0.5377 - val_accuracy: 0.7656\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8229 - val_loss: 0.5378 - val_accuracy: 0.7656\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8212 - val_loss: 0.5377 - val_accuracy: 0.7656\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8229 - val_loss: 0.5379 - val_accuracy: 0.7656\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3932 - accuracy: 0.8229 - val_loss: 0.5380 - val_accuracy: 0.7656\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8229 - val_loss: 0.5381 - val_accuracy: 0.7604\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8212 - val_loss: 0.5380 - val_accuracy: 0.7552\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8229 - val_loss: 0.5381 - val_accuracy: 0.7604\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8229 - val_loss: 0.5382 - val_accuracy: 0.7604\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3933 - accuracy: 0.8212 - val_loss: 0.5382 - val_accuracy: 0.7552\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8229 - val_loss: 0.5381 - val_accuracy: 0.7604\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8229 - val_loss: 0.5381 - val_accuracy: 0.7604\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8229 - val_loss: 0.5383 - val_accuracy: 0.7604\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8229 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8212 - val_loss: 0.5382 - val_accuracy: 0.7604\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8229 - val_loss: 0.5383 - val_accuracy: 0.7604\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8229 - val_loss: 0.5383 - val_accuracy: 0.7604\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3931 - accuracy: 0.8229 - val_loss: 0.5383 - val_accuracy: 0.7604\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8212 - val_loss: 0.5383 - val_accuracy: 0.7604\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8229 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8212 - val_loss: 0.5383 - val_accuracy: 0.7604\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3930 - accuracy: 0.8229 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3931 - accuracy: 0.8229 - val_loss: 0.5385 - val_accuracy: 0.7604\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8229 - val_loss: 0.5383 - val_accuracy: 0.7604\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8229 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8229 - val_loss: 0.5385 - val_accuracy: 0.7604\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8229 - val_loss: 0.5384 - val_accuracy: 0.7604\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8229 - val_loss: 0.5385 - val_accuracy: 0.7604\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8247 - val_loss: 0.5385 - val_accuracy: 0.7604\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8247 - val_loss: 0.5386 - val_accuracy: 0.7604\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8229 - val_loss: 0.5387 - val_accuracy: 0.7604\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8264 - val_loss: 0.5387 - val_accuracy: 0.7604\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3932 - accuracy: 0.8247 - val_loss: 0.5387 - val_accuracy: 0.7604\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8229 - val_loss: 0.5385 - val_accuracy: 0.7604\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8264 - val_loss: 0.5386 - val_accuracy: 0.7604\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8247 - val_loss: 0.5387 - val_accuracy: 0.7604\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3930 - accuracy: 0.8229 - val_loss: 0.5387 - val_accuracy: 0.7604\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8247 - val_loss: 0.5386 - val_accuracy: 0.7604\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8264 - val_loss: 0.5386 - val_accuracy: 0.7604\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8264 - val_loss: 0.5387 - val_accuracy: 0.7604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nnew2 = new_model2.predict(X_test_norm)\n",
        "y_pred_class_nnew2 = (y_pred_prob_nnew2 > 0.5).astype('int32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wpG0IyvAVBT",
        "outputId": "67683388-533c-4f52-995f-05f9c15c8a6d"
      },
      "id": "_wpG0IyvAVBT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nnew2[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "074jaBcaAXmk",
        "outputId": "12a8884a-40cb-4e6c-8b3f-1caab5164cc6"
      },
      "id": "074jaBcaAXmk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nnew2[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytW4i5I2AtSX",
        "outputId": "8ede479c-f341-4a99-cf61-43a89ef9622d"
      },
      "id": "ytW4i5I2AtSX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6447143 ],\n",
              "       [0.762542  ],\n",
              "       [0.3831105 ],\n",
              "       [0.11248234],\n",
              "       [0.24771403],\n",
              "       [0.53396714],\n",
              "       [0.01348655],\n",
              "       [0.45988557],\n",
              "       [0.887487  ],\n",
              "       [0.1467733 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc(y_test, y_pred, new_model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(new_model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ],
      "metadata": {
        "id": "M8zZat7oAcWV"
      },
      "id": "M8zZat7oAcWV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nnew2)))#y_pred_prob_nnew\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nnew2)))#y_pred_prob_nnew\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nnew2, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "xnLwhhmTAeBQ",
        "outputId": "0386f8bf-e49b-496d-c168-cb0e027244bc"
      },
      "id": "xnLwhhmTAeBQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.771\n",
            "roc-auc is 0.827\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This model shows the accuracy, standing at 74.5%, signifies that the model's predictions were correct at some point. In terms of ROC-AUC, it achieved a  score of 0.803. This assesses the model's capability to distinguish between positive and negative instances, with higher values suggesting a superior separation between classes. But overall, not a good model."
      ],
      "metadata": {
        "id": "zK5fbYqqDxp0"
      },
      "id": "zK5fbYqqDxp0"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9EU6RxWdDvJx"
      },
      "id": "9EU6RxWdDvJx"
    },
    {
      "cell_type": "code",
      "source": [
        "run_hist_3.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXvzp0Y5AipY",
        "outputId": "94362618-a7e5-475c-e6d3-dcfe50a3ece7"
      },
      "id": "WXvzp0Y5AipY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(run_hist_3.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_3.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "zVVGeZ_sAmoh",
        "outputId": "9ec3efa4-dcd5-4cf7-aa73-b7675a8710b5"
      },
      "id": "zVVGeZ_sAmoh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cf71b2d7310>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_3.history['accuracy'], 'y', label = 'Train Accuracy')\n",
        "ax.plot(run_hist_3.history['val_accuracy'], 'g', label = 'Val Accuracy')\n",
        "plt.title(\"Model 2 Accuracy Graph\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "FpU8n-6DAnmX",
        "outputId": "c00b9be6-6a7b-4e47-f878-be7db0e27762"
      },
      "id": "FpU8n-6DAnmX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7cf71b02ded0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Byukilmaz.csv"
      ],
      "metadata": {
        "id": "UxBBZzaeMIq3"
      },
      "id": "UxBBZzaeMIq3"
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "B2FHYuNuJcgH"
      },
      "id": "B2FHYuNuJcgH",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ],
      "metadata": {
        "id": "sxpN8CT4JeLU"
      },
      "id": "sxpN8CT4JeLU",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "byu_df = pd.read_csv('/content/drive/Shareddrives/CPE312/HOA5/buyukyilmaz.csv')\n",
        "byu_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nQpTtsUhJfpI",
        "outputId": "8443cea9-69c6-4e27-dcf6-bde66253f42a"
      },
      "id": "nQpTtsUhJfpI",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
              "0     0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
              "1     0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
              "2     0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
              "3     0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
              "4     0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
              "...        ...       ...       ...       ...       ...       ...        ...   \n",
              "3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
              "3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
              "3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936   1.876502   \n",
              "3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435   1.591065   \n",
              "3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
              "\n",
              "             kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
              "0      274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
              "1      634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
              "2     1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
              "3        4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
              "4        4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
              "...           ...       ...       ...  ...       ...       ...       ...   \n",
              "3163     6.630383  0.962934  0.763182  ...  0.131884  0.182790  0.083770   \n",
              "3164     2.503954  0.960716  0.709570  ...  0.116221  0.188980  0.034409   \n",
              "3165     6.604509  0.946854  0.654196  ...  0.142056  0.209918  0.039506   \n",
              "3166     5.388298  0.950436  0.675470  ...  0.143659  0.172375  0.034483   \n",
              "3167     5.769115  0.938829  0.601529  ...  0.165509  0.185607  0.062257   \n",
              "\n",
              "        maxfun   meandom    mindom    maxdom   dfrange   modindx  gender  \n",
              "0     0.275862  0.007812  0.007812  0.007812  0.000000  0.000000    male  \n",
              "1     0.250000  0.009014  0.007812  0.054688  0.046875  0.052632    male  \n",
              "2     0.271186  0.007990  0.007812  0.015625  0.007812  0.046512    male  \n",
              "3     0.250000  0.201497  0.007812  0.562500  0.554688  0.247119    male  \n",
              "4     0.266667  0.712812  0.007812  5.484375  5.476562  0.208274    male  \n",
              "...        ...       ...       ...       ...       ...       ...     ...  \n",
              "3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929  female  \n",
              "3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897  female  \n",
              "3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759  female  \n",
              "3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002  female  \n",
              "3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000  female  \n",
              "\n",
              "[3168 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9443f80-cd43-4170-a029-7c4cd6b7c4f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meanfreq</th>\n",
              "      <th>sd</th>\n",
              "      <th>median</th>\n",
              "      <th>Q25</th>\n",
              "      <th>Q75</th>\n",
              "      <th>IQR</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurt</th>\n",
              "      <th>sp.ent</th>\n",
              "      <th>sfm</th>\n",
              "      <th>...</th>\n",
              "      <th>centroid</th>\n",
              "      <th>meanfun</th>\n",
              "      <th>minfun</th>\n",
              "      <th>maxfun</th>\n",
              "      <th>meandom</th>\n",
              "      <th>mindom</th>\n",
              "      <th>maxdom</th>\n",
              "      <th>dfrange</th>\n",
              "      <th>modindx</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.059781</td>\n",
              "      <td>0.064241</td>\n",
              "      <td>0.032027</td>\n",
              "      <td>0.015071</td>\n",
              "      <td>0.090193</td>\n",
              "      <td>0.075122</td>\n",
              "      <td>12.863462</td>\n",
              "      <td>274.402906</td>\n",
              "      <td>0.893369</td>\n",
              "      <td>0.491918</td>\n",
              "      <td>...</td>\n",
              "      <td>0.059781</td>\n",
              "      <td>0.084279</td>\n",
              "      <td>0.015702</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.066009</td>\n",
              "      <td>0.067310</td>\n",
              "      <td>0.040229</td>\n",
              "      <td>0.019414</td>\n",
              "      <td>0.092666</td>\n",
              "      <td>0.073252</td>\n",
              "      <td>22.423285</td>\n",
              "      <td>634.613855</td>\n",
              "      <td>0.892193</td>\n",
              "      <td>0.513724</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066009</td>\n",
              "      <td>0.107937</td>\n",
              "      <td>0.015826</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.009014</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.054688</td>\n",
              "      <td>0.046875</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.077316</td>\n",
              "      <td>0.083829</td>\n",
              "      <td>0.036718</td>\n",
              "      <td>0.008701</td>\n",
              "      <td>0.131908</td>\n",
              "      <td>0.123207</td>\n",
              "      <td>30.757155</td>\n",
              "      <td>1024.927705</td>\n",
              "      <td>0.846389</td>\n",
              "      <td>0.478905</td>\n",
              "      <td>...</td>\n",
              "      <td>0.077316</td>\n",
              "      <td>0.098706</td>\n",
              "      <td>0.015656</td>\n",
              "      <td>0.271186</td>\n",
              "      <td>0.007990</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.046512</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.151228</td>\n",
              "      <td>0.072111</td>\n",
              "      <td>0.158011</td>\n",
              "      <td>0.096582</td>\n",
              "      <td>0.207955</td>\n",
              "      <td>0.111374</td>\n",
              "      <td>1.232831</td>\n",
              "      <td>4.177296</td>\n",
              "      <td>0.963322</td>\n",
              "      <td>0.727232</td>\n",
              "      <td>...</td>\n",
              "      <td>0.151228</td>\n",
              "      <td>0.088965</td>\n",
              "      <td>0.017798</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.201497</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.554688</td>\n",
              "      <td>0.247119</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.135120</td>\n",
              "      <td>0.079146</td>\n",
              "      <td>0.124656</td>\n",
              "      <td>0.078720</td>\n",
              "      <td>0.206045</td>\n",
              "      <td>0.127325</td>\n",
              "      <td>1.101174</td>\n",
              "      <td>4.333713</td>\n",
              "      <td>0.971955</td>\n",
              "      <td>0.783568</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135120</td>\n",
              "      <td>0.106398</td>\n",
              "      <td>0.016931</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.712812</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>5.484375</td>\n",
              "      <td>5.476562</td>\n",
              "      <td>0.208274</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3163</th>\n",
              "      <td>0.131884</td>\n",
              "      <td>0.084734</td>\n",
              "      <td>0.153707</td>\n",
              "      <td>0.049285</td>\n",
              "      <td>0.201144</td>\n",
              "      <td>0.151859</td>\n",
              "      <td>1.762129</td>\n",
              "      <td>6.630383</td>\n",
              "      <td>0.962934</td>\n",
              "      <td>0.763182</td>\n",
              "      <td>...</td>\n",
              "      <td>0.131884</td>\n",
              "      <td>0.182790</td>\n",
              "      <td>0.083770</td>\n",
              "      <td>0.262295</td>\n",
              "      <td>0.832899</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>4.210938</td>\n",
              "      <td>4.203125</td>\n",
              "      <td>0.161929</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3164</th>\n",
              "      <td>0.116221</td>\n",
              "      <td>0.089221</td>\n",
              "      <td>0.076758</td>\n",
              "      <td>0.042718</td>\n",
              "      <td>0.204911</td>\n",
              "      <td>0.162193</td>\n",
              "      <td>0.693730</td>\n",
              "      <td>2.503954</td>\n",
              "      <td>0.960716</td>\n",
              "      <td>0.709570</td>\n",
              "      <td>...</td>\n",
              "      <td>0.116221</td>\n",
              "      <td>0.188980</td>\n",
              "      <td>0.034409</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.909856</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>3.679688</td>\n",
              "      <td>3.640625</td>\n",
              "      <td>0.277897</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3165</th>\n",
              "      <td>0.142056</td>\n",
              "      <td>0.095798</td>\n",
              "      <td>0.183731</td>\n",
              "      <td>0.033424</td>\n",
              "      <td>0.224360</td>\n",
              "      <td>0.190936</td>\n",
              "      <td>1.876502</td>\n",
              "      <td>6.604509</td>\n",
              "      <td>0.946854</td>\n",
              "      <td>0.654196</td>\n",
              "      <td>...</td>\n",
              "      <td>0.142056</td>\n",
              "      <td>0.209918</td>\n",
              "      <td>0.039506</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.494271</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>2.937500</td>\n",
              "      <td>2.929688</td>\n",
              "      <td>0.194759</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3166</th>\n",
              "      <td>0.143659</td>\n",
              "      <td>0.090628</td>\n",
              "      <td>0.184976</td>\n",
              "      <td>0.043508</td>\n",
              "      <td>0.219943</td>\n",
              "      <td>0.176435</td>\n",
              "      <td>1.591065</td>\n",
              "      <td>5.388298</td>\n",
              "      <td>0.950436</td>\n",
              "      <td>0.675470</td>\n",
              "      <td>...</td>\n",
              "      <td>0.143659</td>\n",
              "      <td>0.172375</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.791360</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>3.593750</td>\n",
              "      <td>3.585938</td>\n",
              "      <td>0.311002</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3167</th>\n",
              "      <td>0.165509</td>\n",
              "      <td>0.092884</td>\n",
              "      <td>0.183044</td>\n",
              "      <td>0.070072</td>\n",
              "      <td>0.250827</td>\n",
              "      <td>0.180756</td>\n",
              "      <td>1.705029</td>\n",
              "      <td>5.769115</td>\n",
              "      <td>0.938829</td>\n",
              "      <td>0.601529</td>\n",
              "      <td>...</td>\n",
              "      <td>0.165509</td>\n",
              "      <td>0.185607</td>\n",
              "      <td>0.062257</td>\n",
              "      <td>0.271186</td>\n",
              "      <td>0.227022</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.554688</td>\n",
              "      <td>0.546875</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3168 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9443f80-cd43-4170-a029-7c4cd6b7c4f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9443f80-cd43-4170-a029-7c4cd6b7c4f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9443f80-cd43-4170-a029-7c4cd6b7c4f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83dc13ca-774c-46ec-b11f-21c9f1f86d72\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83dc13ca-774c-46ec-b11f-21c9f1f86d72')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83dc13ca-774c-46ec-b11f-21c9f1f86d72 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Data Shape: ', byu_df.shape, '\\n\\n')\n",
        "print('Data Types:\\n', byu_df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTdb67ZXJ9XU",
        "outputId": "ca845c40-853f-412b-83c3-70a1ce05bd89"
      },
      "id": "CTdb67ZXJ9XU",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Shape:  (3168, 21) \n",
            "\n",
            "\n",
            "Data Types:\n",
            " meanfreq    float64\n",
            "sd          float64\n",
            "median      float64\n",
            "Q25         float64\n",
            "Q75         float64\n",
            "IQR         float64\n",
            "skew        float64\n",
            "kurt        float64\n",
            "sp.ent      float64\n",
            "sfm         float64\n",
            "mode        float64\n",
            "centroid    float64\n",
            "meanfun     float64\n",
            "minfun      float64\n",
            "maxfun      float64\n",
            "meandom     float64\n",
            "mindom      float64\n",
            "maxdom      float64\n",
            "dfrange     float64\n",
            "modindx     float64\n",
            "gender       object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "byu_df.gender = le.fit_transform(byu_df.gender)"
      ],
      "metadata": {
        "id": "GBz67u81KAkt"
      },
      "id": "GBz67u81KAkt",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = byu_df.drop('gender', axis = 1).values\n",
        "y = byu_df.gender.values"
      ],
      "metadata": {
        "id": "wV19pseWKNWr"
      },
      "id": "wV19pseWKNWr",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ],
      "metadata": {
        "id": "VTGRwQUmKXS8"
      },
      "id": "VTGRwQUmKXS8",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = StandardScaler()\n",
        "X_train_norm = sc.fit_transform(X_train)\n",
        "X_test_norm = sc.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "APNxuWEBKZKt"
      },
      "id": "APNxuWEBKZKt",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_supp = Sequential([\n",
        " Dense(6, input_shape = (20, ), activation = 'relu'),\n",
        " Dense(1, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "1MXtqUsyKccv"
      },
      "id": "1MXtqUsyKccv",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_supp.compile(SGD(lr = 0.003), \"binary_crossentropy\", metrics = ['accuracy'])\n",
        "\n",
        "run_hist_supp = model_supp.fit(X_train_norm, y_train, validation_data = (X_test_norm, y_test), epochs = 1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gExc4WSYKi3m",
        "outputId": "d49ea2e3-0385-49db-b041-6719ed383278"
      },
      "id": "gExc4WSYKi3m",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "75/75 [==============================] - 1s 5ms/step - loss: 0.7041 - accuracy: 0.6128 - val_loss: 0.5912 - val_accuracy: 0.7462\n",
            "Epoch 2/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.8169 - val_loss: 0.4707 - val_accuracy: 0.8497\n",
            "Epoch 3/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8817 - val_loss: 0.3884 - val_accuracy: 0.8851\n",
            "Epoch 4/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.9066 - val_loss: 0.3264 - val_accuracy: 0.9015\n",
            "Epoch 5/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2921 - accuracy: 0.9221 - val_loss: 0.2798 - val_accuracy: 0.9205\n",
            "Epoch 6/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.9343 - val_loss: 0.2439 - val_accuracy: 0.9268\n",
            "Epoch 7/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9457 - val_loss: 0.2158 - val_accuracy: 0.9318\n",
            "Epoch 8/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1958 - accuracy: 0.9516 - val_loss: 0.1947 - val_accuracy: 0.9369\n",
            "Epoch 9/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1773 - accuracy: 0.9554 - val_loss: 0.1780 - val_accuracy: 0.9432\n",
            "Epoch 10/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 0.9609 - val_loss: 0.1650 - val_accuracy: 0.9508\n",
            "Epoch 11/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9646 - val_loss: 0.1540 - val_accuracy: 0.9571\n",
            "Epoch 12/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9680 - val_loss: 0.1453 - val_accuracy: 0.9634\n",
            "Epoch 13/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9693 - val_loss: 0.1376 - val_accuracy: 0.9634\n",
            "Epoch 14/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9705 - val_loss: 0.1310 - val_accuracy: 0.9646\n",
            "Epoch 15/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1194 - accuracy: 0.9705 - val_loss: 0.1258 - val_accuracy: 0.9672\n",
            "Epoch 16/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.9718 - val_loss: 0.1211 - val_accuracy: 0.9672\n",
            "Epoch 17/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9722 - val_loss: 0.1170 - val_accuracy: 0.9697\n",
            "Epoch 18/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 0.9722 - val_loss: 0.1135 - val_accuracy: 0.9722\n",
            "Epoch 19/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9735 - val_loss: 0.1107 - val_accuracy: 0.9710\n",
            "Epoch 20/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9735 - val_loss: 0.1084 - val_accuracy: 0.9710\n",
            "Epoch 21/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0977 - accuracy: 0.9743 - val_loss: 0.1061 - val_accuracy: 0.9722\n",
            "Epoch 22/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0954 - accuracy: 0.9743 - val_loss: 0.1042 - val_accuracy: 0.9722\n",
            "Epoch 23/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0935 - accuracy: 0.9743 - val_loss: 0.1025 - val_accuracy: 0.9722\n",
            "Epoch 24/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9747 - val_loss: 0.1010 - val_accuracy: 0.9722\n",
            "Epoch 25/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9747 - val_loss: 0.0998 - val_accuracy: 0.9722\n",
            "Epoch 26/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9752 - val_loss: 0.0987 - val_accuracy: 0.9735\n",
            "Epoch 27/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9747 - val_loss: 0.0974 - val_accuracy: 0.9735\n",
            "Epoch 28/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9747 - val_loss: 0.0964 - val_accuracy: 0.9735\n",
            "Epoch 29/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9760 - val_loss: 0.0954 - val_accuracy: 0.9735\n",
            "Epoch 30/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9756 - val_loss: 0.0947 - val_accuracy: 0.9735\n",
            "Epoch 31/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9756 - val_loss: 0.0938 - val_accuracy: 0.9747\n",
            "Epoch 32/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9764 - val_loss: 0.0935 - val_accuracy: 0.9735\n",
            "Epoch 33/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9764 - val_loss: 0.0928 - val_accuracy: 0.9735\n",
            "Epoch 34/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9764 - val_loss: 0.0919 - val_accuracy: 0.9747\n",
            "Epoch 35/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.9769 - val_loss: 0.0913 - val_accuracy: 0.9747\n",
            "Epoch 36/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9769 - val_loss: 0.0909 - val_accuracy: 0.9747\n",
            "Epoch 37/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9769 - val_loss: 0.0904 - val_accuracy: 0.9747\n",
            "Epoch 38/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.9764 - val_loss: 0.0902 - val_accuracy: 0.9747\n",
            "Epoch 39/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9769 - val_loss: 0.0897 - val_accuracy: 0.9747\n",
            "Epoch 40/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.9781 - val_loss: 0.0888 - val_accuracy: 0.9760\n",
            "Epoch 41/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9764 - val_loss: 0.0886 - val_accuracy: 0.9760\n",
            "Epoch 42/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9773 - val_loss: 0.0883 - val_accuracy: 0.9760\n",
            "Epoch 43/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9769 - val_loss: 0.0882 - val_accuracy: 0.9760\n",
            "Epoch 44/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0755 - accuracy: 0.9777 - val_loss: 0.0877 - val_accuracy: 0.9760\n",
            "Epoch 45/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9769 - val_loss: 0.0874 - val_accuracy: 0.9760\n",
            "Epoch 46/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 0.9777 - val_loss: 0.0872 - val_accuracy: 0.9760\n",
            "Epoch 47/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9785 - val_loss: 0.0868 - val_accuracy: 0.9747\n",
            "Epoch 48/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.9790 - val_loss: 0.0866 - val_accuracy: 0.9747\n",
            "Epoch 49/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 0.9785 - val_loss: 0.0862 - val_accuracy: 0.9747\n",
            "Epoch 50/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9773 - val_loss: 0.0861 - val_accuracy: 0.9747\n",
            "Epoch 51/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 0.9785 - val_loss: 0.0859 - val_accuracy: 0.9747\n",
            "Epoch 52/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9785 - val_loss: 0.0857 - val_accuracy: 0.9747\n",
            "Epoch 53/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9785 - val_loss: 0.0853 - val_accuracy: 0.9747\n",
            "Epoch 54/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9785 - val_loss: 0.0852 - val_accuracy: 0.9747\n",
            "Epoch 55/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9790 - val_loss: 0.0849 - val_accuracy: 0.9747\n",
            "Epoch 56/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9785 - val_loss: 0.0847 - val_accuracy: 0.9747\n",
            "Epoch 57/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9785 - val_loss: 0.0845 - val_accuracy: 0.9747\n",
            "Epoch 58/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9790 - val_loss: 0.0844 - val_accuracy: 0.9747\n",
            "Epoch 59/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9794 - val_loss: 0.0842 - val_accuracy: 0.9747\n",
            "Epoch 60/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9790 - val_loss: 0.0841 - val_accuracy: 0.9747\n",
            "Epoch 61/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9785 - val_loss: 0.0839 - val_accuracy: 0.9747\n",
            "Epoch 62/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9790 - val_loss: 0.0837 - val_accuracy: 0.9747\n",
            "Epoch 63/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9790 - val_loss: 0.0835 - val_accuracy: 0.9747\n",
            "Epoch 64/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9790 - val_loss: 0.0833 - val_accuracy: 0.9747\n",
            "Epoch 65/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9790 - val_loss: 0.0833 - val_accuracy: 0.9747\n",
            "Epoch 66/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9790 - val_loss: 0.0834 - val_accuracy: 0.9747\n",
            "Epoch 67/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9790 - val_loss: 0.0832 - val_accuracy: 0.9747\n",
            "Epoch 68/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9790 - val_loss: 0.0830 - val_accuracy: 0.9747\n",
            "Epoch 69/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9790 - val_loss: 0.0829 - val_accuracy: 0.9747\n",
            "Epoch 70/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9790 - val_loss: 0.0827 - val_accuracy: 0.9747\n",
            "Epoch 71/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9794 - val_loss: 0.0826 - val_accuracy: 0.9747\n",
            "Epoch 72/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9790 - val_loss: 0.0824 - val_accuracy: 0.9747\n",
            "Epoch 73/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9790 - val_loss: 0.0824 - val_accuracy: 0.9747\n",
            "Epoch 74/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9785 - val_loss: 0.0822 - val_accuracy: 0.9747\n",
            "Epoch 75/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9794 - val_loss: 0.0821 - val_accuracy: 0.9747\n",
            "Epoch 76/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9790 - val_loss: 0.0821 - val_accuracy: 0.9747\n",
            "Epoch 77/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9794 - val_loss: 0.0820 - val_accuracy: 0.9747\n",
            "Epoch 78/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9794 - val_loss: 0.0820 - val_accuracy: 0.9747\n",
            "Epoch 79/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9794 - val_loss: 0.0820 - val_accuracy: 0.9747\n",
            "Epoch 80/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9747\n",
            "Epoch 81/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.9798 - val_loss: 0.0817 - val_accuracy: 0.9747\n",
            "Epoch 82/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9790 - val_loss: 0.0816 - val_accuracy: 0.9747\n",
            "Epoch 83/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.9785 - val_loss: 0.0818 - val_accuracy: 0.9747\n",
            "Epoch 84/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9794 - val_loss: 0.0816 - val_accuracy: 0.9747\n",
            "Epoch 85/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9794 - val_loss: 0.0814 - val_accuracy: 0.9747\n",
            "Epoch 86/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9794 - val_loss: 0.0812 - val_accuracy: 0.9747\n",
            "Epoch 87/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9781 - val_loss: 0.0811 - val_accuracy: 0.9747\n",
            "Epoch 88/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9790 - val_loss: 0.0810 - val_accuracy: 0.9747\n",
            "Epoch 89/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9798 - val_loss: 0.0809 - val_accuracy: 0.9747\n",
            "Epoch 90/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.9794 - val_loss: 0.0807 - val_accuracy: 0.9747\n",
            "Epoch 91/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9794 - val_loss: 0.0805 - val_accuracy: 0.9747\n",
            "Epoch 92/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.9798 - val_loss: 0.0805 - val_accuracy: 0.9747\n",
            "Epoch 93/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9790 - val_loss: 0.0806 - val_accuracy: 0.9747\n",
            "Epoch 94/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9794 - val_loss: 0.0804 - val_accuracy: 0.9747\n",
            "Epoch 95/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9790 - val_loss: 0.0803 - val_accuracy: 0.9747\n",
            "Epoch 96/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9790 - val_loss: 0.0802 - val_accuracy: 0.9747\n",
            "Epoch 97/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9802 - val_loss: 0.0802 - val_accuracy: 0.9747\n",
            "Epoch 98/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9790 - val_loss: 0.0800 - val_accuracy: 0.9747\n",
            "Epoch 99/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9785 - val_loss: 0.0800 - val_accuracy: 0.9747\n",
            "Epoch 100/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.9794 - val_loss: 0.0799 - val_accuracy: 0.9747\n",
            "Epoch 101/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9798 - val_loss: 0.0798 - val_accuracy: 0.9747\n",
            "Epoch 102/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9790 - val_loss: 0.0799 - val_accuracy: 0.9747\n",
            "Epoch 103/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9794 - val_loss: 0.0798 - val_accuracy: 0.9747\n",
            "Epoch 104/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9798 - val_loss: 0.0797 - val_accuracy: 0.9747\n",
            "Epoch 105/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9802 - val_loss: 0.0798 - val_accuracy: 0.9747\n",
            "Epoch 106/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9798 - val_loss: 0.0796 - val_accuracy: 0.9747\n",
            "Epoch 107/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9794 - val_loss: 0.0797 - val_accuracy: 0.9747\n",
            "Epoch 108/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9798 - val_loss: 0.0796 - val_accuracy: 0.9747\n",
            "Epoch 109/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9802 - val_loss: 0.0797 - val_accuracy: 0.9747\n",
            "Epoch 110/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9798 - val_loss: 0.0795 - val_accuracy: 0.9747\n",
            "Epoch 111/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9802 - val_loss: 0.0796 - val_accuracy: 0.9747\n",
            "Epoch 112/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9798 - val_loss: 0.0796 - val_accuracy: 0.9747\n",
            "Epoch 113/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9798 - val_loss: 0.0794 - val_accuracy: 0.9747\n",
            "Epoch 114/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9802 - val_loss: 0.0794 - val_accuracy: 0.9747\n",
            "Epoch 115/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9798 - val_loss: 0.0797 - val_accuracy: 0.9747\n",
            "Epoch 116/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9802 - val_loss: 0.0794 - val_accuracy: 0.9747\n",
            "Epoch 117/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9798 - val_loss: 0.0793 - val_accuracy: 0.9747\n",
            "Epoch 118/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9798 - val_loss: 0.0792 - val_accuracy: 0.9747\n",
            "Epoch 119/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9798 - val_loss: 0.0791 - val_accuracy: 0.9747\n",
            "Epoch 120/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9802 - val_loss: 0.0792 - val_accuracy: 0.9747\n",
            "Epoch 121/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9798 - val_loss: 0.0790 - val_accuracy: 0.9747\n",
            "Epoch 122/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9798 - val_loss: 0.0791 - val_accuracy: 0.9747\n",
            "Epoch 123/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9798 - val_loss: 0.0790 - val_accuracy: 0.9747\n",
            "Epoch 124/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9794 - val_loss: 0.0790 - val_accuracy: 0.9747\n",
            "Epoch 125/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9802 - val_loss: 0.0790 - val_accuracy: 0.9747\n",
            "Epoch 126/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9798 - val_loss: 0.0789 - val_accuracy: 0.9747\n",
            "Epoch 127/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0648 - accuracy: 0.9798 - val_loss: 0.0788 - val_accuracy: 0.9747\n",
            "Epoch 128/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9798 - val_loss: 0.0788 - val_accuracy: 0.9747\n",
            "Epoch 129/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9802 - val_loss: 0.0787 - val_accuracy: 0.9747\n",
            "Epoch 130/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9798 - val_loss: 0.0786 - val_accuracy: 0.9747\n",
            "Epoch 131/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9802 - val_loss: 0.0787 - val_accuracy: 0.9747\n",
            "Epoch 132/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.9798 - val_loss: 0.0787 - val_accuracy: 0.9747\n",
            "Epoch 133/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9802 - val_loss: 0.0787 - val_accuracy: 0.9747\n",
            "Epoch 134/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9802 - val_loss: 0.0787 - val_accuracy: 0.9747\n",
            "Epoch 135/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9802 - val_loss: 0.0787 - val_accuracy: 0.9747\n",
            "Epoch 136/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9802 - val_loss: 0.0788 - val_accuracy: 0.9747\n",
            "Epoch 137/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9802 - val_loss: 0.0790 - val_accuracy: 0.9735\n",
            "Epoch 138/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9798 - val_loss: 0.0789 - val_accuracy: 0.9747\n",
            "Epoch 139/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9798 - val_loss: 0.0788 - val_accuracy: 0.9747\n",
            "Epoch 140/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.9798 - val_loss: 0.0787 - val_accuracy: 0.9747\n",
            "Epoch 141/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.9798 - val_loss: 0.0786 - val_accuracy: 0.9747\n",
            "Epoch 142/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9798 - val_loss: 0.0785 - val_accuracy: 0.9747\n",
            "Epoch 143/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9802 - val_loss: 0.0787 - val_accuracy: 0.9747\n",
            "Epoch 144/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9798 - val_loss: 0.0786 - val_accuracy: 0.9747\n",
            "Epoch 145/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9802 - val_loss: 0.0786 - val_accuracy: 0.9747\n",
            "Epoch 146/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9798 - val_loss: 0.0783 - val_accuracy: 0.9735\n",
            "Epoch 147/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9802 - val_loss: 0.0784 - val_accuracy: 0.9735\n",
            "Epoch 148/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9798 - val_loss: 0.0784 - val_accuracy: 0.9735\n",
            "Epoch 149/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9798 - val_loss: 0.0784 - val_accuracy: 0.9735\n",
            "Epoch 150/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9802 - val_loss: 0.0784 - val_accuracy: 0.9735\n",
            "Epoch 151/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9802 - val_loss: 0.0785 - val_accuracy: 0.9735\n",
            "Epoch 152/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9798 - val_loss: 0.0785 - val_accuracy: 0.9735\n",
            "Epoch 153/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9798 - val_loss: 0.0784 - val_accuracy: 0.9735\n",
            "Epoch 154/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9798 - val_loss: 0.0781 - val_accuracy: 0.9735\n",
            "Epoch 155/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9802 - val_loss: 0.0783 - val_accuracy: 0.9735\n",
            "Epoch 156/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 0.0782 - val_accuracy: 0.9735\n",
            "Epoch 157/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9794 - val_loss: 0.0782 - val_accuracy: 0.9735\n",
            "Epoch 158/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9798 - val_loss: 0.0784 - val_accuracy: 0.9735\n",
            "Epoch 159/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9798 - val_loss: 0.0785 - val_accuracy: 0.9735\n",
            "Epoch 160/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9798 - val_loss: 0.0784 - val_accuracy: 0.9735\n",
            "Epoch 161/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9802 - val_loss: 0.0783 - val_accuracy: 0.9735\n",
            "Epoch 162/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9798 - val_loss: 0.0784 - val_accuracy: 0.9735\n",
            "Epoch 163/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9798 - val_loss: 0.0783 - val_accuracy: 0.9735\n",
            "Epoch 164/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9798 - val_loss: 0.0782 - val_accuracy: 0.9735\n",
            "Epoch 165/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9798 - val_loss: 0.0783 - val_accuracy: 0.9735\n",
            "Epoch 166/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9798 - val_loss: 0.0782 - val_accuracy: 0.9722\n",
            "Epoch 167/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9798 - val_loss: 0.0782 - val_accuracy: 0.9735\n",
            "Epoch 168/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9802 - val_loss: 0.0781 - val_accuracy: 0.9710\n",
            "Epoch 169/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.0780 - val_accuracy: 0.9710\n",
            "Epoch 170/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.0781 - val_accuracy: 0.9722\n",
            "Epoch 171/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9802 - val_loss: 0.0782 - val_accuracy: 0.9722\n",
            "Epoch 172/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9798 - val_loss: 0.0781 - val_accuracy: 0.9710\n",
            "Epoch 173/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9794 - val_loss: 0.0781 - val_accuracy: 0.9722\n",
            "Epoch 174/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9802 - val_loss: 0.0780 - val_accuracy: 0.9710\n",
            "Epoch 175/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9802 - val_loss: 0.0781 - val_accuracy: 0.9710\n",
            "Epoch 176/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9798 - val_loss: 0.0780 - val_accuracy: 0.9710\n",
            "Epoch 177/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9802 - val_loss: 0.0780 - val_accuracy: 0.9710\n",
            "Epoch 178/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9811 - val_loss: 0.0780 - val_accuracy: 0.9710\n",
            "Epoch 179/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9798 - val_loss: 0.0779 - val_accuracy: 0.9710\n",
            "Epoch 180/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9802 - val_loss: 0.0778 - val_accuracy: 0.9710\n",
            "Epoch 181/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9806 - val_loss: 0.0777 - val_accuracy: 0.9710\n",
            "Epoch 182/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9806 - val_loss: 0.0777 - val_accuracy: 0.9710\n",
            "Epoch 183/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9806 - val_loss: 0.0776 - val_accuracy: 0.9710\n",
            "Epoch 184/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9806 - val_loss: 0.0775 - val_accuracy: 0.9722\n",
            "Epoch 185/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9811 - val_loss: 0.0776 - val_accuracy: 0.9697\n",
            "Epoch 186/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9806 - val_loss: 0.0776 - val_accuracy: 0.9697\n",
            "Epoch 187/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9806 - val_loss: 0.0776 - val_accuracy: 0.9697\n",
            "Epoch 188/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9811 - val_loss: 0.0772 - val_accuracy: 0.9697\n",
            "Epoch 189/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9806 - val_loss: 0.0772 - val_accuracy: 0.9697\n",
            "Epoch 190/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9806 - val_loss: 0.0771 - val_accuracy: 0.9697\n",
            "Epoch 191/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9806 - val_loss: 0.0771 - val_accuracy: 0.9697\n",
            "Epoch 192/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9802 - val_loss: 0.0771 - val_accuracy: 0.9697\n",
            "Epoch 193/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9806 - val_loss: 0.0771 - val_accuracy: 0.9697\n",
            "Epoch 194/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9806 - val_loss: 0.0770 - val_accuracy: 0.9697\n",
            "Epoch 195/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9802 - val_loss: 0.0769 - val_accuracy: 0.9710\n",
            "Epoch 196/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9802 - val_loss: 0.0770 - val_accuracy: 0.9697\n",
            "Epoch 197/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9802 - val_loss: 0.0769 - val_accuracy: 0.9697\n",
            "Epoch 198/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9811 - val_loss: 0.0768 - val_accuracy: 0.9710\n",
            "Epoch 199/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9811 - val_loss: 0.0769 - val_accuracy: 0.9697\n",
            "Epoch 200/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9811 - val_loss: 0.0770 - val_accuracy: 0.9697\n",
            "Epoch 201/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9806 - val_loss: 0.0768 - val_accuracy: 0.9697\n",
            "Epoch 202/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9811 - val_loss: 0.0767 - val_accuracy: 0.9697\n",
            "Epoch 203/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9811 - val_loss: 0.0767 - val_accuracy: 0.9697\n",
            "Epoch 204/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9806 - val_loss: 0.0768 - val_accuracy: 0.9697\n",
            "Epoch 205/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9806 - val_loss: 0.0766 - val_accuracy: 0.9697\n",
            "Epoch 206/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9806 - val_loss: 0.0767 - val_accuracy: 0.9697\n",
            "Epoch 207/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 0.9815 - val_loss: 0.0767 - val_accuracy: 0.9697\n",
            "Epoch 208/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9811 - val_loss: 0.0766 - val_accuracy: 0.9697\n",
            "Epoch 209/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9815 - val_loss: 0.0766 - val_accuracy: 0.9697\n",
            "Epoch 210/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9811 - val_loss: 0.0766 - val_accuracy: 0.9710\n",
            "Epoch 211/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9815 - val_loss: 0.0765 - val_accuracy: 0.9697\n",
            "Epoch 212/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9815 - val_loss: 0.0764 - val_accuracy: 0.9697\n",
            "Epoch 213/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9815 - val_loss: 0.0762 - val_accuracy: 0.9710\n",
            "Epoch 214/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 0.9819 - val_loss: 0.0764 - val_accuracy: 0.9697\n",
            "Epoch 215/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9815 - val_loss: 0.0764 - val_accuracy: 0.9697\n",
            "Epoch 216/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9811 - val_loss: 0.0763 - val_accuracy: 0.9697\n",
            "Epoch 217/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9815 - val_loss: 0.0765 - val_accuracy: 0.9710\n",
            "Epoch 218/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9806 - val_loss: 0.0763 - val_accuracy: 0.9710\n",
            "Epoch 219/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9815 - val_loss: 0.0761 - val_accuracy: 0.9710\n",
            "Epoch 220/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9811 - val_loss: 0.0761 - val_accuracy: 0.9710\n",
            "Epoch 221/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9815 - val_loss: 0.0760 - val_accuracy: 0.9710\n",
            "Epoch 222/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9811 - val_loss: 0.0760 - val_accuracy: 0.9710\n",
            "Epoch 223/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9815 - val_loss: 0.0759 - val_accuracy: 0.9710\n",
            "Epoch 224/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9815 - val_loss: 0.0759 - val_accuracy: 0.9710\n",
            "Epoch 225/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9815 - val_loss: 0.0756 - val_accuracy: 0.9710\n",
            "Epoch 226/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9815 - val_loss: 0.0757 - val_accuracy: 0.9710\n",
            "Epoch 227/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9815 - val_loss: 0.0757 - val_accuracy: 0.9710\n",
            "Epoch 228/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9815 - val_loss: 0.0757 - val_accuracy: 0.9710\n",
            "Epoch 229/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9815 - val_loss: 0.0756 - val_accuracy: 0.9710\n",
            "Epoch 230/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9815 - val_loss: 0.0756 - val_accuracy: 0.9710\n",
            "Epoch 231/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9806 - val_loss: 0.0754 - val_accuracy: 0.9710\n",
            "Epoch 232/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9806 - val_loss: 0.0755 - val_accuracy: 0.9710\n",
            "Epoch 233/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9815 - val_loss: 0.0754 - val_accuracy: 0.9710\n",
            "Epoch 234/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9815 - val_loss: 0.0753 - val_accuracy: 0.9710\n",
            "Epoch 235/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9815 - val_loss: 0.0754 - val_accuracy: 0.9710\n",
            "Epoch 236/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9815 - val_loss: 0.0753 - val_accuracy: 0.9710\n",
            "Epoch 237/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9811 - val_loss: 0.0752 - val_accuracy: 0.9710\n",
            "Epoch 238/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9815 - val_loss: 0.0751 - val_accuracy: 0.9710\n",
            "Epoch 239/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9811 - val_loss: 0.0750 - val_accuracy: 0.9710\n",
            "Epoch 240/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9815 - val_loss: 0.0750 - val_accuracy: 0.9710\n",
            "Epoch 241/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9811 - val_loss: 0.0750 - val_accuracy: 0.9710\n",
            "Epoch 242/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9815 - val_loss: 0.0749 - val_accuracy: 0.9710\n",
            "Epoch 243/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 0.0747 - val_accuracy: 0.9710\n",
            "Epoch 244/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 0.0748 - val_accuracy: 0.9710\n",
            "Epoch 245/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9811 - val_loss: 0.0749 - val_accuracy: 0.9710\n",
            "Epoch 246/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9806 - val_loss: 0.0748 - val_accuracy: 0.9710\n",
            "Epoch 247/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9811 - val_loss: 0.0747 - val_accuracy: 0.9710\n",
            "Epoch 248/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9811 - val_loss: 0.0747 - val_accuracy: 0.9710\n",
            "Epoch 249/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9815 - val_loss: 0.0745 - val_accuracy: 0.9710\n",
            "Epoch 250/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 0.0745 - val_accuracy: 0.9710\n",
            "Epoch 251/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9811 - val_loss: 0.0743 - val_accuracy: 0.9697\n",
            "Epoch 252/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 0.0743 - val_accuracy: 0.9697\n",
            "Epoch 253/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9815 - val_loss: 0.0743 - val_accuracy: 0.9697\n",
            "Epoch 254/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9811 - val_loss: 0.0742 - val_accuracy: 0.9697\n",
            "Epoch 255/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9811 - val_loss: 0.0742 - val_accuracy: 0.9697\n",
            "Epoch 256/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9811 - val_loss: 0.0742 - val_accuracy: 0.9697\n",
            "Epoch 257/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9811 - val_loss: 0.0742 - val_accuracy: 0.9697\n",
            "Epoch 258/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9815 - val_loss: 0.0741 - val_accuracy: 0.9697\n",
            "Epoch 259/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9811 - val_loss: 0.0741 - val_accuracy: 0.9697\n",
            "Epoch 260/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9806 - val_loss: 0.0740 - val_accuracy: 0.9697\n",
            "Epoch 261/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9811 - val_loss: 0.0740 - val_accuracy: 0.9697\n",
            "Epoch 262/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9811 - val_loss: 0.0740 - val_accuracy: 0.9697\n",
            "Epoch 263/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9811 - val_loss: 0.0739 - val_accuracy: 0.9697\n",
            "Epoch 264/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.9806 - val_loss: 0.0739 - val_accuracy: 0.9697\n",
            "Epoch 265/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.9802 - val_loss: 0.0738 - val_accuracy: 0.9697\n",
            "Epoch 266/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9811 - val_loss: 0.0738 - val_accuracy: 0.9697\n",
            "Epoch 267/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9815 - val_loss: 0.0739 - val_accuracy: 0.9697\n",
            "Epoch 268/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9815 - val_loss: 0.0738 - val_accuracy: 0.9697\n",
            "Epoch 269/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9811 - val_loss: 0.0738 - val_accuracy: 0.9697\n",
            "Epoch 270/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9811 - val_loss: 0.0737 - val_accuracy: 0.9697\n",
            "Epoch 271/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9819 - val_loss: 0.0736 - val_accuracy: 0.9710\n",
            "Epoch 272/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9806 - val_loss: 0.0736 - val_accuracy: 0.9710\n",
            "Epoch 273/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.9811 - val_loss: 0.0736 - val_accuracy: 0.9710\n",
            "Epoch 274/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.9811 - val_loss: 0.0736 - val_accuracy: 0.9710\n",
            "Epoch 275/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9806 - val_loss: 0.0736 - val_accuracy: 0.9710\n",
            "Epoch 276/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9806 - val_loss: 0.0735 - val_accuracy: 0.9710\n",
            "Epoch 277/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9815 - val_loss: 0.0736 - val_accuracy: 0.9710\n",
            "Epoch 278/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9811 - val_loss: 0.0736 - val_accuracy: 0.9710\n",
            "Epoch 279/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9819 - val_loss: 0.0735 - val_accuracy: 0.9710\n",
            "Epoch 280/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9806 - val_loss: 0.0735 - val_accuracy: 0.9710\n",
            "Epoch 281/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.0734 - val_accuracy: 0.9710\n",
            "Epoch 282/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9815 - val_loss: 0.0733 - val_accuracy: 0.9710\n",
            "Epoch 283/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9811 - val_loss: 0.0733 - val_accuracy: 0.9710\n",
            "Epoch 284/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9811 - val_loss: 0.0732 - val_accuracy: 0.9697\n",
            "Epoch 285/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9811 - val_loss: 0.0732 - val_accuracy: 0.9710\n",
            "Epoch 286/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9815 - val_loss: 0.0731 - val_accuracy: 0.9697\n",
            "Epoch 287/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9811 - val_loss: 0.0731 - val_accuracy: 0.9710\n",
            "Epoch 288/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9819 - val_loss: 0.0732 - val_accuracy: 0.9710\n",
            "Epoch 289/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9806 - val_loss: 0.0731 - val_accuracy: 0.9710\n",
            "Epoch 290/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9819 - val_loss: 0.0731 - val_accuracy: 0.9710\n",
            "Epoch 291/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9815 - val_loss: 0.0731 - val_accuracy: 0.9710\n",
            "Epoch 292/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9815 - val_loss: 0.0731 - val_accuracy: 0.9697\n",
            "Epoch 293/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9815 - val_loss: 0.0730 - val_accuracy: 0.9697\n",
            "Epoch 294/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9819 - val_loss: 0.0730 - val_accuracy: 0.9697\n",
            "Epoch 295/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9811 - val_loss: 0.0728 - val_accuracy: 0.9697\n",
            "Epoch 296/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9806 - val_loss: 0.0728 - val_accuracy: 0.9697\n",
            "Epoch 297/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 0.0728 - val_accuracy: 0.9697\n",
            "Epoch 298/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 0.0728 - val_accuracy: 0.9697\n",
            "Epoch 299/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 0.0729 - val_accuracy: 0.9697\n",
            "Epoch 300/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9811 - val_loss: 0.0728 - val_accuracy: 0.9697\n",
            "Epoch 301/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9815 - val_loss: 0.0728 - val_accuracy: 0.9697\n",
            "Epoch 302/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9806 - val_loss: 0.0727 - val_accuracy: 0.9697\n",
            "Epoch 303/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9815 - val_loss: 0.0727 - val_accuracy: 0.9697\n",
            "Epoch 304/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9806 - val_loss: 0.0728 - val_accuracy: 0.9697\n",
            "Epoch 305/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9811 - val_loss: 0.0727 - val_accuracy: 0.9697\n",
            "Epoch 306/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9815 - val_loss: 0.0727 - val_accuracy: 0.9697\n",
            "Epoch 307/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9806 - val_loss: 0.0726 - val_accuracy: 0.9697\n",
            "Epoch 308/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9815 - val_loss: 0.0726 - val_accuracy: 0.9697\n",
            "Epoch 309/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9823 - val_loss: 0.0724 - val_accuracy: 0.9697\n",
            "Epoch 310/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9798 - val_loss: 0.0723 - val_accuracy: 0.9697\n",
            "Epoch 311/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9815 - val_loss: 0.0724 - val_accuracy: 0.9710\n",
            "Epoch 312/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9802 - val_loss: 0.0724 - val_accuracy: 0.9710\n",
            "Epoch 313/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9811 - val_loss: 0.0724 - val_accuracy: 0.9697\n",
            "Epoch 314/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9806 - val_loss: 0.0725 - val_accuracy: 0.9697\n",
            "Epoch 315/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9806 - val_loss: 0.0724 - val_accuracy: 0.9710\n",
            "Epoch 316/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9815 - val_loss: 0.0724 - val_accuracy: 0.9710\n",
            "Epoch 317/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9802 - val_loss: 0.0723 - val_accuracy: 0.9710\n",
            "Epoch 318/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9823 - val_loss: 0.0724 - val_accuracy: 0.9710\n",
            "Epoch 319/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9806 - val_loss: 0.0723 - val_accuracy: 0.9697\n",
            "Epoch 320/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9802 - val_loss: 0.0723 - val_accuracy: 0.9697\n",
            "Epoch 321/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9802 - val_loss: 0.0722 - val_accuracy: 0.9697\n",
            "Epoch 322/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9815 - val_loss: 0.0722 - val_accuracy: 0.9697\n",
            "Epoch 323/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9811 - val_loss: 0.0722 - val_accuracy: 0.9697\n",
            "Epoch 324/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.0722 - val_accuracy: 0.9697\n",
            "Epoch 325/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9811 - val_loss: 0.0722 - val_accuracy: 0.9710\n",
            "Epoch 326/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.0722 - val_accuracy: 0.9697\n",
            "Epoch 327/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9819 - val_loss: 0.0722 - val_accuracy: 0.9697\n",
            "Epoch 328/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9815 - val_loss: 0.0722 - val_accuracy: 0.9697\n",
            "Epoch 329/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9806 - val_loss: 0.0720 - val_accuracy: 0.9710\n",
            "Epoch 330/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9815 - val_loss: 0.0721 - val_accuracy: 0.9710\n",
            "Epoch 331/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9811 - val_loss: 0.0720 - val_accuracy: 0.9710\n",
            "Epoch 332/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9815 - val_loss: 0.0720 - val_accuracy: 0.9697\n",
            "Epoch 333/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9815 - val_loss: 0.0720 - val_accuracy: 0.9697\n",
            "Epoch 334/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9815 - val_loss: 0.0726 - val_accuracy: 0.9722\n",
            "Epoch 335/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.9815 - val_loss: 0.0726 - val_accuracy: 0.9710\n",
            "Epoch 336/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9811 - val_loss: 0.0724 - val_accuracy: 0.9710\n",
            "Epoch 337/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9811 - val_loss: 0.0723 - val_accuracy: 0.9722\n",
            "Epoch 338/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9815 - val_loss: 0.0718 - val_accuracy: 0.9697\n",
            "Epoch 339/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9806 - val_loss: 0.0717 - val_accuracy: 0.9697\n",
            "Epoch 340/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9806 - val_loss: 0.0717 - val_accuracy: 0.9710\n",
            "Epoch 341/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9811 - val_loss: 0.0717 - val_accuracy: 0.9710\n",
            "Epoch 342/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9815 - val_loss: 0.0717 - val_accuracy: 0.9697\n",
            "Epoch 343/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9815 - val_loss: 0.0716 - val_accuracy: 0.9697\n",
            "Epoch 344/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9827 - val_loss: 0.0716 - val_accuracy: 0.9710\n",
            "Epoch 345/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9811 - val_loss: 0.0715 - val_accuracy: 0.9710\n",
            "Epoch 346/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9811 - val_loss: 0.0716 - val_accuracy: 0.9710\n",
            "Epoch 347/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9815 - val_loss: 0.0715 - val_accuracy: 0.9697\n",
            "Epoch 348/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9815 - val_loss: 0.0715 - val_accuracy: 0.9697\n",
            "Epoch 349/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9819 - val_loss: 0.0715 - val_accuracy: 0.9697\n",
            "Epoch 350/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9819 - val_loss: 0.0714 - val_accuracy: 0.9710\n",
            "Epoch 351/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9815 - val_loss: 0.0715 - val_accuracy: 0.9722\n",
            "Epoch 352/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9815 - val_loss: 0.0714 - val_accuracy: 0.9722\n",
            "Epoch 353/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9815 - val_loss: 0.0715 - val_accuracy: 0.9722\n",
            "Epoch 354/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9806 - val_loss: 0.0715 - val_accuracy: 0.9722\n",
            "Epoch 355/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9811 - val_loss: 0.0714 - val_accuracy: 0.9710\n",
            "Epoch 356/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9819 - val_loss: 0.0714 - val_accuracy: 0.9710\n",
            "Epoch 357/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9811 - val_loss: 0.0715 - val_accuracy: 0.9722\n",
            "Epoch 358/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9819 - val_loss: 0.0714 - val_accuracy: 0.9722\n",
            "Epoch 359/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9819 - val_loss: 0.0713 - val_accuracy: 0.9722\n",
            "Epoch 360/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9815 - val_loss: 0.0714 - val_accuracy: 0.9722\n",
            "Epoch 361/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9811 - val_loss: 0.0713 - val_accuracy: 0.9735\n",
            "Epoch 362/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9819 - val_loss: 0.0714 - val_accuracy: 0.9735\n",
            "Epoch 363/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9815 - val_loss: 0.0713 - val_accuracy: 0.9722\n",
            "Epoch 364/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9819 - val_loss: 0.0712 - val_accuracy: 0.9735\n",
            "Epoch 365/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9815 - val_loss: 0.0712 - val_accuracy: 0.9735\n",
            "Epoch 366/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9815 - val_loss: 0.0710 - val_accuracy: 0.9722\n",
            "Epoch 367/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9806 - val_loss: 0.0711 - val_accuracy: 0.9735\n",
            "Epoch 368/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9806 - val_loss: 0.0711 - val_accuracy: 0.9735\n",
            "Epoch 369/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9811 - val_loss: 0.0711 - val_accuracy: 0.9722\n",
            "Epoch 370/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9819 - val_loss: 0.0712 - val_accuracy: 0.9722\n",
            "Epoch 371/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9827 - val_loss: 0.0711 - val_accuracy: 0.9735\n",
            "Epoch 372/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9815 - val_loss: 0.0710 - val_accuracy: 0.9735\n",
            "Epoch 373/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9819 - val_loss: 0.0709 - val_accuracy: 0.9735\n",
            "Epoch 374/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9819 - val_loss: 0.0709 - val_accuracy: 0.9735\n",
            "Epoch 375/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9815 - val_loss: 0.0709 - val_accuracy: 0.9722\n",
            "Epoch 376/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9815 - val_loss: 0.0708 - val_accuracy: 0.9722\n",
            "Epoch 377/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0550 - accuracy: 0.9823 - val_loss: 0.0709 - val_accuracy: 0.9735\n",
            "Epoch 378/1500\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0550 - accuracy: 0.9823 - val_loss: 0.0709 - val_accuracy: 0.9735\n",
            "Epoch 379/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9819 - val_loss: 0.0708 - val_accuracy: 0.9722\n",
            "Epoch 380/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9832 - val_loss: 0.0708 - val_accuracy: 0.9722\n",
            "Epoch 381/1500\n",
            "75/75 [==============================] - 1s 13ms/step - loss: 0.0549 - accuracy: 0.9823 - val_loss: 0.0708 - val_accuracy: 0.9722\n",
            "Epoch 382/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0549 - accuracy: 0.9827 - val_loss: 0.0709 - val_accuracy: 0.9722\n",
            "Epoch 383/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9823 - val_loss: 0.0709 - val_accuracy: 0.9735\n",
            "Epoch 384/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9832 - val_loss: 0.0708 - val_accuracy: 0.9735\n",
            "Epoch 385/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9827 - val_loss: 0.0708 - val_accuracy: 0.9735\n",
            "Epoch 386/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9819 - val_loss: 0.0708 - val_accuracy: 0.9735\n",
            "Epoch 387/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9823 - val_loss: 0.0707 - val_accuracy: 0.9722\n",
            "Epoch 388/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.0708 - val_accuracy: 0.9722\n",
            "Epoch 389/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9815 - val_loss: 0.0708 - val_accuracy: 0.9722\n",
            "Epoch 390/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9836 - val_loss: 0.0707 - val_accuracy: 0.9722\n",
            "Epoch 391/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.0708 - val_accuracy: 0.9722\n",
            "Epoch 392/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9823 - val_loss: 0.0708 - val_accuracy: 0.9735\n",
            "Epoch 393/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9823 - val_loss: 0.0708 - val_accuracy: 0.9735\n",
            "Epoch 394/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9832 - val_loss: 0.0709 - val_accuracy: 0.9735\n",
            "Epoch 395/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9827 - val_loss: 0.0709 - val_accuracy: 0.9735\n",
            "Epoch 396/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 0.0708 - val_accuracy: 0.9735\n",
            "Epoch 397/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9819 - val_loss: 0.0708 - val_accuracy: 0.9735\n",
            "Epoch 398/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 0.0708 - val_accuracy: 0.9735\n",
            "Epoch 399/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9823 - val_loss: 0.0708 - val_accuracy: 0.9735\n",
            "Epoch 400/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9819 - val_loss: 0.0707 - val_accuracy: 0.9735\n",
            "Epoch 401/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9823 - val_loss: 0.0707 - val_accuracy: 0.9735\n",
            "Epoch 402/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9819 - val_loss: 0.0706 - val_accuracy: 0.9735\n",
            "Epoch 403/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9827 - val_loss: 0.0706 - val_accuracy: 0.9735\n",
            "Epoch 404/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9827 - val_loss: 0.0707 - val_accuracy: 0.9735\n",
            "Epoch 405/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9832 - val_loss: 0.0707 - val_accuracy: 0.9735\n",
            "Epoch 406/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9823 - val_loss: 0.0707 - val_accuracy: 0.9735\n",
            "Epoch 407/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9827 - val_loss: 0.0707 - val_accuracy: 0.9735\n",
            "Epoch 408/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9823 - val_loss: 0.0707 - val_accuracy: 0.9735\n",
            "Epoch 409/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9832 - val_loss: 0.0707 - val_accuracy: 0.9735\n",
            "Epoch 410/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9832 - val_loss: 0.0707 - val_accuracy: 0.9735\n",
            "Epoch 411/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9827 - val_loss: 0.0706 - val_accuracy: 0.9735\n",
            "Epoch 412/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9832 - val_loss: 0.0706 - val_accuracy: 0.9735\n",
            "Epoch 413/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9827 - val_loss: 0.0706 - val_accuracy: 0.9735\n",
            "Epoch 414/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9823 - val_loss: 0.0706 - val_accuracy: 0.9735\n",
            "Epoch 415/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.0706 - val_accuracy: 0.9735\n",
            "Epoch 416/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.0705 - val_accuracy: 0.9735\n",
            "Epoch 417/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.0705 - val_accuracy: 0.9735\n",
            "Epoch 418/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.0704 - val_accuracy: 0.9735\n",
            "Epoch 419/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.0704 - val_accuracy: 0.9735\n",
            "Epoch 420/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9832 - val_loss: 0.0705 - val_accuracy: 0.9735\n",
            "Epoch 421/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9823 - val_loss: 0.0704 - val_accuracy: 0.9735\n",
            "Epoch 422/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9823 - val_loss: 0.0704 - val_accuracy: 0.9735\n",
            "Epoch 423/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9832 - val_loss: 0.0705 - val_accuracy: 0.9735\n",
            "Epoch 424/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9827 - val_loss: 0.0705 - val_accuracy: 0.9735\n",
            "Epoch 425/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9832 - val_loss: 0.0705 - val_accuracy: 0.9735\n",
            "Epoch 426/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9832 - val_loss: 0.0705 - val_accuracy: 0.9735\n",
            "Epoch 427/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9827 - val_loss: 0.0705 - val_accuracy: 0.9735\n",
            "Epoch 428/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9827 - val_loss: 0.0704 - val_accuracy: 0.9735\n",
            "Epoch 429/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9827 - val_loss: 0.0705 - val_accuracy: 0.9735\n",
            "Epoch 430/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9823 - val_loss: 0.0707 - val_accuracy: 0.9735\n",
            "Epoch 431/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9832 - val_loss: 0.0705 - val_accuracy: 0.9735\n",
            "Epoch 432/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9832 - val_loss: 0.0703 - val_accuracy: 0.9722\n",
            "Epoch 433/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9832 - val_loss: 0.0703 - val_accuracy: 0.9735\n",
            "Epoch 434/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9836 - val_loss: 0.0704 - val_accuracy: 0.9735\n",
            "Epoch 435/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9827 - val_loss: 0.0703 - val_accuracy: 0.9735\n",
            "Epoch 436/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9832 - val_loss: 0.0702 - val_accuracy: 0.9735\n",
            "Epoch 437/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9832 - val_loss: 0.0703 - val_accuracy: 0.9735\n",
            "Epoch 438/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9827 - val_loss: 0.0703 - val_accuracy: 0.9735\n",
            "Epoch 439/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9827 - val_loss: 0.0702 - val_accuracy: 0.9735\n",
            "Epoch 440/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9827 - val_loss: 0.0702 - val_accuracy: 0.9735\n",
            "Epoch 441/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9827 - val_loss: 0.0703 - val_accuracy: 0.9735\n",
            "Epoch 442/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9827 - val_loss: 0.0702 - val_accuracy: 0.9735\n",
            "Epoch 443/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9823 - val_loss: 0.0702 - val_accuracy: 0.9735\n",
            "Epoch 444/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.9827 - val_loss: 0.0702 - val_accuracy: 0.9735\n",
            "Epoch 445/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9827 - val_loss: 0.0702 - val_accuracy: 0.9735\n",
            "Epoch 446/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9827 - val_loss: 0.0701 - val_accuracy: 0.9735\n",
            "Epoch 447/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9827 - val_loss: 0.0700 - val_accuracy: 0.9735\n",
            "Epoch 448/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9832 - val_loss: 0.0701 - val_accuracy: 0.9735\n",
            "Epoch 449/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9832 - val_loss: 0.0701 - val_accuracy: 0.9735\n",
            "Epoch 450/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9827 - val_loss: 0.0700 - val_accuracy: 0.9735\n",
            "Epoch 451/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9823 - val_loss: 0.0699 - val_accuracy: 0.9735\n",
            "Epoch 452/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9832 - val_loss: 0.0699 - val_accuracy: 0.9735\n",
            "Epoch 453/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.0699 - val_accuracy: 0.9735\n",
            "Epoch 454/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.0699 - val_accuracy: 0.9735\n",
            "Epoch 455/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.0698 - val_accuracy: 0.9747\n",
            "Epoch 456/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9827 - val_loss: 0.0698 - val_accuracy: 0.9747\n",
            "Epoch 457/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 0.0700 - val_accuracy: 0.9747\n",
            "Epoch 458/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.0701 - val_accuracy: 0.9747\n",
            "Epoch 459/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9823 - val_loss: 0.0699 - val_accuracy: 0.9747\n",
            "Epoch 460/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9827 - val_loss: 0.0699 - val_accuracy: 0.9747\n",
            "Epoch 461/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9827 - val_loss: 0.0699 - val_accuracy: 0.9747\n",
            "Epoch 462/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9832 - val_loss: 0.0699 - val_accuracy: 0.9747\n",
            "Epoch 463/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9832 - val_loss: 0.0698 - val_accuracy: 0.9747\n",
            "Epoch 464/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9832 - val_loss: 0.0698 - val_accuracy: 0.9747\n",
            "Epoch 465/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.0699 - val_accuracy: 0.9747\n",
            "Epoch 466/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9823 - val_loss: 0.0698 - val_accuracy: 0.9747\n",
            "Epoch 467/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.0698 - val_accuracy: 0.9747\n",
            "Epoch 468/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.0698 - val_accuracy: 0.9747\n",
            "Epoch 469/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.0699 - val_accuracy: 0.9747\n",
            "Epoch 470/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9823 - val_loss: 0.0698 - val_accuracy: 0.9747\n",
            "Epoch 471/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9832 - val_loss: 0.0698 - val_accuracy: 0.9747\n",
            "Epoch 472/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9827 - val_loss: 0.0697 - val_accuracy: 0.9747\n",
            "Epoch 473/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9832 - val_loss: 0.0697 - val_accuracy: 0.9747\n",
            "Epoch 474/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9832 - val_loss: 0.0697 - val_accuracy: 0.9747\n",
            "Epoch 475/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9827 - val_loss: 0.0697 - val_accuracy: 0.9747\n",
            "Epoch 476/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9827 - val_loss: 0.0696 - val_accuracy: 0.9747\n",
            "Epoch 477/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9836 - val_loss: 0.0696 - val_accuracy: 0.9747\n",
            "Epoch 478/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9827 - val_loss: 0.0696 - val_accuracy: 0.9747\n",
            "Epoch 479/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9827 - val_loss: 0.0695 - val_accuracy: 0.9747\n",
            "Epoch 480/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9832 - val_loss: 0.0695 - val_accuracy: 0.9747\n",
            "Epoch 481/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9832 - val_loss: 0.0695 - val_accuracy: 0.9747\n",
            "Epoch 482/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9827 - val_loss: 0.0695 - val_accuracy: 0.9747\n",
            "Epoch 483/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9836 - val_loss: 0.0694 - val_accuracy: 0.9747\n",
            "Epoch 484/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 0.0695 - val_accuracy: 0.9747\n",
            "Epoch 485/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9836 - val_loss: 0.0695 - val_accuracy: 0.9747\n",
            "Epoch 486/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 0.0695 - val_accuracy: 0.9760\n",
            "Epoch 487/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0524 - accuracy: 0.9836 - val_loss: 0.0699 - val_accuracy: 0.9760\n",
            "Epoch 488/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 0.0697 - val_accuracy: 0.9760\n",
            "Epoch 489/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9836 - val_loss: 0.0697 - val_accuracy: 0.9760\n",
            "Epoch 490/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9832 - val_loss: 0.0697 - val_accuracy: 0.9760\n",
            "Epoch 491/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9827 - val_loss: 0.0696 - val_accuracy: 0.9760\n",
            "Epoch 492/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9836 - val_loss: 0.0699 - val_accuracy: 0.9760\n",
            "Epoch 493/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9827 - val_loss: 0.0698 - val_accuracy: 0.9760\n",
            "Epoch 494/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9832 - val_loss: 0.0697 - val_accuracy: 0.9760\n",
            "Epoch 495/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9836 - val_loss: 0.0697 - val_accuracy: 0.9760\n",
            "Epoch 496/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9832 - val_loss: 0.0696 - val_accuracy: 0.9760\n",
            "Epoch 497/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9832 - val_loss: 0.0695 - val_accuracy: 0.9760\n",
            "Epoch 498/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9836 - val_loss: 0.0694 - val_accuracy: 0.9760\n",
            "Epoch 499/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9836 - val_loss: 0.0694 - val_accuracy: 0.9760\n",
            "Epoch 500/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.0694 - val_accuracy: 0.9760\n",
            "Epoch 501/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9832 - val_loss: 0.0694 - val_accuracy: 0.9760\n",
            "Epoch 502/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9823 - val_loss: 0.0693 - val_accuracy: 0.9747\n",
            "Epoch 503/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.0693 - val_accuracy: 0.9760\n",
            "Epoch 504/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.0694 - val_accuracy: 0.9760\n",
            "Epoch 505/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 506/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 0.0690 - val_accuracy: 0.9747\n",
            "Epoch 507/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.9832 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 508/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9827 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 509/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 510/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9832 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 511/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9832 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 512/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 513/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9832 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 514/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 515/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0517 - accuracy: 0.9832 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 516/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 517/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 518/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9832 - val_loss: 0.0693 - val_accuracy: 0.9760\n",
            "Epoch 519/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 520/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9832 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 521/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 522/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 523/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 524/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 525/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.0693 - val_accuracy: 0.9760\n",
            "Epoch 526/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 527/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 528/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9836 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 529/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9832 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 530/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 531/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9832 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 532/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9836 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 533/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9827 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 534/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 535/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 536/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9836 - val_loss: 0.0692 - val_accuracy: 0.9760\n",
            "Epoch 537/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9832 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 538/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9836 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 539/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9836 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 540/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9836 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 541/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9840 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 542/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9836 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 543/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9832 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 544/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 545/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 546/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9832 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 547/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 548/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 549/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9832 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 550/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 551/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9832 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 552/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9836 - val_loss: 0.0691 - val_accuracy: 0.9760\n",
            "Epoch 553/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9832 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 554/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9836 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 555/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9832 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 556/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9836 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 557/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9832 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
            "Epoch 558/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9832 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 559/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9832 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
            "Epoch 560/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9836 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
            "Epoch 561/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9836 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
            "Epoch 562/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9832 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
            "Epoch 563/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9836 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
            "Epoch 564/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9760\n",
            "Epoch 565/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9832 - val_loss: 0.0686 - val_accuracy: 0.9760\n",
            "Epoch 566/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9836 - val_loss: 0.0687 - val_accuracy: 0.9760\n",
            "Epoch 567/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9836 - val_loss: 0.0687 - val_accuracy: 0.9760\n",
            "Epoch 568/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9760\n",
            "Epoch 569/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9832 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
            "Epoch 570/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9760\n",
            "Epoch 571/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 572/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0504 - accuracy: 0.9827 - val_loss: 0.0687 - val_accuracy: 0.9747\n",
            "Epoch 573/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9747\n",
            "Epoch 574/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9827 - val_loss: 0.0688 - val_accuracy: 0.9747\n",
            "Epoch 575/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9840 - val_loss: 0.0688 - val_accuracy: 0.9747\n",
            "Epoch 576/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9832 - val_loss: 0.0688 - val_accuracy: 0.9747\n",
            "Epoch 577/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9836 - val_loss: 0.0689 - val_accuracy: 0.9735\n",
            "Epoch 578/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9836 - val_loss: 0.0689 - val_accuracy: 0.9735\n",
            "Epoch 579/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9840 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 580/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9840 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 581/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9832 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 582/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 583/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9827 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 584/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 585/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9840 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 586/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 587/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 588/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 589/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 590/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 591/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9832 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 592/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9832 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 593/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 594/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9832 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 595/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9836 - val_loss: 0.0686 - val_accuracy: 0.9735\n",
            "Epoch 596/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9836 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 597/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9836 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 598/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 599/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 600/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 601/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 602/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 603/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9827 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 604/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 605/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9832 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 606/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9832 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 607/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9836 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 608/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9832 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 609/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9836 - val_loss: 0.0687 - val_accuracy: 0.9747\n",
            "Epoch 610/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9832 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 611/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9832 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 612/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9836 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 613/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9832 - val_loss: 0.0688 - val_accuracy: 0.9735\n",
            "Epoch 614/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9836 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 615/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9836 - val_loss: 0.0687 - val_accuracy: 0.9747\n",
            "Epoch 616/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9836 - val_loss: 0.0687 - val_accuracy: 0.9747\n",
            "Epoch 617/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9836 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 618/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9832 - val_loss: 0.0685 - val_accuracy: 0.9747\n",
            "Epoch 619/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9832 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 620/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9832 - val_loss: 0.0685 - val_accuracy: 0.9747\n",
            "Epoch 621/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9836 - val_loss: 0.0685 - val_accuracy: 0.9747\n",
            "Epoch 622/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9832 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 623/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9832 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 624/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9836 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 625/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9836 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 626/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9832 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 627/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9836 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 628/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9836 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 629/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9832 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 630/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9840 - val_loss: 0.0685 - val_accuracy: 0.9747\n",
            "Epoch 631/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9827 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 632/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9827 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 633/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9832 - val_loss: 0.0685 - val_accuracy: 0.9747\n",
            "Epoch 634/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9836 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 635/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9827 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 636/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 637/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 638/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9836 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 639/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9827 - val_loss: 0.0685 - val_accuracy: 0.9747\n",
            "Epoch 640/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9827 - val_loss: 0.0683 - val_accuracy: 0.9747\n",
            "Epoch 641/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9836 - val_loss: 0.0683 - val_accuracy: 0.9747\n",
            "Epoch 642/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9836 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 643/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9832 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 644/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9827 - val_loss: 0.0683 - val_accuracy: 0.9747\n",
            "Epoch 645/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9836 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 646/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9827 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 647/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9840 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 648/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9827 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
            "Epoch 649/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.0685 - val_accuracy: 0.9747\n",
            "Epoch 650/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9832 - val_loss: 0.0683 - val_accuracy: 0.9747\n",
            "Epoch 651/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.0683 - val_accuracy: 0.9747\n",
            "Epoch 652/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.0683 - val_accuracy: 0.9747\n",
            "Epoch 653/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.0683 - val_accuracy: 0.9747\n",
            "Epoch 654/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9840 - val_loss: 0.0682 - val_accuracy: 0.9747\n",
            "Epoch 655/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9832 - val_loss: 0.0683 - val_accuracy: 0.9747\n",
            "Epoch 656/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9832 - val_loss: 0.0683 - val_accuracy: 0.9747\n",
            "Epoch 657/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9836 - val_loss: 0.0682 - val_accuracy: 0.9747\n",
            "Epoch 658/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9836 - val_loss: 0.0682 - val_accuracy: 0.9747\n",
            "Epoch 659/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9836 - val_loss: 0.0681 - val_accuracy: 0.9747\n",
            "Epoch 660/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9836 - val_loss: 0.0681 - val_accuracy: 0.9747\n",
            "Epoch 661/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9832 - val_loss: 0.0682 - val_accuracy: 0.9747\n",
            "Epoch 662/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9836 - val_loss: 0.0683 - val_accuracy: 0.9747\n",
            "Epoch 663/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9832 - val_loss: 0.0684 - val_accuracy: 0.9735\n",
            "Epoch 664/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9836 - val_loss: 0.0682 - val_accuracy: 0.9747\n",
            "Epoch 665/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9836 - val_loss: 0.0683 - val_accuracy: 0.9747\n",
            "Epoch 666/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9827 - val_loss: 0.0682 - val_accuracy: 0.9747\n",
            "Epoch 667/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9836 - val_loss: 0.0681 - val_accuracy: 0.9747\n",
            "Epoch 668/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9832 - val_loss: 0.0681 - val_accuracy: 0.9747\n",
            "Epoch 669/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9832 - val_loss: 0.0681 - val_accuracy: 0.9747\n",
            "Epoch 670/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9832 - val_loss: 0.0681 - val_accuracy: 0.9735\n",
            "Epoch 671/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9832 - val_loss: 0.0680 - val_accuracy: 0.9747\n",
            "Epoch 672/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9827 - val_loss: 0.0680 - val_accuracy: 0.9747\n",
            "Epoch 673/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9832 - val_loss: 0.0679 - val_accuracy: 0.9747\n",
            "Epoch 674/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9840 - val_loss: 0.0680 - val_accuracy: 0.9747\n",
            "Epoch 675/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9832 - val_loss: 0.0679 - val_accuracy: 0.9747\n",
            "Epoch 676/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9832 - val_loss: 0.0680 - val_accuracy: 0.9747\n",
            "Epoch 677/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9832 - val_loss: 0.0680 - val_accuracy: 0.9747\n",
            "Epoch 678/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9836 - val_loss: 0.0679 - val_accuracy: 0.9747\n",
            "Epoch 679/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9836 - val_loss: 0.0680 - val_accuracy: 0.9747\n",
            "Epoch 680/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9836 - val_loss: 0.0680 - val_accuracy: 0.9747\n",
            "Epoch 681/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9836 - val_loss: 0.0680 - val_accuracy: 0.9747\n",
            "Epoch 682/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9844 - val_loss: 0.0681 - val_accuracy: 0.9747\n",
            "Epoch 683/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.0680 - val_accuracy: 0.9747\n",
            "Epoch 684/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9832 - val_loss: 0.0679 - val_accuracy: 0.9747\n",
            "Epoch 685/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9836 - val_loss: 0.0678 - val_accuracy: 0.9747\n",
            "Epoch 686/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9840 - val_loss: 0.0678 - val_accuracy: 0.9747\n",
            "Epoch 687/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9840 - val_loss: 0.0678 - val_accuracy: 0.9747\n",
            "Epoch 688/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9840 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 689/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9844 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 690/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9836 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 691/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9840 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 692/1500\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9844 - val_loss: 0.0678 - val_accuracy: 0.9747\n",
            "Epoch 693/1500\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0475 - accuracy: 0.9840 - val_loss: 0.0678 - val_accuracy: 0.9747\n",
            "Epoch 694/1500\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0476 - accuracy: 0.9844 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 695/1500\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0475 - accuracy: 0.9840 - val_loss: 0.0678 - val_accuracy: 0.9747\n",
            "Epoch 696/1500\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0475 - accuracy: 0.9844 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 697/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0475 - accuracy: 0.9840 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 698/1500\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0474 - accuracy: 0.9840 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 699/1500\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0475 - accuracy: 0.9844 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 700/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9836 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 701/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9844 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 702/1500\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0474 - accuracy: 0.9840 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 703/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9840 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 704/1500\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0474 - accuracy: 0.9844 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 705/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 706/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9836 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 707/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 708/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 709/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 710/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 711/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9840 - val_loss: 0.0675 - val_accuracy: 0.9747\n",
            "Epoch 712/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9844 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 713/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9844 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 714/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9848 - val_loss: 0.0676 - val_accuracy: 0.9760\n",
            "Epoch 715/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9840 - val_loss: 0.0676 - val_accuracy: 0.9760\n",
            "Epoch 716/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9836 - val_loss: 0.0675 - val_accuracy: 0.9747\n",
            "Epoch 717/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9844 - val_loss: 0.0675 - val_accuracy: 0.9747\n",
            "Epoch 718/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9844 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 719/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9840 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 720/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9844 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 721/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9844 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 722/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9844 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 723/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9840 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 724/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9840 - val_loss: 0.0675 - val_accuracy: 0.9747\n",
            "Epoch 725/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9848 - val_loss: 0.0675 - val_accuracy: 0.9747\n",
            "Epoch 726/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9844 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 727/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9844 - val_loss: 0.0675 - val_accuracy: 0.9747\n",
            "Epoch 728/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9844 - val_loss: 0.0675 - val_accuracy: 0.9747\n",
            "Epoch 729/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9840 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
            "Epoch 730/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9844 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 731/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9844 - val_loss: 0.0676 - val_accuracy: 0.9760\n",
            "Epoch 732/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9844 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 733/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9844 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 734/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9848 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 735/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 736/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9844 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 737/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 738/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9848 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 739/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9844 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 740/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9844 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 741/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 742/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 0.0674 - val_accuracy: 0.9747\n",
            "Epoch 743/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9840 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 744/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 745/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 746/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9844 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 747/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 748/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 749/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 750/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9853 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 751/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9857 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 752/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9853 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 753/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9848 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 754/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9848 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 755/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9844 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 756/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9844 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 757/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9853 - val_loss: 0.0676 - val_accuracy: 0.9773\n",
            "Epoch 758/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9840 - val_loss: 0.0675 - val_accuracy: 0.9747\n",
            "Epoch 759/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9844 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 760/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9848 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 761/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 762/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9848 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 763/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 764/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9844 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 765/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9853 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 766/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 767/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 768/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 769/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 770/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9747\n",
            "Epoch 771/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 772/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 0.0672 - val_accuracy: 0.9747\n",
            "Epoch 773/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 774/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 775/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9773\n",
            "Epoch 776/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 777/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 778/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 779/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9853 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 780/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 781/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 782/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 783/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 784/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 785/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 786/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 787/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 788/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.9844 - val_loss: 0.0678 - val_accuracy: 0.9760\n",
            "Epoch 789/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9848 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 790/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 0.0672 - val_accuracy: 0.9773\n",
            "Epoch 791/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9773\n",
            "Epoch 792/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 793/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0461 - accuracy: 0.9853 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 794/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 795/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9773\n",
            "Epoch 796/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9773\n",
            "Epoch 797/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 798/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 799/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 800/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 801/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9844 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 802/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 803/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 804/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 805/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.0672 - val_accuracy: 0.9773\n",
            "Epoch 806/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9844 - val_loss: 0.0669 - val_accuracy: 0.9785\n",
            "Epoch 807/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9844 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 808/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 809/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 810/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 811/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 812/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 813/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 814/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 815/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 816/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 817/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 818/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 819/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9853 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 820/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 821/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 822/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9853 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 823/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 824/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 825/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 826/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 827/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 828/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9853 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 829/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9844 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 830/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 831/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 832/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9844 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 833/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 834/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 835/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 836/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9853 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 837/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 838/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 839/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 840/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 841/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 842/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 843/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9844 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 844/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 845/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 846/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 847/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 848/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 849/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 850/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 851/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9844 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 852/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 853/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 854/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9844 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 855/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 856/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 857/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 858/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 859/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 860/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 861/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 862/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9853 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 863/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 864/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 865/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 866/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9844 - val_loss: 0.0668 - val_accuracy: 0.9773\n",
            "Epoch 867/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9844 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 868/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 869/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 870/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 871/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 872/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 873/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 874/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9853 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 875/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 876/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9844 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 877/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 878/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 879/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9853 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 880/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 881/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 882/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 883/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9844 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 884/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9844 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 885/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 886/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 0.0666 - val_accuracy: 0.9773\n",
            "Epoch 887/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9848 - val_loss: 0.0667 - val_accuracy: 0.9773\n",
            "Epoch 888/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9844 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 889/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9848 - val_loss: 0.0666 - val_accuracy: 0.9773\n",
            "Epoch 890/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 891/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 0.0667 - val_accuracy: 0.9773\n",
            "Epoch 892/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 893/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 894/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 895/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 896/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9857 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 897/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9853 - val_loss: 0.0666 - val_accuracy: 0.9760\n",
            "Epoch 898/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 899/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 900/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 901/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9857 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 902/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9857 - val_loss: 0.0666 - val_accuracy: 0.9760\n",
            "Epoch 903/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9844 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 904/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9857 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 905/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 906/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9853 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 907/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9848 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 908/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9853 - val_loss: 0.0665 - val_accuracy: 0.9760\n",
            "Epoch 909/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9844 - val_loss: 0.0666 - val_accuracy: 0.9760\n",
            "Epoch 910/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9853 - val_loss: 0.0666 - val_accuracy: 0.9760\n",
            "Epoch 911/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 912/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 913/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9853 - val_loss: 0.0666 - val_accuracy: 0.9773\n",
            "Epoch 914/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9853 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 915/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9853 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 916/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9857 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 917/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 918/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9857 - val_loss: 0.0667 - val_accuracy: 0.9773\n",
            "Epoch 919/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 920/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 921/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9857 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 922/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 923/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 924/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.0667 - val_accuracy: 0.9773\n",
            "Epoch 925/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 926/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9861 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 927/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 928/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.0667 - val_accuracy: 0.9773\n",
            "Epoch 929/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 930/1500\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 931/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9848 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 932/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9853 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 933/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9857 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 934/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9848 - val_loss: 0.0678 - val_accuracy: 0.9760\n",
            "Epoch 935/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9857 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 936/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9857 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 937/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 938/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 939/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 940/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 941/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 942/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9853 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 943/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 944/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 945/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9857 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 946/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.9760\n",
            "Epoch 947/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 948/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9857 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 949/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 950/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9857 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 951/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9857 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 952/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 953/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 954/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9857 - val_loss: 0.0668 - val_accuracy: 0.9773\n",
            "Epoch 955/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9861 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 956/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9861 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 957/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9857 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 958/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9848 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 959/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 960/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9857 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 961/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9857 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 962/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 963/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 964/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9853 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 965/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 966/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9857 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 967/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9857 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 968/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 969/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9857 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 970/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 971/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 972/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 973/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 974/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 0.9857 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 975/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 976/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 977/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 978/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 979/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 980/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 981/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9853 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 982/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9853 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 983/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9857 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 984/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.9853 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 985/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 986/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 0.9857 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 987/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0438 - accuracy: 0.9853 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 988/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.9853 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 989/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9861 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 990/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 991/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9857 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 992/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9857 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 993/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9857 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 994/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
            "Epoch 995/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 996/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.0670 - val_accuracy: 0.9760\n",
            "Epoch 997/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 998/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9861 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 999/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 1000/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 1001/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9853 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 1002/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 1003/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 1004/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 1005/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 1006/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 1007/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9861 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 1008/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 1009/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 1010/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 1011/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 1012/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 1013/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 1014/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 1015/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9853 - val_loss: 0.0671 - val_accuracy: 0.9760\n",
            "Epoch 1016/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0671 - val_accuracy: 0.9773\n",
            "Epoch 1017/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 1018/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9861 - val_loss: 0.0673 - val_accuracy: 0.9773\n",
            "Epoch 1019/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 1020/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9861 - val_loss: 0.0672 - val_accuracy: 0.9773\n",
            "Epoch 1021/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9861 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 1022/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9861 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 1023/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 1024/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9861 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 1025/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9857 - val_loss: 0.0673 - val_accuracy: 0.9773\n",
            "Epoch 1026/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9857 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 1027/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9853 - val_loss: 0.0672 - val_accuracy: 0.9773\n",
            "Epoch 1028/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9861 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 1029/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9861 - val_loss: 0.0673 - val_accuracy: 0.9773\n",
            "Epoch 1030/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9857 - val_loss: 0.0673 - val_accuracy: 0.9773\n",
            "Epoch 1031/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9865 - val_loss: 0.0672 - val_accuracy: 0.9773\n",
            "Epoch 1032/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9857 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 1033/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9861 - val_loss: 0.0673 - val_accuracy: 0.9760\n",
            "Epoch 1034/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.0672 - val_accuracy: 0.9773\n",
            "Epoch 1035/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 1036/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9861 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 1037/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9861 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 1038/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9861 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 1039/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 1040/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 1041/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9785\n",
            "Epoch 1042/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.0673 - val_accuracy: 0.9773\n",
            "Epoch 1043/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0430 - accuracy: 0.9857 - val_loss: 0.0675 - val_accuracy: 0.9773\n",
            "Epoch 1044/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.0674 - val_accuracy: 0.9773\n",
            "Epoch 1045/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.0674 - val_accuracy: 0.9773\n",
            "Epoch 1046/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9857 - val_loss: 0.0674 - val_accuracy: 0.9773\n",
            "Epoch 1047/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 1048/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 0.0674 - val_accuracy: 0.9760\n",
            "Epoch 1049/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9861 - val_loss: 0.0674 - val_accuracy: 0.9773\n",
            "Epoch 1050/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9861 - val_loss: 0.0676 - val_accuracy: 0.9760\n",
            "Epoch 1051/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9857 - val_loss: 0.0675 - val_accuracy: 0.9773\n",
            "Epoch 1052/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 0.0675 - val_accuracy: 0.9773\n",
            "Epoch 1053/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 1054/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9861 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 1055/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9861 - val_loss: 0.0676 - val_accuracy: 0.9760\n",
            "Epoch 1056/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 0.0676 - val_accuracy: 0.9760\n",
            "Epoch 1057/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9861 - val_loss: 0.0676 - val_accuracy: 0.9760\n",
            "Epoch 1058/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9861 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 1059/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9853 - val_loss: 0.0674 - val_accuracy: 0.9773\n",
            "Epoch 1060/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9861 - val_loss: 0.0676 - val_accuracy: 0.9760\n",
            "Epoch 1061/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9853 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 1062/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9857 - val_loss: 0.0674 - val_accuracy: 0.9773\n",
            "Epoch 1063/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9857 - val_loss: 0.0674 - val_accuracy: 0.9773\n",
            "Epoch 1064/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9857 - val_loss: 0.0674 - val_accuracy: 0.9773\n",
            "Epoch 1065/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9857 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 1066/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9853 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 1067/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.0677 - val_accuracy: 0.9760\n",
            "Epoch 1068/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9857 - val_loss: 0.0673 - val_accuracy: 0.9773\n",
            "Epoch 1069/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9861 - val_loss: 0.0675 - val_accuracy: 0.9773\n",
            "Epoch 1070/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.0676 - val_accuracy: 0.9760\n",
            "Epoch 1071/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.0676 - val_accuracy: 0.9760\n",
            "Epoch 1072/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.0676 - val_accuracy: 0.9760\n",
            "Epoch 1073/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9857 - val_loss: 0.0675 - val_accuracy: 0.9773\n",
            "Epoch 1074/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.0674 - val_accuracy: 0.9773\n",
            "Epoch 1075/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.0675 - val_accuracy: 0.9773\n",
            "Epoch 1076/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9865 - val_loss: 0.0677 - val_accuracy: 0.9760\n",
            "Epoch 1077/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9857 - val_loss: 0.0676 - val_accuracy: 0.9773\n",
            "Epoch 1078/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.0675 - val_accuracy: 0.9760\n",
            "Epoch 1079/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.0675 - val_accuracy: 0.9773\n",
            "Epoch 1080/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9865 - val_loss: 0.0676 - val_accuracy: 0.9773\n",
            "Epoch 1081/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.0677 - val_accuracy: 0.9760\n",
            "Epoch 1082/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.0678 - val_accuracy: 0.9760\n",
            "Epoch 1083/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.0675 - val_accuracy: 0.9773\n",
            "Epoch 1084/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.0675 - val_accuracy: 0.9773\n",
            "Epoch 1085/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.0677 - val_accuracy: 0.9760\n",
            "Epoch 1086/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.0677 - val_accuracy: 0.9760\n",
            "Epoch 1087/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.0677 - val_accuracy: 0.9760\n",
            "Epoch 1088/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.0676 - val_accuracy: 0.9773\n",
            "Epoch 1089/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.0677 - val_accuracy: 0.9760\n",
            "Epoch 1090/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9857 - val_loss: 0.0677 - val_accuracy: 0.9760\n",
            "Epoch 1091/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.0680 - val_accuracy: 0.9760\n",
            "Epoch 1092/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.0678 - val_accuracy: 0.9760\n",
            "Epoch 1093/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.0676 - val_accuracy: 0.9773\n",
            "Epoch 1094/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.0678 - val_accuracy: 0.9760\n",
            "Epoch 1095/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.0677 - val_accuracy: 0.9760\n",
            "Epoch 1096/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9853 - val_loss: 0.0678 - val_accuracy: 0.9760\n",
            "Epoch 1097/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.0678 - val_accuracy: 0.9760\n",
            "Epoch 1098/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.0676 - val_accuracy: 0.9773\n",
            "Epoch 1099/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9857 - val_loss: 0.0679 - val_accuracy: 0.9760\n",
            "Epoch 1100/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.9865 - val_loss: 0.0677 - val_accuracy: 0.9773\n",
            "Epoch 1101/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.0676 - val_accuracy: 0.9773\n",
            "Epoch 1102/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0677 - val_accuracy: 0.9773\n",
            "Epoch 1103/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9865 - val_loss: 0.0678 - val_accuracy: 0.9760\n",
            "Epoch 1104/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0676 - val_accuracy: 0.9773\n",
            "Epoch 1105/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0677 - val_accuracy: 0.9773\n",
            "Epoch 1106/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0677 - val_accuracy: 0.9773\n",
            "Epoch 1107/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9865 - val_loss: 0.0680 - val_accuracy: 0.9760\n",
            "Epoch 1108/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9865 - val_loss: 0.0679 - val_accuracy: 0.9773\n",
            "Epoch 1109/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0678 - val_accuracy: 0.9773\n",
            "Epoch 1110/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0678 - val_accuracy: 0.9773\n",
            "Epoch 1111/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9857 - val_loss: 0.0677 - val_accuracy: 0.9773\n",
            "Epoch 1112/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0677 - val_accuracy: 0.9773\n",
            "Epoch 1113/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9861 - val_loss: 0.0679 - val_accuracy: 0.9760\n",
            "Epoch 1114/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9861 - val_loss: 0.0677 - val_accuracy: 0.9773\n",
            "Epoch 1115/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0678 - val_accuracy: 0.9773\n",
            "Epoch 1116/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9857 - val_loss: 0.0680 - val_accuracy: 0.9773\n",
            "Epoch 1117/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9857 - val_loss: 0.0678 - val_accuracy: 0.9773\n",
            "Epoch 1118/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9861 - val_loss: 0.0679 - val_accuracy: 0.9773\n",
            "Epoch 1119/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9857 - val_loss: 0.0679 - val_accuracy: 0.9773\n",
            "Epoch 1120/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9861 - val_loss: 0.0679 - val_accuracy: 0.9773\n",
            "Epoch 1121/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9861 - val_loss: 0.0678 - val_accuracy: 0.9773\n",
            "Epoch 1122/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9861 - val_loss: 0.0679 - val_accuracy: 0.9773\n",
            "Epoch 1123/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9857 - val_loss: 0.0681 - val_accuracy: 0.9760\n",
            "Epoch 1124/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9861 - val_loss: 0.0681 - val_accuracy: 0.9760\n",
            "Epoch 1125/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9861 - val_loss: 0.0681 - val_accuracy: 0.9760\n",
            "Epoch 1126/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9857 - val_loss: 0.0679 - val_accuracy: 0.9773\n",
            "Epoch 1127/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.0680 - val_accuracy: 0.9773\n",
            "Epoch 1128/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9861 - val_loss: 0.0681 - val_accuracy: 0.9760\n",
            "Epoch 1129/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9865 - val_loss: 0.0681 - val_accuracy: 0.9760\n",
            "Epoch 1130/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9861 - val_loss: 0.0680 - val_accuracy: 0.9773\n",
            "Epoch 1131/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.0682 - val_accuracy: 0.9760\n",
            "Epoch 1132/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.0680 - val_accuracy: 0.9773\n",
            "Epoch 1133/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.0679 - val_accuracy: 0.9773\n",
            "Epoch 1134/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.0678 - val_accuracy: 0.9773\n",
            "Epoch 1135/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.0679 - val_accuracy: 0.9773\n",
            "Epoch 1136/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.0679 - val_accuracy: 0.9773\n",
            "Epoch 1137/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9857 - val_loss: 0.0677 - val_accuracy: 0.9773\n",
            "Epoch 1138/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.0678 - val_accuracy: 0.9773\n",
            "Epoch 1139/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.0679 - val_accuracy: 0.9773\n",
            "Epoch 1140/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9861 - val_loss: 0.0681 - val_accuracy: 0.9760\n",
            "Epoch 1141/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.0680 - val_accuracy: 0.9773\n",
            "Epoch 1142/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9865 - val_loss: 0.0680 - val_accuracy: 0.9773\n",
            "Epoch 1143/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9865 - val_loss: 0.0679 - val_accuracy: 0.9773\n",
            "Epoch 1144/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9857 - val_loss: 0.0679 - val_accuracy: 0.9785\n",
            "Epoch 1145/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9865 - val_loss: 0.0680 - val_accuracy: 0.9773\n",
            "Epoch 1146/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9857 - val_loss: 0.0680 - val_accuracy: 0.9773\n",
            "Epoch 1147/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9865 - val_loss: 0.0682 - val_accuracy: 0.9773\n",
            "Epoch 1148/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9865 - val_loss: 0.0681 - val_accuracy: 0.9773\n",
            "Epoch 1149/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 0.0679 - val_accuracy: 0.9785\n",
            "Epoch 1150/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9857 - val_loss: 0.0681 - val_accuracy: 0.9773\n",
            "Epoch 1151/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9865 - val_loss: 0.0684 - val_accuracy: 0.9760\n",
            "Epoch 1152/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9865 - val_loss: 0.0681 - val_accuracy: 0.9773\n",
            "Epoch 1153/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9861 - val_loss: 0.0682 - val_accuracy: 0.9773\n",
            "Epoch 1154/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 0.9861 - val_loss: 0.0687 - val_accuracy: 0.9760\n",
            "Epoch 1155/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9861 - val_loss: 0.0685 - val_accuracy: 0.9760\n",
            "Epoch 1156/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9861 - val_loss: 0.0681 - val_accuracy: 0.9773\n",
            "Epoch 1157/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9865 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 1158/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9865 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 1159/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.0685 - val_accuracy: 0.9760\n",
            "Epoch 1160/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9861 - val_loss: 0.0684 - val_accuracy: 0.9773\n",
            "Epoch 1161/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9861 - val_loss: 0.0683 - val_accuracy: 0.9773\n",
            "Epoch 1162/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9861 - val_loss: 0.0682 - val_accuracy: 0.9773\n",
            "Epoch 1163/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9857 - val_loss: 0.0682 - val_accuracy: 0.9785\n",
            "Epoch 1164/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.0684 - val_accuracy: 0.9773\n",
            "Epoch 1165/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9861 - val_loss: 0.0684 - val_accuracy: 0.9773\n",
            "Epoch 1166/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.0684 - val_accuracy: 0.9773\n",
            "Epoch 1167/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9861 - val_loss: 0.0686 - val_accuracy: 0.9760\n",
            "Epoch 1168/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1169/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9870 - val_loss: 0.0696 - val_accuracy: 0.9760\n",
            "Epoch 1170/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9861 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
            "Epoch 1171/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9861 - val_loss: 0.0688 - val_accuracy: 0.9760\n",
            "Epoch 1172/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9861 - val_loss: 0.0684 - val_accuracy: 0.9773\n",
            "Epoch 1173/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.0684 - val_accuracy: 0.9773\n",
            "Epoch 1174/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 1175/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9870 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 1176/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9857 - val_loss: 0.0683 - val_accuracy: 0.9773\n",
            "Epoch 1177/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9865 - val_loss: 0.0684 - val_accuracy: 0.9773\n",
            "Epoch 1178/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9865 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 1179/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9861 - val_loss: 0.0684 - val_accuracy: 0.9773\n",
            "Epoch 1180/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9861 - val_loss: 0.0683 - val_accuracy: 0.9773\n",
            "Epoch 1181/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9861 - val_loss: 0.0684 - val_accuracy: 0.9773\n",
            "Epoch 1182/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9870 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 1183/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0684 - val_accuracy: 0.9773\n",
            "Epoch 1184/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 1185/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9870 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 1186/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9861 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 1187/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 1188/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9861 - val_loss: 0.0684 - val_accuracy: 0.9785\n",
            "Epoch 1189/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 1190/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1191/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1192/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1193/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9760\n",
            "Epoch 1194/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
            "Epoch 1195/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1196/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1197/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1198/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1199/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9861 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 1200/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1201/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1202/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1203/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9861 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1204/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1205/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1206/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9861 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1207/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1208/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1209/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1210/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1211/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 0.0684 - val_accuracy: 0.9785\n",
            "Epoch 1212/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 0.0685 - val_accuracy: 0.9785\n",
            "Epoch 1213/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1214/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0411 - accuracy: 0.9861 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1215/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0411 - accuracy: 0.9865 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1216/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0411 - accuracy: 0.9865 - val_loss: 0.0688 - val_accuracy: 0.9760\n",
            "Epoch 1217/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9861 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1218/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9870 - val_loss: 0.0685 - val_accuracy: 0.9773\n",
            "Epoch 1219/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1220/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1221/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1222/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1223/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9785\n",
            "Epoch 1224/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9861 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
            "Epoch 1225/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9865 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1226/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1227/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9865 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1228/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9865 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1229/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9865 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1230/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1231/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1232/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1233/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9865 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
            "Epoch 1234/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9861 - val_loss: 0.0690 - val_accuracy: 0.9760\n",
            "Epoch 1235/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9870 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
            "Epoch 1236/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9865 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1237/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1238/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9865 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
            "Epoch 1239/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9865 - val_loss: 0.0685 - val_accuracy: 0.9785\n",
            "Epoch 1240/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1241/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1242/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1243/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
            "Epoch 1244/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1245/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1246/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9785\n",
            "Epoch 1247/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1248/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1249/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9861 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
            "Epoch 1250/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1251/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
            "Epoch 1252/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1253/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1254/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9861 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
            "Epoch 1255/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1256/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1257/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1258/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9785\n",
            "Epoch 1259/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1260/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9865 - val_loss: 0.0685 - val_accuracy: 0.9785\n",
            "Epoch 1261/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9865 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1262/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1263/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1264/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9865 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1265/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1266/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9861 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
            "Epoch 1267/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1268/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1269/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1270/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1271/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9785\n",
            "Epoch 1272/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9865 - val_loss: 0.0685 - val_accuracy: 0.9785\n",
            "Epoch 1273/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9861 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1274/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0685 - val_accuracy: 0.9785\n",
            "Epoch 1275/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.0685 - val_accuracy: 0.9785\n",
            "Epoch 1276/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0686 - val_accuracy: 0.9773\n",
            "Epoch 1277/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.0685 - val_accuracy: 0.9785\n",
            "Epoch 1278/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9785\n",
            "Epoch 1279/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1280/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9785\n",
            "Epoch 1281/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9785\n",
            "Epoch 1282/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1283/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1284/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
            "Epoch 1285/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9874 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
            "Epoch 1286/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1287/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9874 - val_loss: 0.0686 - val_accuracy: 0.9785\n",
            "Epoch 1288/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1289/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1290/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9874 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1291/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.0686 - val_accuracy: 0.9785\n",
            "Epoch 1292/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9874 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1293/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1294/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9874 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1295/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1296/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9773\n",
            "Epoch 1297/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1298/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1299/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9874 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1300/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1301/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9785\n",
            "Epoch 1302/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
            "Epoch 1303/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9874 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
            "Epoch 1304/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9874 - val_loss: 0.0689 - val_accuracy: 0.9773\n",
            "Epoch 1305/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9785\n",
            "Epoch 1306/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9861 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1307/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1308/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9865 - val_loss: 0.0691 - val_accuracy: 0.9785\n",
            "Epoch 1309/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.0688 - val_accuracy: 0.9773\n",
            "Epoch 1310/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1311/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1312/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 0.0687 - val_accuracy: 0.9785\n",
            "Epoch 1313/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 0.0689 - val_accuracy: 0.9785\n",
            "Epoch 1314/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9861 - val_loss: 0.0689 - val_accuracy: 0.9785\n",
            "Epoch 1315/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0688 - val_accuracy: 0.9785\n",
            "Epoch 1316/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9874 - val_loss: 0.0689 - val_accuracy: 0.9785\n",
            "Epoch 1317/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.0688 - val_accuracy: 0.9785\n",
            "Epoch 1318/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.0700 - val_accuracy: 0.9773\n",
            "Epoch 1319/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.0692 - val_accuracy: 0.9785\n",
            "Epoch 1320/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9785\n",
            "Epoch 1321/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9785\n",
            "Epoch 1322/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9785\n",
            "Epoch 1323/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9785\n",
            "Epoch 1324/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9785\n",
            "Epoch 1325/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.0689 - val_accuracy: 0.9785\n",
            "Epoch 1326/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9785\n",
            "Epoch 1327/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9785\n",
            "Epoch 1328/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9785\n",
            "Epoch 1329/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9785\n",
            "Epoch 1330/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9865 - val_loss: 0.0689 - val_accuracy: 0.9785\n",
            "Epoch 1331/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9798\n",
            "Epoch 1332/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9785\n",
            "Epoch 1333/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9785\n",
            "Epoch 1334/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.0690 - val_accuracy: 0.9798\n",
            "Epoch 1335/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9785\n",
            "Epoch 1336/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9785\n",
            "Epoch 1337/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9798\n",
            "Epoch 1338/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1339/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9785\n",
            "Epoch 1340/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9785\n",
            "Epoch 1341/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9785\n",
            "Epoch 1342/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9785\n",
            "Epoch 1343/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9785\n",
            "Epoch 1344/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9870 - val_loss: 0.0690 - val_accuracy: 0.9798\n",
            "Epoch 1345/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0686 - val_accuracy: 0.9785\n",
            "Epoch 1346/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0688 - val_accuracy: 0.9785\n",
            "Epoch 1347/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9798\n",
            "Epoch 1348/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0689 - val_accuracy: 0.9798\n",
            "Epoch 1349/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9798\n",
            "Epoch 1350/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1351/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1352/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1353/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1354/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1355/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
            "Epoch 1356/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1357/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
            "Epoch 1358/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1359/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
            "Epoch 1360/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1361/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9798\n",
            "Epoch 1362/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9798\n",
            "Epoch 1363/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1364/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9798\n",
            "Epoch 1365/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
            "Epoch 1366/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9785\n",
            "Epoch 1367/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
            "Epoch 1368/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
            "Epoch 1369/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
            "Epoch 1370/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
            "Epoch 1371/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1372/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0690 - val_accuracy: 0.9798\n",
            "Epoch 1373/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1374/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
            "Epoch 1375/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
            "Epoch 1376/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0691 - val_accuracy: 0.9798\n",
            "Epoch 1377/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0693 - val_accuracy: 0.9798\n",
            "Epoch 1378/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1379/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0693 - val_accuracy: 0.9798\n",
            "Epoch 1380/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
            "Epoch 1381/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0693 - val_accuracy: 0.9798\n",
            "Epoch 1382/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
            "Epoch 1383/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0692 - val_accuracy: 0.9798\n",
            "Epoch 1384/1500\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0693 - val_accuracy: 0.9798\n",
            "Epoch 1385/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0693 - val_accuracy: 0.9798\n",
            "Epoch 1386/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0693 - val_accuracy: 0.9798\n",
            "Epoch 1387/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
            "Epoch 1388/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.0693 - val_accuracy: 0.9798\n",
            "Epoch 1389/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
            "Epoch 1390/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1391/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
            "Epoch 1392/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
            "Epoch 1393/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0697 - val_accuracy: 0.9785\n",
            "Epoch 1394/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
            "Epoch 1395/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.0693 - val_accuracy: 0.9798\n",
            "Epoch 1396/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
            "Epoch 1397/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1398/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1399/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1400/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
            "Epoch 1401/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
            "Epoch 1402/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1403/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0701 - val_accuracy: 0.9785\n",
            "Epoch 1404/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.0697 - val_accuracy: 0.9798\n",
            "Epoch 1405/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0697 - val_accuracy: 0.9798\n",
            "Epoch 1406/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 1407/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1408/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1409/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1410/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1411/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1412/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1413/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1414/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1415/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1416/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1417/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1418/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0697 - val_accuracy: 0.9798\n",
            "Epoch 1419/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9870 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1420/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1421/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1422/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1423/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1424/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 1425/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1426/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0697 - val_accuracy: 0.9798\n",
            "Epoch 1427/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0697 - val_accuracy: 0.9798\n",
            "Epoch 1428/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1429/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1430/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1431/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0702 - val_accuracy: 0.9785\n",
            "Epoch 1432/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.0701 - val_accuracy: 0.9785\n",
            "Epoch 1433/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1434/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
            "Epoch 1435/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1436/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0697 - val_accuracy: 0.9798\n",
            "Epoch 1437/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1438/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0697 - val_accuracy: 0.9798\n",
            "Epoch 1439/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1440/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1441/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0699 - val_accuracy: 0.9798\n",
            "Epoch 1442/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1443/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1444/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1445/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9798\n",
            "Epoch 1446/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1447/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.0703 - val_accuracy: 0.9785\n",
            "Epoch 1448/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0701 - val_accuracy: 0.9798\n",
            "Epoch 1449/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 1450/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1451/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0697 - val_accuracy: 0.9798\n",
            "Epoch 1452/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 1453/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0694 - val_accuracy: 0.9798\n",
            "Epoch 1454/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
            "Epoch 1455/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 1456/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0697 - val_accuracy: 0.9798\n",
            "Epoch 1457/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 1458/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.0697 - val_accuracy: 0.9798\n",
            "Epoch 1459/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.0697 - val_accuracy: 0.9798\n",
            "Epoch 1460/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.0699 - val_accuracy: 0.9798\n",
            "Epoch 1461/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.0700 - val_accuracy: 0.9798\n",
            "Epoch 1462/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 1463/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0699 - val_accuracy: 0.9798\n",
            "Epoch 1464/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0700 - val_accuracy: 0.9798\n",
            "Epoch 1465/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.0700 - val_accuracy: 0.9798\n",
            "Epoch 1466/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0700 - val_accuracy: 0.9798\n",
            "Epoch 1467/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0699 - val_accuracy: 0.9798\n",
            "Epoch 1468/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9870 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 1469/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0700 - val_accuracy: 0.9798\n",
            "Epoch 1470/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 1471/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 1472/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 1473/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.0703 - val_accuracy: 0.9798\n",
            "Epoch 1474/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0700 - val_accuracy: 0.9798\n",
            "Epoch 1475/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.0700 - val_accuracy: 0.9798\n",
            "Epoch 1476/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.0700 - val_accuracy: 0.9798\n",
            "Epoch 1477/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.0699 - val_accuracy: 0.9798\n",
            "Epoch 1478/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.0701 - val_accuracy: 0.9798\n",
            "Epoch 1479/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.0700 - val_accuracy: 0.9798\n",
            "Epoch 1480/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9874 - val_loss: 0.0699 - val_accuracy: 0.9798\n",
            "Epoch 1481/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0703 - val_accuracy: 0.9798\n",
            "Epoch 1482/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0701 - val_accuracy: 0.9798\n",
            "Epoch 1483/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0698 - val_accuracy: 0.9798\n",
            "Epoch 1484/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0699 - val_accuracy: 0.9798\n",
            "Epoch 1485/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0701 - val_accuracy: 0.9798\n",
            "Epoch 1486/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0703 - val_accuracy: 0.9798\n",
            "Epoch 1487/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0701 - val_accuracy: 0.9798\n",
            "Epoch 1488/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0703 - val_accuracy: 0.9798\n",
            "Epoch 1489/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0701 - val_accuracy: 0.9798\n",
            "Epoch 1490/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0700 - val_accuracy: 0.9798\n",
            "Epoch 1491/1500\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0701 - val_accuracy: 0.9798\n",
            "Epoch 1492/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9874 - val_loss: 0.0701 - val_accuracy: 0.9798\n",
            "Epoch 1493/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0701 - val_accuracy: 0.9798\n",
            "Epoch 1494/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0700 - val_accuracy: 0.9798\n",
            "Epoch 1495/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9874 - val_loss: 0.0706 - val_accuracy: 0.9798\n",
            "Epoch 1496/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.0701 - val_accuracy: 0.9798\n",
            "Epoch 1497/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 0.0700 - val_accuracy: 0.9811\n",
            "Epoch 1498/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0703 - val_accuracy: 0.9798\n",
            "Epoch 1499/1500\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9874 - val_loss: 0.0702 - val_accuracy: 0.9798\n",
            "Epoch 1500/1500\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9874 - val_loss: 0.0702 - val_accuracy: 0.9798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_supp = model_supp.predict(X_test_norm)\n",
        "y_pred_class_nn_supp = (y_pred_prob_nn_supp > 0.5).astype('int32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V56n7pgJLkQa",
        "outputId": "1946720c-a4f4-4f8a-cdfb-ea5b77e74994"
      },
      "id": "V56n7pgJLkQa",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_supp[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4GOU_vQL6zb",
        "outputId": "c784c102-a861-465f-a29a-e91090f25ff5"
      },
      "id": "b4GOU_vQL6zb",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_supp[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNvJ2OdDL-uB",
        "outputId": "83fe2e3a-6cdd-496d-832d-9d959e56af56"
      },
      "id": "XNvJ2OdDL-uB",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9989748e-01],\n",
              "       [9.9905604e-01],\n",
              "       [9.9817389e-01],\n",
              "       [9.9999958e-01],\n",
              "       [9.9989897e-01],\n",
              "       [9.9819648e-01],\n",
              "       [9.9983877e-01],\n",
              "       [9.8757589e-01],\n",
              "       [5.3232161e-05],\n",
              "       [3.3626668e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_hist_supp.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFlYBcZ4MBBK",
        "outputId": "15a34189-66d9-4b27-ff62-7e26ac4bc2aa"
      },
      "id": "kFlYBcZ4MBBK",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_supp.history['loss'], 'r', label = 'Train loss')\n",
        "ax.plot(run_hist_supp.history['val_loss'], 'b', label = \"Val loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ys6zD_pMMEOv",
        "outputId": "ff1104df-30a1-4d61-be73-445bb38b4509"
      },
      "id": "ys6zD_pMMEOv",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7b29bddc6a10>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve {} for Gender Classification in Byukilmaz'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ],
      "metadata": {
        "id": "n5wUBSIgNJHJ"
      },
      "id": "n5wUBSIgNJHJ",
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_supp)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_supp)))\n",
        "plot_roc(y_test, y_pred_prob_nn_supp, \"NN Model 1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "StP6oCbQOCPX",
        "outputId": "ce208c48-4e71-4e5a-f021-2e27f6461374"
      },
      "id": "StP6oCbQOCPX",
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.980\n",
            "roc-auc is 0.997\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The model shows above has a great result by having a high accuracy and roc-auc result. After testing it out with 1 hidden layer and 1500 epoch and .003 learning rate."
      ],
      "metadata": {
        "id": "9QyD99CXOq9p"
      },
      "id": "9QyD99CXOq9p"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2hidden layer, 200 epoch, .003 learning rate"
      ],
      "metadata": {
        "id": "REVKuPDTPRKJ"
      },
      "id": "REVKuPDTPRKJ"
    },
    {
      "cell_type": "code",
      "source": [
        "model_supp2 = Sequential([\n",
        " Dense(6, input_shape = (20, ), activation = 'relu'),\n",
        " Dense(6, input_shape = (20, ), activation = 'relu'),\n",
        " Dense(1, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "HB32zFqLOqZI"
      },
      "id": "HB32zFqLOqZI",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_supp2.compile(SGD(lr = 0.003), \"binary_crossentropy\", metrics = ['accuracy'])\n",
        "\n",
        "run_hist_supp2 = model_supp2.fit(X_train_norm, y_train, validation_data = (X_test_norm, y_test), epochs = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThS_bM0kPfQ1",
        "outputId": "5ae62ce5-0585-4697-f86c-1534d5cf707f"
      },
      "id": "ThS_bM0kPfQ1",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "75/75 [==============================] - 1s 5ms/step - loss: 0.6613 - accuracy: 0.7189 - val_loss: 0.6347 - val_accuracy: 0.7386\n",
            "Epoch 2/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.7795 - val_loss: 0.5861 - val_accuracy: 0.8005\n",
            "Epoch 3/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.8215 - val_loss: 0.5387 - val_accuracy: 0.8295\n",
            "Epoch 4/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.8413 - val_loss: 0.4904 - val_accuracy: 0.8535\n",
            "Epoch 5/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.8565 - val_loss: 0.4428 - val_accuracy: 0.8674\n",
            "Epoch 6/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8708 - val_loss: 0.3970 - val_accuracy: 0.8813\n",
            "Epoch 7/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8796 - val_loss: 0.3544 - val_accuracy: 0.8965\n",
            "Epoch 8/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3352 - accuracy: 0.8893 - val_loss: 0.3143 - val_accuracy: 0.9028\n",
            "Epoch 9/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.9011 - val_loss: 0.2782 - val_accuracy: 0.9129\n",
            "Epoch 10/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.9137 - val_loss: 0.2464 - val_accuracy: 0.9179\n",
            "Epoch 11/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9263 - val_loss: 0.2186 - val_accuracy: 0.9293\n",
            "Epoch 12/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9377 - val_loss: 0.1954 - val_accuracy: 0.9457\n",
            "Epoch 13/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1883 - accuracy: 0.9461 - val_loss: 0.1763 - val_accuracy: 0.9482\n",
            "Epoch 14/200\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.9541 - val_loss: 0.1599 - val_accuracy: 0.9520\n",
            "Epoch 15/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9588 - val_loss: 0.1466 - val_accuracy: 0.9520\n",
            "Epoch 16/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1416 - accuracy: 0.9613 - val_loss: 0.1357 - val_accuracy: 0.9533\n",
            "Epoch 17/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1308 - accuracy: 0.9634 - val_loss: 0.1269 - val_accuracy: 0.9520\n",
            "Epoch 18/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1221 - accuracy: 0.9642 - val_loss: 0.1200 - val_accuracy: 0.9533\n",
            "Epoch 19/200\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.1149 - accuracy: 0.9672 - val_loss: 0.1141 - val_accuracy: 0.9558\n",
            "Epoch 20/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1088 - accuracy: 0.9668 - val_loss: 0.1097 - val_accuracy: 0.9558\n",
            "Epoch 21/200\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.9697 - val_loss: 0.1059 - val_accuracy: 0.9571\n",
            "Epoch 22/200\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0996 - accuracy: 0.9697 - val_loss: 0.1030 - val_accuracy: 0.9583\n",
            "Epoch 23/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9701 - val_loss: 0.1004 - val_accuracy: 0.9596\n",
            "Epoch 24/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9710 - val_loss: 0.0987 - val_accuracy: 0.9583\n",
            "Epoch 25/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9693 - val_loss: 0.0969 - val_accuracy: 0.9583\n",
            "Epoch 26/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0879 - accuracy: 0.9710 - val_loss: 0.0954 - val_accuracy: 0.9596\n",
            "Epoch 27/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9718 - val_loss: 0.0939 - val_accuracy: 0.9596\n",
            "Epoch 28/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9718 - val_loss: 0.0929 - val_accuracy: 0.9609\n",
            "Epoch 29/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0827 - accuracy: 0.9726 - val_loss: 0.0918 - val_accuracy: 0.9609\n",
            "Epoch 30/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9722 - val_loss: 0.0910 - val_accuracy: 0.9609\n",
            "Epoch 31/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9726 - val_loss: 0.0903 - val_accuracy: 0.9609\n",
            "Epoch 32/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.9731 - val_loss: 0.0894 - val_accuracy: 0.9609\n",
            "Epoch 33/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9739 - val_loss: 0.0889 - val_accuracy: 0.9596\n",
            "Epoch 34/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9743 - val_loss: 0.0883 - val_accuracy: 0.9596\n",
            "Epoch 35/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9743 - val_loss: 0.0878 - val_accuracy: 0.9609\n",
            "Epoch 36/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 0.9743 - val_loss: 0.0871 - val_accuracy: 0.9634\n",
            "Epoch 37/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 0.9739 - val_loss: 0.0868 - val_accuracy: 0.9634\n",
            "Epoch 38/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9739 - val_loss: 0.0865 - val_accuracy: 0.9634\n",
            "Epoch 39/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0735 - accuracy: 0.9769 - val_loss: 0.0863 - val_accuracy: 0.9697\n",
            "Epoch 40/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9760 - val_loss: 0.0859 - val_accuracy: 0.9710\n",
            "Epoch 41/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9781 - val_loss: 0.0862 - val_accuracy: 0.9710\n",
            "Epoch 42/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9785 - val_loss: 0.0858 - val_accuracy: 0.9710\n",
            "Epoch 43/200\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9785 - val_loss: 0.0855 - val_accuracy: 0.9710\n",
            "Epoch 44/200\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0712 - accuracy: 0.9794 - val_loss: 0.0856 - val_accuracy: 0.9710\n",
            "Epoch 45/200\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9785 - val_loss: 0.0852 - val_accuracy: 0.9710\n",
            "Epoch 46/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9798 - val_loss: 0.0850 - val_accuracy: 0.9710\n",
            "Epoch 47/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9798 - val_loss: 0.0847 - val_accuracy: 0.9710\n",
            "Epoch 48/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9811 - val_loss: 0.0846 - val_accuracy: 0.9722\n",
            "Epoch 49/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.9806 - val_loss: 0.0843 - val_accuracy: 0.9710\n",
            "Epoch 50/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 0.9811 - val_loss: 0.0841 - val_accuracy: 0.9710\n",
            "Epoch 51/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9815 - val_loss: 0.0841 - val_accuracy: 0.9710\n",
            "Epoch 52/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9811 - val_loss: 0.0837 - val_accuracy: 0.9722\n",
            "Epoch 53/200\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0681 - accuracy: 0.9811 - val_loss: 0.0834 - val_accuracy: 0.9710\n",
            "Epoch 54/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.9811 - val_loss: 0.0832 - val_accuracy: 0.9710\n",
            "Epoch 55/200\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9811 - val_loss: 0.0829 - val_accuracy: 0.9710\n",
            "Epoch 56/200\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9811 - val_loss: 0.0827 - val_accuracy: 0.9722\n",
            "Epoch 57/200\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0670 - accuracy: 0.9811 - val_loss: 0.0828 - val_accuracy: 0.9735\n",
            "Epoch 58/200\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0669 - accuracy: 0.9815 - val_loss: 0.0825 - val_accuracy: 0.9710\n",
            "Epoch 59/200\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0666 - accuracy: 0.9815 - val_loss: 0.0824 - val_accuracy: 0.9722\n",
            "Epoch 60/200\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9811 - val_loss: 0.0823 - val_accuracy: 0.9722\n",
            "Epoch 61/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9823 - val_loss: 0.0820 - val_accuracy: 0.9722\n",
            "Epoch 62/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9819 - val_loss: 0.0820 - val_accuracy: 0.9722\n",
            "Epoch 63/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9815 - val_loss: 0.0818 - val_accuracy: 0.9722\n",
            "Epoch 64/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9819 - val_loss: 0.0818 - val_accuracy: 0.9735\n",
            "Epoch 65/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9823 - val_loss: 0.0819 - val_accuracy: 0.9735\n",
            "Epoch 66/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9811 - val_loss: 0.0813 - val_accuracy: 0.9722\n",
            "Epoch 67/200\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9819 - val_loss: 0.0811 - val_accuracy: 0.9722\n",
            "Epoch 68/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9819 - val_loss: 0.0810 - val_accuracy: 0.9722\n",
            "Epoch 69/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9815 - val_loss: 0.0810 - val_accuracy: 0.9735\n",
            "Epoch 70/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9815 - val_loss: 0.0808 - val_accuracy: 0.9735\n",
            "Epoch 71/200\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9811 - val_loss: 0.0806 - val_accuracy: 0.9722\n",
            "Epoch 72/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.9823 - val_loss: 0.0803 - val_accuracy: 0.9722\n",
            "Epoch 73/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9819 - val_loss: 0.0801 - val_accuracy: 0.9722\n",
            "Epoch 74/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9823 - val_loss: 0.0799 - val_accuracy: 0.9722\n",
            "Epoch 75/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.9823 - val_loss: 0.0796 - val_accuracy: 0.9722\n",
            "Epoch 76/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 0.9823 - val_loss: 0.0794 - val_accuracy: 0.9722\n",
            "Epoch 77/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9827 - val_loss: 0.0794 - val_accuracy: 0.9722\n",
            "Epoch 78/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9819 - val_loss: 0.0793 - val_accuracy: 0.9722\n",
            "Epoch 79/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.9827 - val_loss: 0.0792 - val_accuracy: 0.9722\n",
            "Epoch 80/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9823 - val_loss: 0.0792 - val_accuracy: 0.9722\n",
            "Epoch 81/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 0.9823 - val_loss: 0.0792 - val_accuracy: 0.9735\n",
            "Epoch 82/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.9827 - val_loss: 0.0789 - val_accuracy: 0.9722\n",
            "Epoch 83/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9832 - val_loss: 0.0788 - val_accuracy: 0.9722\n",
            "Epoch 84/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9819 - val_loss: 0.0786 - val_accuracy: 0.9735\n",
            "Epoch 85/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9832 - val_loss: 0.0783 - val_accuracy: 0.9735\n",
            "Epoch 86/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9832 - val_loss: 0.0783 - val_accuracy: 0.9722\n",
            "Epoch 87/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9836 - val_loss: 0.0783 - val_accuracy: 0.9735\n",
            "Epoch 88/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9827 - val_loss: 0.0779 - val_accuracy: 0.9722\n",
            "Epoch 89/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9840 - val_loss: 0.0780 - val_accuracy: 0.9735\n",
            "Epoch 90/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9827 - val_loss: 0.0774 - val_accuracy: 0.9722\n",
            "Epoch 91/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9832 - val_loss: 0.0770 - val_accuracy: 0.9722\n",
            "Epoch 92/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9832 - val_loss: 0.0771 - val_accuracy: 0.9722\n",
            "Epoch 93/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9832 - val_loss: 0.0771 - val_accuracy: 0.9722\n",
            "Epoch 94/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9840 - val_loss: 0.0771 - val_accuracy: 0.9735\n",
            "Epoch 95/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9836 - val_loss: 0.0768 - val_accuracy: 0.9722\n",
            "Epoch 96/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9832 - val_loss: 0.0766 - val_accuracy: 0.9722\n",
            "Epoch 97/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.9832 - val_loss: 0.0765 - val_accuracy: 0.9722\n",
            "Epoch 98/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9836 - val_loss: 0.0767 - val_accuracy: 0.9722\n",
            "Epoch 99/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9836 - val_loss: 0.0764 - val_accuracy: 0.9722\n",
            "Epoch 100/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9840 - val_loss: 0.0765 - val_accuracy: 0.9722\n",
            "Epoch 101/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9836 - val_loss: 0.0763 - val_accuracy: 0.9735\n",
            "Epoch 102/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9840 - val_loss: 0.0760 - val_accuracy: 0.9735\n",
            "Epoch 103/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9840 - val_loss: 0.0758 - val_accuracy: 0.9722\n",
            "Epoch 104/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9836 - val_loss: 0.0758 - val_accuracy: 0.9722\n",
            "Epoch 105/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9840 - val_loss: 0.0754 - val_accuracy: 0.9735\n",
            "Epoch 106/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9840 - val_loss: 0.0755 - val_accuracy: 0.9722\n",
            "Epoch 107/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9840 - val_loss: 0.0754 - val_accuracy: 0.9722\n",
            "Epoch 108/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9840 - val_loss: 0.0753 - val_accuracy: 0.9722\n",
            "Epoch 109/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9844 - val_loss: 0.0749 - val_accuracy: 0.9735\n",
            "Epoch 110/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9844 - val_loss: 0.0746 - val_accuracy: 0.9735\n",
            "Epoch 111/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9840 - val_loss: 0.0747 - val_accuracy: 0.9735\n",
            "Epoch 112/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9844 - val_loss: 0.0745 - val_accuracy: 0.9735\n",
            "Epoch 113/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9844 - val_loss: 0.0744 - val_accuracy: 0.9735\n",
            "Epoch 114/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9836 - val_loss: 0.0744 - val_accuracy: 0.9735\n",
            "Epoch 115/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9840 - val_loss: 0.0743 - val_accuracy: 0.9735\n",
            "Epoch 116/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9840 - val_loss: 0.0743 - val_accuracy: 0.9735\n",
            "Epoch 117/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9844 - val_loss: 0.0742 - val_accuracy: 0.9735\n",
            "Epoch 118/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9848 - val_loss: 0.0741 - val_accuracy: 0.9747\n",
            "Epoch 119/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9844 - val_loss: 0.0739 - val_accuracy: 0.9747\n",
            "Epoch 120/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9848 - val_loss: 0.0734 - val_accuracy: 0.9747\n",
            "Epoch 121/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9844 - val_loss: 0.0735 - val_accuracy: 0.9735\n",
            "Epoch 122/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9840 - val_loss: 0.0734 - val_accuracy: 0.9722\n",
            "Epoch 123/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9844 - val_loss: 0.0733 - val_accuracy: 0.9735\n",
            "Epoch 124/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9844 - val_loss: 0.0732 - val_accuracy: 0.9722\n",
            "Epoch 125/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9844 - val_loss: 0.0734 - val_accuracy: 0.9710\n",
            "Epoch 126/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9840 - val_loss: 0.0735 - val_accuracy: 0.9722\n",
            "Epoch 127/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9844 - val_loss: 0.0734 - val_accuracy: 0.9722\n",
            "Epoch 128/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9844 - val_loss: 0.0732 - val_accuracy: 0.9710\n",
            "Epoch 129/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9844 - val_loss: 0.0730 - val_accuracy: 0.9722\n",
            "Epoch 130/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9848 - val_loss: 0.0729 - val_accuracy: 0.9710\n",
            "Epoch 131/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9840 - val_loss: 0.0730 - val_accuracy: 0.9722\n",
            "Epoch 132/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9844 - val_loss: 0.0729 - val_accuracy: 0.9710\n",
            "Epoch 133/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9844 - val_loss: 0.0727 - val_accuracy: 0.9710\n",
            "Epoch 134/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9848 - val_loss: 0.0731 - val_accuracy: 0.9722\n",
            "Epoch 135/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9844 - val_loss: 0.0724 - val_accuracy: 0.9710\n",
            "Epoch 136/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9844 - val_loss: 0.0723 - val_accuracy: 0.9722\n",
            "Epoch 137/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9853 - val_loss: 0.0721 - val_accuracy: 0.9722\n",
            "Epoch 138/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9844 - val_loss: 0.0721 - val_accuracy: 0.9722\n",
            "Epoch 139/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9848 - val_loss: 0.0722 - val_accuracy: 0.9710\n",
            "Epoch 140/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9848 - val_loss: 0.0721 - val_accuracy: 0.9722\n",
            "Epoch 141/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9844 - val_loss: 0.0719 - val_accuracy: 0.9710\n",
            "Epoch 142/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9844 - val_loss: 0.0719 - val_accuracy: 0.9710\n",
            "Epoch 143/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9848 - val_loss: 0.0718 - val_accuracy: 0.9735\n",
            "Epoch 144/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9840 - val_loss: 0.0718 - val_accuracy: 0.9722\n",
            "Epoch 145/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9848 - val_loss: 0.0718 - val_accuracy: 0.9722\n",
            "Epoch 146/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9853 - val_loss: 0.0714 - val_accuracy: 0.9722\n",
            "Epoch 147/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9853 - val_loss: 0.0714 - val_accuracy: 0.9722\n",
            "Epoch 148/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9848 - val_loss: 0.0717 - val_accuracy: 0.9735\n",
            "Epoch 149/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9844 - val_loss: 0.0712 - val_accuracy: 0.9722\n",
            "Epoch 150/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0557 - accuracy: 0.9853 - val_loss: 0.0712 - val_accuracy: 0.9722\n",
            "Epoch 151/200\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9848 - val_loss: 0.0713 - val_accuracy: 0.9722\n",
            "Epoch 152/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9848 - val_loss: 0.0714 - val_accuracy: 0.9735\n",
            "Epoch 153/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9853 - val_loss: 0.0711 - val_accuracy: 0.9722\n",
            "Epoch 154/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9853 - val_loss: 0.0710 - val_accuracy: 0.9722\n",
            "Epoch 155/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9848 - val_loss: 0.0710 - val_accuracy: 0.9722\n",
            "Epoch 156/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9848 - val_loss: 0.0710 - val_accuracy: 0.9722\n",
            "Epoch 157/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9853 - val_loss: 0.0710 - val_accuracy: 0.9722\n",
            "Epoch 158/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9844 - val_loss: 0.0709 - val_accuracy: 0.9722\n",
            "Epoch 159/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9848 - val_loss: 0.0707 - val_accuracy: 0.9722\n",
            "Epoch 160/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9857 - val_loss: 0.0707 - val_accuracy: 0.9722\n",
            "Epoch 161/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9853 - val_loss: 0.0708 - val_accuracy: 0.9722\n",
            "Epoch 162/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9853 - val_loss: 0.0708 - val_accuracy: 0.9722\n",
            "Epoch 163/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9853 - val_loss: 0.0711 - val_accuracy: 0.9710\n",
            "Epoch 164/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9848 - val_loss: 0.0708 - val_accuracy: 0.9722\n",
            "Epoch 165/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9853 - val_loss: 0.0708 - val_accuracy: 0.9722\n",
            "Epoch 166/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9848 - val_loss: 0.0707 - val_accuracy: 0.9722\n",
            "Epoch 167/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9853 - val_loss: 0.0704 - val_accuracy: 0.9735\n",
            "Epoch 168/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9840 - val_loss: 0.0704 - val_accuracy: 0.9735\n",
            "Epoch 169/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9848 - val_loss: 0.0702 - val_accuracy: 0.9722\n",
            "Epoch 170/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0540 - accuracy: 0.9857 - val_loss: 0.0712 - val_accuracy: 0.9722\n",
            "Epoch 171/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9853 - val_loss: 0.0710 - val_accuracy: 0.9710\n",
            "Epoch 172/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9848 - val_loss: 0.0711 - val_accuracy: 0.9722\n",
            "Epoch 173/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9861 - val_loss: 0.0707 - val_accuracy: 0.9710\n",
            "Epoch 174/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9857 - val_loss: 0.0708 - val_accuracy: 0.9722\n",
            "Epoch 175/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9857 - val_loss: 0.0702 - val_accuracy: 0.9722\n",
            "Epoch 176/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9861 - val_loss: 0.0701 - val_accuracy: 0.9722\n",
            "Epoch 177/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9857 - val_loss: 0.0702 - val_accuracy: 0.9722\n",
            "Epoch 178/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9857 - val_loss: 0.0699 - val_accuracy: 0.9735\n",
            "Epoch 179/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9853 - val_loss: 0.0700 - val_accuracy: 0.9735\n",
            "Epoch 180/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9848 - val_loss: 0.0699 - val_accuracy: 0.9722\n",
            "Epoch 181/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9857 - val_loss: 0.0700 - val_accuracy: 0.9722\n",
            "Epoch 182/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9848 - val_loss: 0.0698 - val_accuracy: 0.9735\n",
            "Epoch 183/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9848 - val_loss: 0.0700 - val_accuracy: 0.9722\n",
            "Epoch 184/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9844 - val_loss: 0.0696 - val_accuracy: 0.9722\n",
            "Epoch 185/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9857 - val_loss: 0.0694 - val_accuracy: 0.9722\n",
            "Epoch 186/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9857 - val_loss: 0.0694 - val_accuracy: 0.9735\n",
            "Epoch 187/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9861 - val_loss: 0.0695 - val_accuracy: 0.9722\n",
            "Epoch 188/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9857 - val_loss: 0.0694 - val_accuracy: 0.9735\n",
            "Epoch 189/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9857 - val_loss: 0.0695 - val_accuracy: 0.9735\n",
            "Epoch 190/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9853 - val_loss: 0.0693 - val_accuracy: 0.9747\n",
            "Epoch 191/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9848 - val_loss: 0.0695 - val_accuracy: 0.9735\n",
            "Epoch 192/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9853 - val_loss: 0.0693 - val_accuracy: 0.9735\n",
            "Epoch 193/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9857 - val_loss: 0.0689 - val_accuracy: 0.9760\n",
            "Epoch 194/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9857 - val_loss: 0.0686 - val_accuracy: 0.9747\n",
            "Epoch 195/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9861 - val_loss: 0.0687 - val_accuracy: 0.9735\n",
            "Epoch 196/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9853 - val_loss: 0.0687 - val_accuracy: 0.9747\n",
            "Epoch 197/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9840 - val_loss: 0.0691 - val_accuracy: 0.9747\n",
            "Epoch 198/200\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9857 - val_loss: 0.0688 - val_accuracy: 0.9747\n",
            "Epoch 199/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9853 - val_loss: 0.0688 - val_accuracy: 0.9747\n",
            "Epoch 200/200\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9861 - val_loss: 0.0685 - val_accuracy: 0.9747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_supp2 = model_supp2.predict(X_test_norm)\n",
        "y_pred_class_nn_supp2 = (y_pred_prob_nn_supp2 > 0.5).astype('int32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcTqH1TpP3Yd",
        "outputId": "34a7e7f6-8acd-4303-d3e9-8395a5cc6ce0"
      },
      "id": "lcTqH1TpP3Yd",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_supp2[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeqhGKGkQKQp",
        "outputId": "633651f1-c113-4ce7-c79a-fea9d5bb472c"
      },
      "id": "MeqhGKGkQKQp",
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_supp2[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6KhHO8NQKp3",
        "outputId": "9f9e7e1e-06aa-4618-d9c0-679f4e7eb4a7"
      },
      "id": "s6KhHO8NQKp3",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9758953e-01],\n",
              "       [9.9632859e-01],\n",
              "       [9.9464029e-01],\n",
              "       [9.9986553e-01],\n",
              "       [9.9732304e-01],\n",
              "       [9.5251268e-01],\n",
              "       [9.9892521e-01],\n",
              "       [5.4142284e-01],\n",
              "       [2.0988989e-03],\n",
              "       [3.9202740e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_hist_supp2.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYFjOcbiQMbN",
        "outputId": "9fae2680-e52f-47dd-e88e-28f753548c38"
      },
      "id": "XYFjOcbiQMbN",
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_supp2.history['loss'], 'r', label = 'Train loss')\n",
        "ax.plot(run_hist_supp2.history['val_loss'], 'b', label = \"Val loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "6e0IDVLgQNgX",
        "outputId": "284d8123-c955-4a14-9564-cbdacf1a00f4"
      },
      "id": "6e0IDVLgQNgX",
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7b29b595dd50>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve {} for Gender Classification in Byukilmaz'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ],
      "metadata": {
        "id": "wLp3e26FVNlu"
      },
      "id": "wLp3e26FVNlu",
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_supp2)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_supp2)))\n",
        "plot_roc(y_test, y_pred_prob_nn_supp, \"NN Model 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "3rXc2BvzVOxN",
        "outputId": "ff9c99e6-1013-4b49-8ec6-771e298c7aa9"
      },
      "id": "3rXc2BvzVOxN",
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.975\n",
            "roc-auc is 0.997\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-With 2 hidden layers and 800 epoch with the same learning rate, this model shows a impressive result."
      ],
      "metadata": {
        "id": "oBwcWqh9U57a"
      },
      "id": "oBwcWqh9U57a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 hidden layer, learning rate of .001, epoch of 800"
      ],
      "metadata": {
        "id": "zQiXLCfNU5Cc"
      },
      "id": "zQiXLCfNU5Cc"
    },
    {
      "cell_type": "code",
      "source": [
        "model_supp3 = Sequential([\n",
        " Dense(6, input_shape = (20, ), activation = 'relu'),\n",
        " Dense(6, input_shape = (20, ), activation = 'relu'),\n",
        " Dense(1, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "NdHcAb-JUw0j"
      },
      "id": "NdHcAb-JUw0j",
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_supp3.compile(SGD(lr = 0.001), \"binary_crossentropy\", metrics = ['accuracy'])\n",
        "\n",
        "run_hist_supp3 = model_supp3.fit(X_train_norm, y_train, validation_data = (X_test_norm, y_test), epochs = 800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY9X0bUbUzrz",
        "outputId": "146b7507-01b1-4eb7-d732-ece06f574076"
      },
      "id": "tY9X0bUbUzrz",
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "75/75 [==============================] - 2s 11ms/step - loss: 0.6292 - accuracy: 0.5997 - val_loss: 0.5769 - val_accuracy: 0.6843\n",
            "Epoch 2/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7210 - val_loss: 0.5185 - val_accuracy: 0.7866\n",
            "Epoch 3/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7976 - val_loss: 0.4776 - val_accuracy: 0.8295\n",
            "Epoch 4/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.8312 - val_loss: 0.4454 - val_accuracy: 0.8687\n",
            "Epoch 5/800\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.4460 - accuracy: 0.8497 - val_loss: 0.4178 - val_accuracy: 0.8826\n",
            "Epoch 6/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8670 - val_loss: 0.3933 - val_accuracy: 0.8965\n",
            "Epoch 7/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8767 - val_loss: 0.3711 - val_accuracy: 0.9003\n",
            "Epoch 8/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8809 - val_loss: 0.3502 - val_accuracy: 0.9091\n",
            "Epoch 9/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8897 - val_loss: 0.3303 - val_accuracy: 0.9129\n",
            "Epoch 10/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8956 - val_loss: 0.3099 - val_accuracy: 0.9217\n",
            "Epoch 11/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.3187 - accuracy: 0.9053 - val_loss: 0.2887 - val_accuracy: 0.9318\n",
            "Epoch 12/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.9184 - val_loss: 0.2653 - val_accuracy: 0.9407\n",
            "Epoch 13/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.9285 - val_loss: 0.2417 - val_accuracy: 0.9495\n",
            "Epoch 14/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9377 - val_loss: 0.2190 - val_accuracy: 0.9545\n",
            "Epoch 15/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9440 - val_loss: 0.1988 - val_accuracy: 0.9609\n",
            "Epoch 16/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.2022 - accuracy: 0.9478 - val_loss: 0.1800 - val_accuracy: 0.9634\n",
            "Epoch 17/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9524 - val_loss: 0.1642 - val_accuracy: 0.9659\n",
            "Epoch 18/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1689 - accuracy: 0.9537 - val_loss: 0.1505 - val_accuracy: 0.9672\n",
            "Epoch 19/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9566 - val_loss: 0.1390 - val_accuracy: 0.9722\n",
            "Epoch 20/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9588 - val_loss: 0.1294 - val_accuracy: 0.9735\n",
            "Epoch 21/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9617 - val_loss: 0.1210 - val_accuracy: 0.9760\n",
            "Epoch 22/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9630 - val_loss: 0.1146 - val_accuracy: 0.9747\n",
            "Epoch 23/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1204 - accuracy: 0.9638 - val_loss: 0.1094 - val_accuracy: 0.9735\n",
            "Epoch 24/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1146 - accuracy: 0.9642 - val_loss: 0.1048 - val_accuracy: 0.9722\n",
            "Epoch 25/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9651 - val_loss: 0.1014 - val_accuracy: 0.9710\n",
            "Epoch 26/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9668 - val_loss: 0.0980 - val_accuracy: 0.9710\n",
            "Epoch 27/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.1022 - accuracy: 0.9680 - val_loss: 0.0949 - val_accuracy: 0.9710\n",
            "Epoch 28/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9684 - val_loss: 0.0929 - val_accuracy: 0.9710\n",
            "Epoch 29/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9697 - val_loss: 0.0906 - val_accuracy: 0.9710\n",
            "Epoch 30/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0944 - accuracy: 0.9693 - val_loss: 0.0892 - val_accuracy: 0.9684\n",
            "Epoch 31/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.9710 - val_loss: 0.0877 - val_accuracy: 0.9697\n",
            "Epoch 32/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9718 - val_loss: 0.0865 - val_accuracy: 0.9697\n",
            "Epoch 33/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9726 - val_loss: 0.0852 - val_accuracy: 0.9710\n",
            "Epoch 34/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9726 - val_loss: 0.0841 - val_accuracy: 0.9710\n",
            "Epoch 35/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9722 - val_loss: 0.0830 - val_accuracy: 0.9710\n",
            "Epoch 36/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9739 - val_loss: 0.0817 - val_accuracy: 0.9710\n",
            "Epoch 37/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9722 - val_loss: 0.0814 - val_accuracy: 0.9710\n",
            "Epoch 38/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9731 - val_loss: 0.0805 - val_accuracy: 0.9710\n",
            "Epoch 39/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9739 - val_loss: 0.0803 - val_accuracy: 0.9710\n",
            "Epoch 40/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9739 - val_loss: 0.0792 - val_accuracy: 0.9710\n",
            "Epoch 41/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9739 - val_loss: 0.0790 - val_accuracy: 0.9697\n",
            "Epoch 42/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9743 - val_loss: 0.0790 - val_accuracy: 0.9697\n",
            "Epoch 43/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9764 - val_loss: 0.0782 - val_accuracy: 0.9697\n",
            "Epoch 44/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9760 - val_loss: 0.0780 - val_accuracy: 0.9697\n",
            "Epoch 45/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 0.9769 - val_loss: 0.0766 - val_accuracy: 0.9722\n",
            "Epoch 46/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9760 - val_loss: 0.0757 - val_accuracy: 0.9722\n",
            "Epoch 47/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9764 - val_loss: 0.0752 - val_accuracy: 0.9735\n",
            "Epoch 48/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9773 - val_loss: 0.0762 - val_accuracy: 0.9722\n",
            "Epoch 49/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9777 - val_loss: 0.0748 - val_accuracy: 0.9722\n",
            "Epoch 50/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9785 - val_loss: 0.0746 - val_accuracy: 0.9722\n",
            "Epoch 51/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9777 - val_loss: 0.0744 - val_accuracy: 0.9722\n",
            "Epoch 52/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 0.9794 - val_loss: 0.0737 - val_accuracy: 0.9710\n",
            "Epoch 53/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9777 - val_loss: 0.0733 - val_accuracy: 0.9722\n",
            "Epoch 54/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9773 - val_loss: 0.0736 - val_accuracy: 0.9722\n",
            "Epoch 55/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9794 - val_loss: 0.0733 - val_accuracy: 0.9722\n",
            "Epoch 56/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9790 - val_loss: 0.0737 - val_accuracy: 0.9735\n",
            "Epoch 57/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9811 - val_loss: 0.0728 - val_accuracy: 0.9722\n",
            "Epoch 58/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9802 - val_loss: 0.0724 - val_accuracy: 0.9735\n",
            "Epoch 59/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9798 - val_loss: 0.0727 - val_accuracy: 0.9722\n",
            "Epoch 60/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9798 - val_loss: 0.0725 - val_accuracy: 0.9722\n",
            "Epoch 61/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9802 - val_loss: 0.0724 - val_accuracy: 0.9722\n",
            "Epoch 62/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.9802 - val_loss: 0.0722 - val_accuracy: 0.9722\n",
            "Epoch 63/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9798 - val_loss: 0.0721 - val_accuracy: 0.9722\n",
            "Epoch 64/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9806 - val_loss: 0.0714 - val_accuracy: 0.9760\n",
            "Epoch 65/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9823 - val_loss: 0.0705 - val_accuracy: 0.9722\n",
            "Epoch 66/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9798 - val_loss: 0.0711 - val_accuracy: 0.9747\n",
            "Epoch 67/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9823 - val_loss: 0.0710 - val_accuracy: 0.9747\n",
            "Epoch 68/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9806 - val_loss: 0.0714 - val_accuracy: 0.9747\n",
            "Epoch 69/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9819 - val_loss: 0.0716 - val_accuracy: 0.9735\n",
            "Epoch 70/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9815 - val_loss: 0.0706 - val_accuracy: 0.9735\n",
            "Epoch 71/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9815 - val_loss: 0.0705 - val_accuracy: 0.9722\n",
            "Epoch 72/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9819 - val_loss: 0.0703 - val_accuracy: 0.9735\n",
            "Epoch 73/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9819 - val_loss: 0.0702 - val_accuracy: 0.9735\n",
            "Epoch 74/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9832 - val_loss: 0.0701 - val_accuracy: 0.9735\n",
            "Epoch 75/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9827 - val_loss: 0.0702 - val_accuracy: 0.9735\n",
            "Epoch 76/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9823 - val_loss: 0.0700 - val_accuracy: 0.9735\n",
            "Epoch 77/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9815 - val_loss: 0.0698 - val_accuracy: 0.9747\n",
            "Epoch 78/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9815 - val_loss: 0.0696 - val_accuracy: 0.9747\n",
            "Epoch 79/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9819 - val_loss: 0.0689 - val_accuracy: 0.9735\n",
            "Epoch 80/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0670 - accuracy: 0.9815 - val_loss: 0.0691 - val_accuracy: 0.9735\n",
            "Epoch 81/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9815 - val_loss: 0.0689 - val_accuracy: 0.9735\n",
            "Epoch 82/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9811 - val_loss: 0.0686 - val_accuracy: 0.9735\n",
            "Epoch 83/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9815 - val_loss: 0.0682 - val_accuracy: 0.9735\n",
            "Epoch 84/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9815 - val_loss: 0.0675 - val_accuracy: 0.9747\n",
            "Epoch 85/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9823 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
            "Epoch 86/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9815 - val_loss: 0.0669 - val_accuracy: 0.9760\n",
            "Epoch 87/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9806 - val_loss: 0.0666 - val_accuracy: 0.9735\n",
            "Epoch 88/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9815 - val_loss: 0.0666 - val_accuracy: 0.9735\n",
            "Epoch 89/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9819 - val_loss: 0.0664 - val_accuracy: 0.9747\n",
            "Epoch 90/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9811 - val_loss: 0.0664 - val_accuracy: 0.9747\n",
            "Epoch 91/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9819 - val_loss: 0.0663 - val_accuracy: 0.9747\n",
            "Epoch 92/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9819 - val_loss: 0.0663 - val_accuracy: 0.9735\n",
            "Epoch 93/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9819 - val_loss: 0.0660 - val_accuracy: 0.9735\n",
            "Epoch 94/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9815 - val_loss: 0.0658 - val_accuracy: 0.9747\n",
            "Epoch 95/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9815 - val_loss: 0.0654 - val_accuracy: 0.9760\n",
            "Epoch 96/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9815 - val_loss: 0.0654 - val_accuracy: 0.9735\n",
            "Epoch 97/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9819 - val_loss: 0.0655 - val_accuracy: 0.9747\n",
            "Epoch 98/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9819 - val_loss: 0.0655 - val_accuracy: 0.9760\n",
            "Epoch 99/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9806 - val_loss: 0.0650 - val_accuracy: 0.9747\n",
            "Epoch 100/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9815 - val_loss: 0.0651 - val_accuracy: 0.9747\n",
            "Epoch 101/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9819 - val_loss: 0.0650 - val_accuracy: 0.9747\n",
            "Epoch 102/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9811 - val_loss: 0.0651 - val_accuracy: 0.9760\n",
            "Epoch 103/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9819 - val_loss: 0.0652 - val_accuracy: 0.9735\n",
            "Epoch 104/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9819 - val_loss: 0.0650 - val_accuracy: 0.9760\n",
            "Epoch 105/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9811 - val_loss: 0.0649 - val_accuracy: 0.9747\n",
            "Epoch 106/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9819 - val_loss: 0.0646 - val_accuracy: 0.9760\n",
            "Epoch 107/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9819 - val_loss: 0.0647 - val_accuracy: 0.9747\n",
            "Epoch 108/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9819 - val_loss: 0.0646 - val_accuracy: 0.9760\n",
            "Epoch 109/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9823 - val_loss: 0.0645 - val_accuracy: 0.9747\n",
            "Epoch 110/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9815 - val_loss: 0.0645 - val_accuracy: 0.9747\n",
            "Epoch 111/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9819 - val_loss: 0.0643 - val_accuracy: 0.9747\n",
            "Epoch 112/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9823 - val_loss: 0.0639 - val_accuracy: 0.9760\n",
            "Epoch 113/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9819 - val_loss: 0.0638 - val_accuracy: 0.9760\n",
            "Epoch 114/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9815 - val_loss: 0.0637 - val_accuracy: 0.9735\n",
            "Epoch 115/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9819 - val_loss: 0.0641 - val_accuracy: 0.9747\n",
            "Epoch 116/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9832 - val_loss: 0.0640 - val_accuracy: 0.9747\n",
            "Epoch 117/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9819 - val_loss: 0.0636 - val_accuracy: 0.9747\n",
            "Epoch 118/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9823 - val_loss: 0.0634 - val_accuracy: 0.9747\n",
            "Epoch 119/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9832 - val_loss: 0.0635 - val_accuracy: 0.9747\n",
            "Epoch 120/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9823 - val_loss: 0.0634 - val_accuracy: 0.9735\n",
            "Epoch 121/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0597 - accuracy: 0.9827 - val_loss: 0.0634 - val_accuracy: 0.9735\n",
            "Epoch 122/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9823 - val_loss: 0.0633 - val_accuracy: 0.9747\n",
            "Epoch 123/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9815 - val_loss: 0.0632 - val_accuracy: 0.9735\n",
            "Epoch 124/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9823 - val_loss: 0.0632 - val_accuracy: 0.9735\n",
            "Epoch 125/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9827 - val_loss: 0.0632 - val_accuracy: 0.9735\n",
            "Epoch 126/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9827 - val_loss: 0.0631 - val_accuracy: 0.9747\n",
            "Epoch 127/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9827 - val_loss: 0.0631 - val_accuracy: 0.9747\n",
            "Epoch 128/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9827 - val_loss: 0.0630 - val_accuracy: 0.9747\n",
            "Epoch 129/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9823 - val_loss: 0.0630 - val_accuracy: 0.9747\n",
            "Epoch 130/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9827 - val_loss: 0.0630 - val_accuracy: 0.9747\n",
            "Epoch 131/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9827 - val_loss: 0.0629 - val_accuracy: 0.9747\n",
            "Epoch 132/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9827 - val_loss: 0.0633 - val_accuracy: 0.9735\n",
            "Epoch 133/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9823 - val_loss: 0.0630 - val_accuracy: 0.9747\n",
            "Epoch 134/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9827 - val_loss: 0.0629 - val_accuracy: 0.9735\n",
            "Epoch 135/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9832 - val_loss: 0.0628 - val_accuracy: 0.9735\n",
            "Epoch 136/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9832 - val_loss: 0.0627 - val_accuracy: 0.9735\n",
            "Epoch 137/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9823 - val_loss: 0.0627 - val_accuracy: 0.9735\n",
            "Epoch 138/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9819 - val_loss: 0.0627 - val_accuracy: 0.9722\n",
            "Epoch 139/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9827 - val_loss: 0.0625 - val_accuracy: 0.9747\n",
            "Epoch 140/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9823 - val_loss: 0.0625 - val_accuracy: 0.9735\n",
            "Epoch 141/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9823 - val_loss: 0.0626 - val_accuracy: 0.9722\n",
            "Epoch 142/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9827 - val_loss: 0.0624 - val_accuracy: 0.9735\n",
            "Epoch 143/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9823 - val_loss: 0.0624 - val_accuracy: 0.9735\n",
            "Epoch 144/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9832 - val_loss: 0.0622 - val_accuracy: 0.9735\n",
            "Epoch 145/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 0.0623 - val_accuracy: 0.9722\n",
            "Epoch 146/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9827 - val_loss: 0.0622 - val_accuracy: 0.9722\n",
            "Epoch 147/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.9827 - val_loss: 0.0622 - val_accuracy: 0.9735\n",
            "Epoch 148/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9823 - val_loss: 0.0621 - val_accuracy: 0.9735\n",
            "Epoch 149/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.9832 - val_loss: 0.0615 - val_accuracy: 0.9747\n",
            "Epoch 150/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9827 - val_loss: 0.0612 - val_accuracy: 0.9735\n",
            "Epoch 151/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9823 - val_loss: 0.0614 - val_accuracy: 0.9735\n",
            "Epoch 152/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9827 - val_loss: 0.0615 - val_accuracy: 0.9722\n",
            "Epoch 153/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9832 - val_loss: 0.0616 - val_accuracy: 0.9722\n",
            "Epoch 154/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.9832 - val_loss: 0.0615 - val_accuracy: 0.9735\n",
            "Epoch 155/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9832 - val_loss: 0.0618 - val_accuracy: 0.9735\n",
            "Epoch 156/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9840 - val_loss: 0.0616 - val_accuracy: 0.9722\n",
            "Epoch 157/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9832 - val_loss: 0.0617 - val_accuracy: 0.9722\n",
            "Epoch 158/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9827 - val_loss: 0.0615 - val_accuracy: 0.9735\n",
            "Epoch 159/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9832 - val_loss: 0.0615 - val_accuracy: 0.9735\n",
            "Epoch 160/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9832 - val_loss: 0.0616 - val_accuracy: 0.9735\n",
            "Epoch 161/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0555 - accuracy: 0.9827 - val_loss: 0.0617 - val_accuracy: 0.9735\n",
            "Epoch 162/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9836 - val_loss: 0.0616 - val_accuracy: 0.9747\n",
            "Epoch 163/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9832 - val_loss: 0.0614 - val_accuracy: 0.9747\n",
            "Epoch 164/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9840 - val_loss: 0.0612 - val_accuracy: 0.9747\n",
            "Epoch 165/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9827 - val_loss: 0.0611 - val_accuracy: 0.9735\n",
            "Epoch 166/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9836 - val_loss: 0.0610 - val_accuracy: 0.9747\n",
            "Epoch 167/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9836 - val_loss: 0.0609 - val_accuracy: 0.9747\n",
            "Epoch 168/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9832 - val_loss: 0.0608 - val_accuracy: 0.9735\n",
            "Epoch 169/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9832 - val_loss: 0.0609 - val_accuracy: 0.9735\n",
            "Epoch 170/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9832 - val_loss: 0.0609 - val_accuracy: 0.9735\n",
            "Epoch 171/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9836 - val_loss: 0.0607 - val_accuracy: 0.9747\n",
            "Epoch 172/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9836 - val_loss: 0.0604 - val_accuracy: 0.9747\n",
            "Epoch 173/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9840 - val_loss: 0.0604 - val_accuracy: 0.9747\n",
            "Epoch 174/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9840 - val_loss: 0.0605 - val_accuracy: 0.9735\n",
            "Epoch 175/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9848 - val_loss: 0.0605 - val_accuracy: 0.9735\n",
            "Epoch 176/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9836 - val_loss: 0.0606 - val_accuracy: 0.9747\n",
            "Epoch 177/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9853 - val_loss: 0.0605 - val_accuracy: 0.9747\n",
            "Epoch 178/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9844 - val_loss: 0.0604 - val_accuracy: 0.9747\n",
            "Epoch 179/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9844 - val_loss: 0.0602 - val_accuracy: 0.9735\n",
            "Epoch 180/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9844 - val_loss: 0.0608 - val_accuracy: 0.9747\n",
            "Epoch 181/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9848 - val_loss: 0.0604 - val_accuracy: 0.9735\n",
            "Epoch 182/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9853 - val_loss: 0.0602 - val_accuracy: 0.9735\n",
            "Epoch 183/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9853 - val_loss: 0.0601 - val_accuracy: 0.9735\n",
            "Epoch 184/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9861 - val_loss: 0.0598 - val_accuracy: 0.9747\n",
            "Epoch 185/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0530 - accuracy: 0.9848 - val_loss: 0.0602 - val_accuracy: 0.9747\n",
            "Epoch 186/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9857 - val_loss: 0.0598 - val_accuracy: 0.9735\n",
            "Epoch 187/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9857 - val_loss: 0.0592 - val_accuracy: 0.9773\n",
            "Epoch 188/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9840 - val_loss: 0.0593 - val_accuracy: 0.9773\n",
            "Epoch 189/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9848 - val_loss: 0.0593 - val_accuracy: 0.9760\n",
            "Epoch 190/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0526 - accuracy: 0.9853 - val_loss: 0.0594 - val_accuracy: 0.9735\n",
            "Epoch 191/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9840 - val_loss: 0.0594 - val_accuracy: 0.9747\n",
            "Epoch 192/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9844 - val_loss: 0.0594 - val_accuracy: 0.9747\n",
            "Epoch 193/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9840 - val_loss: 0.0595 - val_accuracy: 0.9735\n",
            "Epoch 194/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9857 - val_loss: 0.0594 - val_accuracy: 0.9760\n",
            "Epoch 195/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9844 - val_loss: 0.0594 - val_accuracy: 0.9735\n",
            "Epoch 196/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9853 - val_loss: 0.0594 - val_accuracy: 0.9747\n",
            "Epoch 197/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9853 - val_loss: 0.0594 - val_accuracy: 0.9747\n",
            "Epoch 198/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9848 - val_loss: 0.0593 - val_accuracy: 0.9747\n",
            "Epoch 199/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9853 - val_loss: 0.0591 - val_accuracy: 0.9747\n",
            "Epoch 200/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9844 - val_loss: 0.0592 - val_accuracy: 0.9735\n",
            "Epoch 201/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9848 - val_loss: 0.0595 - val_accuracy: 0.9747\n",
            "Epoch 202/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9857 - val_loss: 0.0592 - val_accuracy: 0.9747\n",
            "Epoch 203/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9848 - val_loss: 0.0589 - val_accuracy: 0.9760\n",
            "Epoch 204/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9853 - val_loss: 0.0590 - val_accuracy: 0.9735\n",
            "Epoch 205/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9853 - val_loss: 0.0590 - val_accuracy: 0.9760\n",
            "Epoch 206/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9848 - val_loss: 0.0589 - val_accuracy: 0.9747\n",
            "Epoch 207/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9844 - val_loss: 0.0588 - val_accuracy: 0.9760\n",
            "Epoch 208/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9853 - val_loss: 0.0586 - val_accuracy: 0.9760\n",
            "Epoch 209/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9848 - val_loss: 0.0587 - val_accuracy: 0.9760\n",
            "Epoch 210/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9861 - val_loss: 0.0585 - val_accuracy: 0.9760\n",
            "Epoch 211/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9853 - val_loss: 0.0584 - val_accuracy: 0.9760\n",
            "Epoch 212/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9857 - val_loss: 0.0585 - val_accuracy: 0.9760\n",
            "Epoch 213/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9844 - val_loss: 0.0586 - val_accuracy: 0.9760\n",
            "Epoch 214/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9853 - val_loss: 0.0584 - val_accuracy: 0.9773\n",
            "Epoch 215/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9853 - val_loss: 0.0583 - val_accuracy: 0.9760\n",
            "Epoch 216/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9844 - val_loss: 0.0582 - val_accuracy: 0.9760\n",
            "Epoch 217/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9844 - val_loss: 0.0584 - val_accuracy: 0.9760\n",
            "Epoch 218/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9853 - val_loss: 0.0583 - val_accuracy: 0.9760\n",
            "Epoch 219/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9848 - val_loss: 0.0586 - val_accuracy: 0.9747\n",
            "Epoch 220/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9861 - val_loss: 0.0581 - val_accuracy: 0.9760\n",
            "Epoch 221/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9853 - val_loss: 0.0581 - val_accuracy: 0.9760\n",
            "Epoch 222/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9853 - val_loss: 0.0582 - val_accuracy: 0.9760\n",
            "Epoch 223/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9853 - val_loss: 0.0581 - val_accuracy: 0.9785\n",
            "Epoch 224/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9853 - val_loss: 0.0580 - val_accuracy: 0.9773\n",
            "Epoch 225/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9857 - val_loss: 0.0579 - val_accuracy: 0.9760\n",
            "Epoch 226/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9848 - val_loss: 0.0578 - val_accuracy: 0.9773\n",
            "Epoch 227/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9853 - val_loss: 0.0578 - val_accuracy: 0.9773\n",
            "Epoch 228/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9840 - val_loss: 0.0577 - val_accuracy: 0.9773\n",
            "Epoch 229/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9857 - val_loss: 0.0579 - val_accuracy: 0.9773\n",
            "Epoch 230/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9853 - val_loss: 0.0577 - val_accuracy: 0.9773\n",
            "Epoch 231/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9857 - val_loss: 0.0576 - val_accuracy: 0.9785\n",
            "Epoch 232/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9848 - val_loss: 0.0576 - val_accuracy: 0.9798\n",
            "Epoch 233/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9857 - val_loss: 0.0575 - val_accuracy: 0.9773\n",
            "Epoch 234/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9848 - val_loss: 0.0576 - val_accuracy: 0.9785\n",
            "Epoch 235/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9865 - val_loss: 0.0574 - val_accuracy: 0.9773\n",
            "Epoch 236/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9861 - val_loss: 0.0574 - val_accuracy: 0.9773\n",
            "Epoch 237/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9861 - val_loss: 0.0575 - val_accuracy: 0.9760\n",
            "Epoch 238/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9848 - val_loss: 0.0574 - val_accuracy: 0.9773\n",
            "Epoch 239/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9848 - val_loss: 0.0574 - val_accuracy: 0.9773\n",
            "Epoch 240/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9857 - val_loss: 0.0594 - val_accuracy: 0.9773\n",
            "Epoch 241/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9853 - val_loss: 0.0577 - val_accuracy: 0.9773\n",
            "Epoch 242/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9853 - val_loss: 0.0573 - val_accuracy: 0.9760\n",
            "Epoch 243/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9848 - val_loss: 0.0572 - val_accuracy: 0.9773\n",
            "Epoch 244/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9857 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
            "Epoch 245/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9857 - val_loss: 0.0575 - val_accuracy: 0.9785\n",
            "Epoch 246/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0489 - accuracy: 0.9857 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
            "Epoch 247/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9861 - val_loss: 0.0570 - val_accuracy: 0.9785\n",
            "Epoch 248/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9857 - val_loss: 0.0572 - val_accuracy: 0.9760\n",
            "Epoch 249/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9853 - val_loss: 0.0571 - val_accuracy: 0.9773\n",
            "Epoch 250/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9844 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
            "Epoch 251/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9857 - val_loss: 0.0570 - val_accuracy: 0.9773\n",
            "Epoch 252/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9848 - val_loss: 0.0572 - val_accuracy: 0.9760\n",
            "Epoch 253/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9857 - val_loss: 0.0570 - val_accuracy: 0.9773\n",
            "Epoch 254/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9861 - val_loss: 0.0569 - val_accuracy: 0.9773\n",
            "Epoch 255/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9857 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
            "Epoch 256/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9857 - val_loss: 0.0570 - val_accuracy: 0.9773\n",
            "Epoch 257/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9857 - val_loss: 0.0570 - val_accuracy: 0.9760\n",
            "Epoch 258/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9853 - val_loss: 0.0570 - val_accuracy: 0.9773\n",
            "Epoch 259/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9861 - val_loss: 0.0571 - val_accuracy: 0.9773\n",
            "Epoch 260/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9857 - val_loss: 0.0569 - val_accuracy: 0.9785\n",
            "Epoch 261/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9853 - val_loss: 0.0572 - val_accuracy: 0.9773\n",
            "Epoch 262/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9857 - val_loss: 0.0572 - val_accuracy: 0.9773\n",
            "Epoch 263/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9861 - val_loss: 0.0572 - val_accuracy: 0.9773\n",
            "Epoch 264/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9857 - val_loss: 0.0571 - val_accuracy: 0.9785\n",
            "Epoch 265/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.9853 - val_loss: 0.0570 - val_accuracy: 0.9760\n",
            "Epoch 266/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9857 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
            "Epoch 267/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9857 - val_loss: 0.0570 - val_accuracy: 0.9773\n",
            "Epoch 268/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9848 - val_loss: 0.0570 - val_accuracy: 0.9773\n",
            "Epoch 269/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9853 - val_loss: 0.0570 - val_accuracy: 0.9760\n",
            "Epoch 270/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9857 - val_loss: 0.0571 - val_accuracy: 0.9760\n",
            "Epoch 271/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9865 - val_loss: 0.0573 - val_accuracy: 0.9760\n",
            "Epoch 272/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9861 - val_loss: 0.0575 - val_accuracy: 0.9760\n",
            "Epoch 273/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9861 - val_loss: 0.0567 - val_accuracy: 0.9785\n",
            "Epoch 274/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9857 - val_loss: 0.0568 - val_accuracy: 0.9773\n",
            "Epoch 275/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9857 - val_loss: 0.0569 - val_accuracy: 0.9773\n",
            "Epoch 276/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9853 - val_loss: 0.0570 - val_accuracy: 0.9773\n",
            "Epoch 277/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9853 - val_loss: 0.0568 - val_accuracy: 0.9773\n",
            "Epoch 278/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9865 - val_loss: 0.0569 - val_accuracy: 0.9773\n",
            "Epoch 279/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9857 - val_loss: 0.0570 - val_accuracy: 0.9773\n",
            "Epoch 280/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9857 - val_loss: 0.0573 - val_accuracy: 0.9785\n",
            "Epoch 281/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9865 - val_loss: 0.0572 - val_accuracy: 0.9773\n",
            "Epoch 282/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9857 - val_loss: 0.0572 - val_accuracy: 0.9773\n",
            "Epoch 283/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9857 - val_loss: 0.0577 - val_accuracy: 0.9773\n",
            "Epoch 284/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9857 - val_loss: 0.0571 - val_accuracy: 0.9773\n",
            "Epoch 285/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9853 - val_loss: 0.0572 - val_accuracy: 0.9773\n",
            "Epoch 286/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9857 - val_loss: 0.0573 - val_accuracy: 0.9798\n",
            "Epoch 287/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9848 - val_loss: 0.0572 - val_accuracy: 0.9773\n",
            "Epoch 288/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9853 - val_loss: 0.0573 - val_accuracy: 0.9760\n",
            "Epoch 289/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9857 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
            "Epoch 290/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9853 - val_loss: 0.0570 - val_accuracy: 0.9773\n",
            "Epoch 291/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9853 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
            "Epoch 292/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9857 - val_loss: 0.0572 - val_accuracy: 0.9773\n",
            "Epoch 293/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.0574 - val_accuracy: 0.9785\n",
            "Epoch 294/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9865 - val_loss: 0.0575 - val_accuracy: 0.9773\n",
            "Epoch 295/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9870 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
            "Epoch 296/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9865 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
            "Epoch 297/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9865 - val_loss: 0.0571 - val_accuracy: 0.9773\n",
            "Epoch 298/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 0.0573 - val_accuracy: 0.9773\n",
            "Epoch 299/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9853 - val_loss: 0.0575 - val_accuracy: 0.9760\n",
            "Epoch 300/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 0.0574 - val_accuracy: 0.9785\n",
            "Epoch 301/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9848 - val_loss: 0.0573 - val_accuracy: 0.9785\n",
            "Epoch 302/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0462 - accuracy: 0.9853 - val_loss: 0.0574 - val_accuracy: 0.9798\n",
            "Epoch 303/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9853 - val_loss: 0.0574 - val_accuracy: 0.9785\n",
            "Epoch 304/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9861 - val_loss: 0.0574 - val_accuracy: 0.9773\n",
            "Epoch 305/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9853 - val_loss: 0.0579 - val_accuracy: 0.9773\n",
            "Epoch 306/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9857 - val_loss: 0.0579 - val_accuracy: 0.9773\n",
            "Epoch 307/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9844 - val_loss: 0.0576 - val_accuracy: 0.9773\n",
            "Epoch 308/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.0575 - val_accuracy: 0.9798\n",
            "Epoch 309/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.0575 - val_accuracy: 0.9785\n",
            "Epoch 310/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9857 - val_loss: 0.0579 - val_accuracy: 0.9798\n",
            "Epoch 311/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9844 - val_loss: 0.0573 - val_accuracy: 0.9785\n",
            "Epoch 312/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9857 - val_loss: 0.0577 - val_accuracy: 0.9785\n",
            "Epoch 313/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9844 - val_loss: 0.0579 - val_accuracy: 0.9785\n",
            "Epoch 314/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9848 - val_loss: 0.0579 - val_accuracy: 0.9785\n",
            "Epoch 315/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9853 - val_loss: 0.0577 - val_accuracy: 0.9760\n",
            "Epoch 316/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 0.0578 - val_accuracy: 0.9785\n",
            "Epoch 317/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9857 - val_loss: 0.0578 - val_accuracy: 0.9785\n",
            "Epoch 318/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.0578 - val_accuracy: 0.9773\n",
            "Epoch 319/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9857 - val_loss: 0.0577 - val_accuracy: 0.9785\n",
            "Epoch 320/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9857 - val_loss: 0.0576 - val_accuracy: 0.9785\n",
            "Epoch 321/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9853 - val_loss: 0.0575 - val_accuracy: 0.9785\n",
            "Epoch 322/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0453 - accuracy: 0.9848 - val_loss: 0.0577 - val_accuracy: 0.9773\n",
            "Epoch 323/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9848 - val_loss: 0.0577 - val_accuracy: 0.9785\n",
            "Epoch 324/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9865 - val_loss: 0.0576 - val_accuracy: 0.9785\n",
            "Epoch 325/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9853 - val_loss: 0.0578 - val_accuracy: 0.9798\n",
            "Epoch 326/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9848 - val_loss: 0.0578 - val_accuracy: 0.9785\n",
            "Epoch 327/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9848 - val_loss: 0.0571 - val_accuracy: 0.9798\n",
            "Epoch 328/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9844 - val_loss: 0.0573 - val_accuracy: 0.9798\n",
            "Epoch 329/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9853 - val_loss: 0.0575 - val_accuracy: 0.9773\n",
            "Epoch 330/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9853 - val_loss: 0.0576 - val_accuracy: 0.9785\n",
            "Epoch 331/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9848 - val_loss: 0.0577 - val_accuracy: 0.9798\n",
            "Epoch 332/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.0578 - val_accuracy: 0.9773\n",
            "Epoch 333/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9857 - val_loss: 0.0578 - val_accuracy: 0.9785\n",
            "Epoch 334/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9840 - val_loss: 0.0581 - val_accuracy: 0.9773\n",
            "Epoch 335/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9861 - val_loss: 0.0616 - val_accuracy: 0.9760\n",
            "Epoch 336/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9857 - val_loss: 0.0580 - val_accuracy: 0.9773\n",
            "Epoch 337/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9853 - val_loss: 0.0580 - val_accuracy: 0.9773\n",
            "Epoch 338/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9857 - val_loss: 0.0581 - val_accuracy: 0.9773\n",
            "Epoch 339/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9857 - val_loss: 0.0579 - val_accuracy: 0.9773\n",
            "Epoch 340/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9848 - val_loss: 0.0578 - val_accuracy: 0.9773\n",
            "Epoch 341/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9857 - val_loss: 0.0578 - val_accuracy: 0.9785\n",
            "Epoch 342/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.0578 - val_accuracy: 0.9785\n",
            "Epoch 343/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.0579 - val_accuracy: 0.9785\n",
            "Epoch 344/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.0580 - val_accuracy: 0.9798\n",
            "Epoch 345/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9853 - val_loss: 0.0578 - val_accuracy: 0.9811\n",
            "Epoch 346/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 0.0579 - val_accuracy: 0.9785\n",
            "Epoch 347/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9857 - val_loss: 0.0573 - val_accuracy: 0.9785\n",
            "Epoch 348/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.0575 - val_accuracy: 0.9798\n",
            "Epoch 349/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.0574 - val_accuracy: 0.9773\n",
            "Epoch 350/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9861 - val_loss: 0.0575 - val_accuracy: 0.9798\n",
            "Epoch 351/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9853 - val_loss: 0.0578 - val_accuracy: 0.9773\n",
            "Epoch 352/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9848 - val_loss: 0.0581 - val_accuracy: 0.9785\n",
            "Epoch 353/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9853 - val_loss: 0.0577 - val_accuracy: 0.9811\n",
            "Epoch 354/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9848 - val_loss: 0.0577 - val_accuracy: 0.9798\n",
            "Epoch 355/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9861 - val_loss: 0.0580 - val_accuracy: 0.9785\n",
            "Epoch 356/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9857 - val_loss: 0.0581 - val_accuracy: 0.9785\n",
            "Epoch 357/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9857 - val_loss: 0.0580 - val_accuracy: 0.9760\n",
            "Epoch 358/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9848 - val_loss: 0.0579 - val_accuracy: 0.9798\n",
            "Epoch 359/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9853 - val_loss: 0.0580 - val_accuracy: 0.9773\n",
            "Epoch 360/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9848 - val_loss: 0.0579 - val_accuracy: 0.9785\n",
            "Epoch 361/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9853 - val_loss: 0.0579 - val_accuracy: 0.9785\n",
            "Epoch 362/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 0.0581 - val_accuracy: 0.9785\n",
            "Epoch 363/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9853 - val_loss: 0.0580 - val_accuracy: 0.9798\n",
            "Epoch 364/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9861 - val_loss: 0.0579 - val_accuracy: 0.9785\n",
            "Epoch 365/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9865 - val_loss: 0.0580 - val_accuracy: 0.9773\n",
            "Epoch 366/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9857 - val_loss: 0.0580 - val_accuracy: 0.9785\n",
            "Epoch 367/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9857 - val_loss: 0.0584 - val_accuracy: 0.9798\n",
            "Epoch 368/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 0.0579 - val_accuracy: 0.9798\n",
            "Epoch 369/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9861 - val_loss: 0.0580 - val_accuracy: 0.9773\n",
            "Epoch 370/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9853 - val_loss: 0.0579 - val_accuracy: 0.9811\n",
            "Epoch 371/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9865 - val_loss: 0.0577 - val_accuracy: 0.9811\n",
            "Epoch 372/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0433 - accuracy: 0.9853 - val_loss: 0.0578 - val_accuracy: 0.9798\n",
            "Epoch 373/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9857 - val_loss: 0.0580 - val_accuracy: 0.9798\n",
            "Epoch 374/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9861 - val_loss: 0.0581 - val_accuracy: 0.9773\n",
            "Epoch 375/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9861 - val_loss: 0.0576 - val_accuracy: 0.9811\n",
            "Epoch 376/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9857 - val_loss: 0.0578 - val_accuracy: 0.9760\n",
            "Epoch 377/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.0578 - val_accuracy: 0.9760\n",
            "Epoch 378/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9857 - val_loss: 0.0613 - val_accuracy: 0.9747\n",
            "Epoch 379/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9865 - val_loss: 0.0586 - val_accuracy: 0.9760\n",
            "Epoch 380/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.0580 - val_accuracy: 0.9773\n",
            "Epoch 381/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9853 - val_loss: 0.0578 - val_accuracy: 0.9798\n",
            "Epoch 382/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.0577 - val_accuracy: 0.9811\n",
            "Epoch 383/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9861 - val_loss: 0.0580 - val_accuracy: 0.9773\n",
            "Epoch 384/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 0.0580 - val_accuracy: 0.9798\n",
            "Epoch 385/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9861 - val_loss: 0.0578 - val_accuracy: 0.9811\n",
            "Epoch 386/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0428 - accuracy: 0.9861 - val_loss: 0.0578 - val_accuracy: 0.9785\n",
            "Epoch 387/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.0578 - val_accuracy: 0.9785\n",
            "Epoch 388/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.9853 - val_loss: 0.0578 - val_accuracy: 0.9798\n",
            "Epoch 389/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9874 - val_loss: 0.0586 - val_accuracy: 0.9773\n",
            "Epoch 390/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.9857 - val_loss: 0.0583 - val_accuracy: 0.9773\n",
            "Epoch 391/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9865 - val_loss: 0.0586 - val_accuracy: 0.9773\n",
            "Epoch 392/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9857 - val_loss: 0.0579 - val_accuracy: 0.9785\n",
            "Epoch 393/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9870 - val_loss: 0.0580 - val_accuracy: 0.9811\n",
            "Epoch 394/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9857 - val_loss: 0.0580 - val_accuracy: 0.9811\n",
            "Epoch 395/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9857 - val_loss: 0.0580 - val_accuracy: 0.9811\n",
            "Epoch 396/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.0581 - val_accuracy: 0.9798\n",
            "Epoch 397/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9874 - val_loss: 0.0582 - val_accuracy: 0.9798\n",
            "Epoch 398/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.0581 - val_accuracy: 0.9798\n",
            "Epoch 399/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9865 - val_loss: 0.0582 - val_accuracy: 0.9798\n",
            "Epoch 400/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9853 - val_loss: 0.0578 - val_accuracy: 0.9773\n",
            "Epoch 401/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0579 - val_accuracy: 0.9798\n",
            "Epoch 402/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9865 - val_loss: 0.0578 - val_accuracy: 0.9785\n",
            "Epoch 403/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0582 - val_accuracy: 0.9773\n",
            "Epoch 404/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9857 - val_loss: 0.0579 - val_accuracy: 0.9773\n",
            "Epoch 405/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0580 - val_accuracy: 0.9798\n",
            "Epoch 406/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9861 - val_loss: 0.0581 - val_accuracy: 0.9798\n",
            "Epoch 407/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9870 - val_loss: 0.0580 - val_accuracy: 0.9811\n",
            "Epoch 408/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9857 - val_loss: 0.0580 - val_accuracy: 0.9773\n",
            "Epoch 409/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 0.0582 - val_accuracy: 0.9798\n",
            "Epoch 410/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9857 - val_loss: 0.0577 - val_accuracy: 0.9811\n",
            "Epoch 411/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9861 - val_loss: 0.0579 - val_accuracy: 0.9760\n",
            "Epoch 412/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9861 - val_loss: 0.0579 - val_accuracy: 0.9773\n",
            "Epoch 413/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.0583 - val_accuracy: 0.9773\n",
            "Epoch 414/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9865 - val_loss: 0.0583 - val_accuracy: 0.9760\n",
            "Epoch 415/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9870 - val_loss: 0.0644 - val_accuracy: 0.9760\n",
            "Epoch 416/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9857 - val_loss: 0.0586 - val_accuracy: 0.9760\n",
            "Epoch 417/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 0.0584 - val_accuracy: 0.9785\n",
            "Epoch 418/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9865 - val_loss: 0.0581 - val_accuracy: 0.9798\n",
            "Epoch 419/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9874 - val_loss: 0.0583 - val_accuracy: 0.9760\n",
            "Epoch 420/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9870 - val_loss: 0.0585 - val_accuracy: 0.9773\n",
            "Epoch 421/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9874 - val_loss: 0.0582 - val_accuracy: 0.9811\n",
            "Epoch 422/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.0583 - val_accuracy: 0.9798\n",
            "Epoch 423/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.0584 - val_accuracy: 0.9773\n",
            "Epoch 424/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.0580 - val_accuracy: 0.9785\n",
            "Epoch 425/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9861 - val_loss: 0.0586 - val_accuracy: 0.9785\n",
            "Epoch 426/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9865 - val_loss: 0.0583 - val_accuracy: 0.9773\n",
            "Epoch 427/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9865 - val_loss: 0.0581 - val_accuracy: 0.9760\n",
            "Epoch 428/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9861 - val_loss: 0.0579 - val_accuracy: 0.9823\n",
            "Epoch 429/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.0581 - val_accuracy: 0.9823\n",
            "Epoch 430/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9870 - val_loss: 0.0581 - val_accuracy: 0.9823\n",
            "Epoch 431/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 0.0577 - val_accuracy: 0.9811\n",
            "Epoch 432/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.0579 - val_accuracy: 0.9811\n",
            "Epoch 433/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.0581 - val_accuracy: 0.9811\n",
            "Epoch 434/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9861 - val_loss: 0.0580 - val_accuracy: 0.9773\n",
            "Epoch 435/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9870 - val_loss: 0.0579 - val_accuracy: 0.9811\n",
            "Epoch 436/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 0.0580 - val_accuracy: 0.9823\n",
            "Epoch 437/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9865 - val_loss: 0.0583 - val_accuracy: 0.9811\n",
            "Epoch 438/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 0.0580 - val_accuracy: 0.9785\n",
            "Epoch 439/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9870 - val_loss: 0.0583 - val_accuracy: 0.9823\n",
            "Epoch 440/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9874 - val_loss: 0.0583 - val_accuracy: 0.9785\n",
            "Epoch 441/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 0.0585 - val_accuracy: 0.9773\n",
            "Epoch 442/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9861 - val_loss: 0.0586 - val_accuracy: 0.9773\n",
            "Epoch 443/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 0.0584 - val_accuracy: 0.9760\n",
            "Epoch 444/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9870 - val_loss: 0.0582 - val_accuracy: 0.9823\n",
            "Epoch 445/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9874 - val_loss: 0.0582 - val_accuracy: 0.9811\n",
            "Epoch 446/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9878 - val_loss: 0.0582 - val_accuracy: 0.9811\n",
            "Epoch 447/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0583 - val_accuracy: 0.9773\n",
            "Epoch 448/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9878 - val_loss: 0.0584 - val_accuracy: 0.9811\n",
            "Epoch 449/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.0583 - val_accuracy: 0.9811\n",
            "Epoch 450/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.0582 - val_accuracy: 0.9773\n",
            "Epoch 451/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9865 - val_loss: 0.0584 - val_accuracy: 0.9773\n",
            "Epoch 452/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.0582 - val_accuracy: 0.9773\n",
            "Epoch 453/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.0585 - val_accuracy: 0.9773\n",
            "Epoch 454/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.0582 - val_accuracy: 0.9811\n",
            "Epoch 455/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.0583 - val_accuracy: 0.9811\n",
            "Epoch 456/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.0586 - val_accuracy: 0.9798\n",
            "Epoch 457/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9865 - val_loss: 0.0584 - val_accuracy: 0.9773\n",
            "Epoch 458/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 0.0582 - val_accuracy: 0.9785\n",
            "Epoch 459/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.0581 - val_accuracy: 0.9785\n",
            "Epoch 460/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.0583 - val_accuracy: 0.9811\n",
            "Epoch 461/800\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0581 - val_accuracy: 0.9773\n",
            "Epoch 462/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.0583 - val_accuracy: 0.9798\n",
            "Epoch 463/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0405 - accuracy: 0.9865 - val_loss: 0.0583 - val_accuracy: 0.9773\n",
            "Epoch 464/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.0580 - val_accuracy: 0.9798\n",
            "Epoch 465/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0582 - val_accuracy: 0.9811\n",
            "Epoch 466/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9870 - val_loss: 0.0586 - val_accuracy: 0.9823\n",
            "Epoch 467/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.0587 - val_accuracy: 0.9798\n",
            "Epoch 468/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9865 - val_loss: 0.0591 - val_accuracy: 0.9773\n",
            "Epoch 469/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.0585 - val_accuracy: 0.9811\n",
            "Epoch 470/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9878 - val_loss: 0.0585 - val_accuracy: 0.9773\n",
            "Epoch 471/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0584 - val_accuracy: 0.9773\n",
            "Epoch 472/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9865 - val_loss: 0.0588 - val_accuracy: 0.9811\n",
            "Epoch 473/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.0588 - val_accuracy: 0.9811\n",
            "Epoch 474/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9874 - val_loss: 0.0585 - val_accuracy: 0.9823\n",
            "Epoch 475/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 0.0585 - val_accuracy: 0.9811\n",
            "Epoch 476/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9861 - val_loss: 0.0590 - val_accuracy: 0.9811\n",
            "Epoch 477/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0584 - val_accuracy: 0.9811\n",
            "Epoch 478/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.0592 - val_accuracy: 0.9798\n",
            "Epoch 479/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0591 - val_accuracy: 0.9785\n",
            "Epoch 480/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.0585 - val_accuracy: 0.9785\n",
            "Epoch 481/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9870 - val_loss: 0.0589 - val_accuracy: 0.9811\n",
            "Epoch 482/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9870 - val_loss: 0.0587 - val_accuracy: 0.9811\n",
            "Epoch 483/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.0588 - val_accuracy: 0.9785\n",
            "Epoch 484/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9865 - val_loss: 0.0591 - val_accuracy: 0.9798\n",
            "Epoch 485/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 0.0589 - val_accuracy: 0.9798\n",
            "Epoch 486/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9870 - val_loss: 0.0591 - val_accuracy: 0.9811\n",
            "Epoch 487/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9861 - val_loss: 0.0589 - val_accuracy: 0.9811\n",
            "Epoch 488/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.0585 - val_accuracy: 0.9785\n",
            "Epoch 489/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.0586 - val_accuracy: 0.9785\n",
            "Epoch 490/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9865 - val_loss: 0.0591 - val_accuracy: 0.9798\n",
            "Epoch 491/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.0586 - val_accuracy: 0.9785\n",
            "Epoch 492/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 0.0589 - val_accuracy: 0.9823\n",
            "Epoch 493/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.0587 - val_accuracy: 0.9811\n",
            "Epoch 494/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0593 - val_accuracy: 0.9823\n",
            "Epoch 495/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9878 - val_loss: 0.0584 - val_accuracy: 0.9811\n",
            "Epoch 496/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 0.0586 - val_accuracy: 0.9785\n",
            "Epoch 497/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 0.0583 - val_accuracy: 0.9798\n",
            "Epoch 498/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 0.0580 - val_accuracy: 0.9823\n",
            "Epoch 499/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9865 - val_loss: 0.0584 - val_accuracy: 0.9798\n",
            "Epoch 500/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9865 - val_loss: 0.0589 - val_accuracy: 0.9785\n",
            "Epoch 501/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 0.0590 - val_accuracy: 0.9811\n",
            "Epoch 502/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0585 - val_accuracy: 0.9811\n",
            "Epoch 503/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9861 - val_loss: 0.0589 - val_accuracy: 0.9811\n",
            "Epoch 504/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 0.0591 - val_accuracy: 0.9798\n",
            "Epoch 505/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9874 - val_loss: 0.0591 - val_accuracy: 0.9798\n",
            "Epoch 506/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9870 - val_loss: 0.0591 - val_accuracy: 0.9785\n",
            "Epoch 507/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9870 - val_loss: 0.0597 - val_accuracy: 0.9773\n",
            "Epoch 508/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 0.0593 - val_accuracy: 0.9773\n",
            "Epoch 509/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 0.0594 - val_accuracy: 0.9785\n",
            "Epoch 510/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 0.0594 - val_accuracy: 0.9798\n",
            "Epoch 511/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 0.0590 - val_accuracy: 0.9798\n",
            "Epoch 512/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 0.0592 - val_accuracy: 0.9811\n",
            "Epoch 513/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9870 - val_loss: 0.0596 - val_accuracy: 0.9773\n",
            "Epoch 514/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0598 - val_accuracy: 0.9798\n",
            "Epoch 515/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9865 - val_loss: 0.0596 - val_accuracy: 0.9785\n",
            "Epoch 516/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0595 - val_accuracy: 0.9811\n",
            "Epoch 517/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9870 - val_loss: 0.0587 - val_accuracy: 0.9798\n",
            "Epoch 518/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 0.0592 - val_accuracy: 0.9811\n",
            "Epoch 519/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9870 - val_loss: 0.0591 - val_accuracy: 0.9798\n",
            "Epoch 520/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9870 - val_loss: 0.0592 - val_accuracy: 0.9811\n",
            "Epoch 521/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 0.0591 - val_accuracy: 0.9811\n",
            "Epoch 522/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 0.0593 - val_accuracy: 0.9798\n",
            "Epoch 523/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.0592 - val_accuracy: 0.9811\n",
            "Epoch 524/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9874 - val_loss: 0.0600 - val_accuracy: 0.9811\n",
            "Epoch 525/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9870 - val_loss: 0.0600 - val_accuracy: 0.9811\n",
            "Epoch 526/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.0597 - val_accuracy: 0.9785\n",
            "Epoch 527/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 0.0595 - val_accuracy: 0.9785\n",
            "Epoch 528/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 0.0596 - val_accuracy: 0.9811\n",
            "Epoch 529/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0594 - val_accuracy: 0.9811\n",
            "Epoch 530/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 0.0592 - val_accuracy: 0.9785\n",
            "Epoch 531/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9870 - val_loss: 0.0594 - val_accuracy: 0.9785\n",
            "Epoch 532/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.0598 - val_accuracy: 0.9798\n",
            "Epoch 533/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.0600 - val_accuracy: 0.9798\n",
            "Epoch 534/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9865 - val_loss: 0.0594 - val_accuracy: 0.9785\n",
            "Epoch 535/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0596 - val_accuracy: 0.9811\n",
            "Epoch 536/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9870 - val_loss: 0.0593 - val_accuracy: 0.9811\n",
            "Epoch 537/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 0.0593 - val_accuracy: 0.9811\n",
            "Epoch 538/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 0.0592 - val_accuracy: 0.9811\n",
            "Epoch 539/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 0.0589 - val_accuracy: 0.9785\n",
            "Epoch 540/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.0592 - val_accuracy: 0.9785\n",
            "Epoch 541/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9878 - val_loss: 0.0595 - val_accuracy: 0.9811\n",
            "Epoch 542/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 0.0596 - val_accuracy: 0.9798\n",
            "Epoch 543/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9865 - val_loss: 0.0589 - val_accuracy: 0.9811\n",
            "Epoch 544/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9870 - val_loss: 0.0592 - val_accuracy: 0.9811\n",
            "Epoch 545/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.0594 - val_accuracy: 0.9785\n",
            "Epoch 546/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 0.0590 - val_accuracy: 0.9811\n",
            "Epoch 547/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9874 - val_loss: 0.0594 - val_accuracy: 0.9773\n",
            "Epoch 548/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.0592 - val_accuracy: 0.9811\n",
            "Epoch 549/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9870 - val_loss: 0.0595 - val_accuracy: 0.9811\n",
            "Epoch 550/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9870 - val_loss: 0.0597 - val_accuracy: 0.9798\n",
            "Epoch 551/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9861 - val_loss: 0.0594 - val_accuracy: 0.9798\n",
            "Epoch 552/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9874 - val_loss: 0.0592 - val_accuracy: 0.9811\n",
            "Epoch 553/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9874 - val_loss: 0.0592 - val_accuracy: 0.9785\n",
            "Epoch 554/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9874 - val_loss: 0.0594 - val_accuracy: 0.9785\n",
            "Epoch 555/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9874 - val_loss: 0.0599 - val_accuracy: 0.9785\n",
            "Epoch 556/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9878 - val_loss: 0.0595 - val_accuracy: 0.9785\n",
            "Epoch 557/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 0.0598 - val_accuracy: 0.9811\n",
            "Epoch 558/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9870 - val_loss: 0.0596 - val_accuracy: 0.9798\n",
            "Epoch 559/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9870 - val_loss: 0.0594 - val_accuracy: 0.9811\n",
            "Epoch 560/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9878 - val_loss: 0.0592 - val_accuracy: 0.9798\n",
            "Epoch 561/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9874 - val_loss: 0.0599 - val_accuracy: 0.9811\n",
            "Epoch 562/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9874 - val_loss: 0.0597 - val_accuracy: 0.9785\n",
            "Epoch 563/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 0.0597 - val_accuracy: 0.9811\n",
            "Epoch 564/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9874 - val_loss: 0.0597 - val_accuracy: 0.9811\n",
            "Epoch 565/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 0.0599 - val_accuracy: 0.9798\n",
            "Epoch 566/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9874 - val_loss: 0.0599 - val_accuracy: 0.9773\n",
            "Epoch 567/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9870 - val_loss: 0.0591 - val_accuracy: 0.9811\n",
            "Epoch 568/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9874 - val_loss: 0.0589 - val_accuracy: 0.9811\n",
            "Epoch 569/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9865 - val_loss: 0.0596 - val_accuracy: 0.9811\n",
            "Epoch 570/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9878 - val_loss: 0.0596 - val_accuracy: 0.9773\n",
            "Epoch 571/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9878 - val_loss: 0.0598 - val_accuracy: 0.9798\n",
            "Epoch 572/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9874 - val_loss: 0.0594 - val_accuracy: 0.9811\n",
            "Epoch 573/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9874 - val_loss: 0.0601 - val_accuracy: 0.9798\n",
            "Epoch 574/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 0.0601 - val_accuracy: 0.9811\n",
            "Epoch 575/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.0601 - val_accuracy: 0.9798\n",
            "Epoch 576/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 0.0596 - val_accuracy: 0.9811\n",
            "Epoch 577/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9870 - val_loss: 0.0602 - val_accuracy: 0.9773\n",
            "Epoch 578/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.0597 - val_accuracy: 0.9798\n",
            "Epoch 579/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9878 - val_loss: 0.0594 - val_accuracy: 0.9760\n",
            "Epoch 580/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9874 - val_loss: 0.0597 - val_accuracy: 0.9811\n",
            "Epoch 581/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9874 - val_loss: 0.0597 - val_accuracy: 0.9811\n",
            "Epoch 582/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9874 - val_loss: 0.0595 - val_accuracy: 0.9773\n",
            "Epoch 583/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.0599 - val_accuracy: 0.9798\n",
            "Epoch 584/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9878 - val_loss: 0.0593 - val_accuracy: 0.9811\n",
            "Epoch 585/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 0.0598 - val_accuracy: 0.9811\n",
            "Epoch 586/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9874 - val_loss: 0.0596 - val_accuracy: 0.9811\n",
            "Epoch 587/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 0.0597 - val_accuracy: 0.9811\n",
            "Epoch 588/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9874 - val_loss: 0.0599 - val_accuracy: 0.9811\n",
            "Epoch 589/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9874 - val_loss: 0.0596 - val_accuracy: 0.9773\n",
            "Epoch 590/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.0598 - val_accuracy: 0.9773\n",
            "Epoch 591/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9878 - val_loss: 0.0597 - val_accuracy: 0.9798\n",
            "Epoch 592/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9878 - val_loss: 0.0604 - val_accuracy: 0.9760\n",
            "Epoch 593/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9882 - val_loss: 0.0603 - val_accuracy: 0.9798\n",
            "Epoch 594/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9874 - val_loss: 0.0604 - val_accuracy: 0.9798\n",
            "Epoch 595/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9878 - val_loss: 0.0599 - val_accuracy: 0.9811\n",
            "Epoch 596/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9878 - val_loss: 0.0603 - val_accuracy: 0.9785\n",
            "Epoch 597/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9878 - val_loss: 0.0601 - val_accuracy: 0.9811\n",
            "Epoch 598/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9878 - val_loss: 0.0604 - val_accuracy: 0.9798\n",
            "Epoch 599/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9882 - val_loss: 0.0606 - val_accuracy: 0.9798\n",
            "Epoch 600/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.0606 - val_accuracy: 0.9798\n",
            "Epoch 601/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9874 - val_loss: 0.0604 - val_accuracy: 0.9798\n",
            "Epoch 602/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9886 - val_loss: 0.0604 - val_accuracy: 0.9785\n",
            "Epoch 603/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9886 - val_loss: 0.0603 - val_accuracy: 0.9773\n",
            "Epoch 604/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9882 - val_loss: 0.0605 - val_accuracy: 0.9811\n",
            "Epoch 605/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9870 - val_loss: 0.0601 - val_accuracy: 0.9798\n",
            "Epoch 606/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9878 - val_loss: 0.0602 - val_accuracy: 0.9811\n",
            "Epoch 607/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9874 - val_loss: 0.0610 - val_accuracy: 0.9798\n",
            "Epoch 608/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9870 - val_loss: 0.0609 - val_accuracy: 0.9798\n",
            "Epoch 609/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.0606 - val_accuracy: 0.9798\n",
            "Epoch 610/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9870 - val_loss: 0.0606 - val_accuracy: 0.9811\n",
            "Epoch 611/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9874 - val_loss: 0.0607 - val_accuracy: 0.9811\n",
            "Epoch 612/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9870 - val_loss: 0.0602 - val_accuracy: 0.9811\n",
            "Epoch 613/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 0.9874 - val_loss: 0.0638 - val_accuracy: 0.9747\n",
            "Epoch 614/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.0610 - val_accuracy: 0.9811\n",
            "Epoch 615/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9870 - val_loss: 0.0614 - val_accuracy: 0.9811\n",
            "Epoch 616/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9870 - val_loss: 0.0611 - val_accuracy: 0.9760\n",
            "Epoch 617/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.0608 - val_accuracy: 0.9811\n",
            "Epoch 618/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9874 - val_loss: 0.0610 - val_accuracy: 0.9798\n",
            "Epoch 619/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9878 - val_loss: 0.0608 - val_accuracy: 0.9811\n",
            "Epoch 620/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9874 - val_loss: 0.0608 - val_accuracy: 0.9798\n",
            "Epoch 621/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.0614 - val_accuracy: 0.9785\n",
            "Epoch 622/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9870 - val_loss: 0.0607 - val_accuracy: 0.9811\n",
            "Epoch 623/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9891 - val_loss: 0.0608 - val_accuracy: 0.9811\n",
            "Epoch 624/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9878 - val_loss: 0.0611 - val_accuracy: 0.9785\n",
            "Epoch 625/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.9870 - val_loss: 0.0608 - val_accuracy: 0.9811\n",
            "Epoch 626/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9865 - val_loss: 0.0622 - val_accuracy: 0.9811\n",
            "Epoch 627/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.0600 - val_accuracy: 0.9811\n",
            "Epoch 628/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9865 - val_loss: 0.0606 - val_accuracy: 0.9811\n",
            "Epoch 629/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9870 - val_loss: 0.0609 - val_accuracy: 0.9811\n",
            "Epoch 630/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.0612 - val_accuracy: 0.9811\n",
            "Epoch 631/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.0609 - val_accuracy: 0.9811\n",
            "Epoch 632/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.0611 - val_accuracy: 0.9811\n",
            "Epoch 633/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9870 - val_loss: 0.0615 - val_accuracy: 0.9811\n",
            "Epoch 634/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 0.0614 - val_accuracy: 0.9811\n",
            "Epoch 635/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.9874 - val_loss: 0.0611 - val_accuracy: 0.9811\n",
            "Epoch 636/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9874 - val_loss: 0.0612 - val_accuracy: 0.9811\n",
            "Epoch 637/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.9874 - val_loss: 0.0604 - val_accuracy: 0.9798\n",
            "Epoch 638/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9870 - val_loss: 0.0626 - val_accuracy: 0.9798\n",
            "Epoch 639/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9878 - val_loss: 0.0616 - val_accuracy: 0.9811\n",
            "Epoch 640/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9874 - val_loss: 0.0618 - val_accuracy: 0.9798\n",
            "Epoch 641/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.0626 - val_accuracy: 0.9773\n",
            "Epoch 642/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9882 - val_loss: 0.0616 - val_accuracy: 0.9811\n",
            "Epoch 643/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9891 - val_loss: 0.0613 - val_accuracy: 0.9773\n",
            "Epoch 644/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9874 - val_loss: 0.0618 - val_accuracy: 0.9811\n",
            "Epoch 645/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9891 - val_loss: 0.0614 - val_accuracy: 0.9798\n",
            "Epoch 646/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9878 - val_loss: 0.0611 - val_accuracy: 0.9785\n",
            "Epoch 647/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9874 - val_loss: 0.0612 - val_accuracy: 0.9798\n",
            "Epoch 648/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9895 - val_loss: 0.0611 - val_accuracy: 0.9811\n",
            "Epoch 649/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 0.0612 - val_accuracy: 0.9811\n",
            "Epoch 650/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9882 - val_loss: 0.0613 - val_accuracy: 0.9811\n",
            "Epoch 651/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 0.0612 - val_accuracy: 0.9811\n",
            "Epoch 652/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9882 - val_loss: 0.0618 - val_accuracy: 0.9785\n",
            "Epoch 653/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9886 - val_loss: 0.0618 - val_accuracy: 0.9798\n",
            "Epoch 654/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9886 - val_loss: 0.0617 - val_accuracy: 0.9785\n",
            "Epoch 655/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9886 - val_loss: 0.0615 - val_accuracy: 0.9811\n",
            "Epoch 656/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 0.0616 - val_accuracy: 0.9811\n",
            "Epoch 657/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 0.0614 - val_accuracy: 0.9773\n",
            "Epoch 658/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9891 - val_loss: 0.0613 - val_accuracy: 0.9811\n",
            "Epoch 659/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9886 - val_loss: 0.0615 - val_accuracy: 0.9811\n",
            "Epoch 660/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.0617 - val_accuracy: 0.9811\n",
            "Epoch 661/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9886 - val_loss: 0.0616 - val_accuracy: 0.9811\n",
            "Epoch 662/800\n",
            "75/75 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9886 - val_loss: 0.0618 - val_accuracy: 0.9811\n",
            "Epoch 663/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9886 - val_loss: 0.0618 - val_accuracy: 0.9811\n",
            "Epoch 664/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 0.0631 - val_accuracy: 0.9760\n",
            "Epoch 665/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9882 - val_loss: 0.0622 - val_accuracy: 0.9811\n",
            "Epoch 666/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9886 - val_loss: 0.0616 - val_accuracy: 0.9811\n",
            "Epoch 667/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 0.0618 - val_accuracy: 0.9811\n",
            "Epoch 668/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9878 - val_loss: 0.0622 - val_accuracy: 0.9785\n",
            "Epoch 669/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 0.0625 - val_accuracy: 0.9785\n",
            "Epoch 670/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.0619 - val_accuracy: 0.9811\n",
            "Epoch 671/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9874 - val_loss: 0.0624 - val_accuracy: 0.9785\n",
            "Epoch 672/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 0.0623 - val_accuracy: 0.9811\n",
            "Epoch 673/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.0617 - val_accuracy: 0.9811\n",
            "Epoch 674/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 0.0614 - val_accuracy: 0.9811\n",
            "Epoch 675/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.0622 - val_accuracy: 0.9785\n",
            "Epoch 676/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9882 - val_loss: 0.0619 - val_accuracy: 0.9811\n",
            "Epoch 677/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9886 - val_loss: 0.0623 - val_accuracy: 0.9811\n",
            "Epoch 678/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9882 - val_loss: 0.0623 - val_accuracy: 0.9811\n",
            "Epoch 679/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9882 - val_loss: 0.0617 - val_accuracy: 0.9811\n",
            "Epoch 680/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.0620 - val_accuracy: 0.9811\n",
            "Epoch 681/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9886 - val_loss: 0.0629 - val_accuracy: 0.9798\n",
            "Epoch 682/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9874 - val_loss: 0.0625 - val_accuracy: 0.9811\n",
            "Epoch 683/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9886 - val_loss: 0.0629 - val_accuracy: 0.9785\n",
            "Epoch 684/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9882 - val_loss: 0.0627 - val_accuracy: 0.9785\n",
            "Epoch 685/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9895 - val_loss: 0.0622 - val_accuracy: 0.9811\n",
            "Epoch 686/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9886 - val_loss: 0.0624 - val_accuracy: 0.9811\n",
            "Epoch 687/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.0626 - val_accuracy: 0.9798\n",
            "Epoch 688/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9882 - val_loss: 0.0626 - val_accuracy: 0.9785\n",
            "Epoch 689/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9878 - val_loss: 0.0633 - val_accuracy: 0.9785\n",
            "Epoch 690/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9886 - val_loss: 0.0630 - val_accuracy: 0.9785\n",
            "Epoch 691/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.0629 - val_accuracy: 0.9811\n",
            "Epoch 692/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9886 - val_loss: 0.0623 - val_accuracy: 0.9811\n",
            "Epoch 693/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9878 - val_loss: 0.0626 - val_accuracy: 0.9798\n",
            "Epoch 694/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.0622 - val_accuracy: 0.9811\n",
            "Epoch 695/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.0627 - val_accuracy: 0.9811\n",
            "Epoch 696/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9878 - val_loss: 0.0641 - val_accuracy: 0.9785\n",
            "Epoch 697/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9891 - val_loss: 0.0634 - val_accuracy: 0.9798\n",
            "Epoch 698/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.0632 - val_accuracy: 0.9773\n",
            "Epoch 699/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 0.9878 - val_loss: 0.0633 - val_accuracy: 0.9785\n",
            "Epoch 700/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.0630 - val_accuracy: 0.9798\n",
            "Epoch 701/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.0629 - val_accuracy: 0.9798\n",
            "Epoch 702/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9878 - val_loss: 0.0625 - val_accuracy: 0.9811\n",
            "Epoch 703/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9886 - val_loss: 0.0621 - val_accuracy: 0.9798\n",
            "Epoch 704/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 0.9891 - val_loss: 0.0629 - val_accuracy: 0.9773\n",
            "Epoch 705/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9882 - val_loss: 0.0633 - val_accuracy: 0.9798\n",
            "Epoch 706/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9886 - val_loss: 0.0625 - val_accuracy: 0.9811\n",
            "Epoch 707/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 0.9874 - val_loss: 0.0629 - val_accuracy: 0.9811\n",
            "Epoch 708/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.0630 - val_accuracy: 0.9798\n",
            "Epoch 709/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9878 - val_loss: 0.0631 - val_accuracy: 0.9811\n",
            "Epoch 710/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.0633 - val_accuracy: 0.9811\n",
            "Epoch 711/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9886 - val_loss: 0.0632 - val_accuracy: 0.9785\n",
            "Epoch 712/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9895 - val_loss: 0.0635 - val_accuracy: 0.9823\n",
            "Epoch 713/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9882 - val_loss: 0.0631 - val_accuracy: 0.9811\n",
            "Epoch 714/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9878 - val_loss: 0.0635 - val_accuracy: 0.9798\n",
            "Epoch 715/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9878 - val_loss: 0.0640 - val_accuracy: 0.9785\n",
            "Epoch 716/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9878 - val_loss: 0.0632 - val_accuracy: 0.9811\n",
            "Epoch 717/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.0635 - val_accuracy: 0.9798\n",
            "Epoch 718/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 0.9891 - val_loss: 0.0634 - val_accuracy: 0.9798\n",
            "Epoch 719/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9878 - val_loss: 0.0638 - val_accuracy: 0.9811\n",
            "Epoch 720/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9886 - val_loss: 0.0645 - val_accuracy: 0.9785\n",
            "Epoch 721/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.0635 - val_accuracy: 0.9798\n",
            "Epoch 722/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9886 - val_loss: 0.0634 - val_accuracy: 0.9798\n",
            "Epoch 723/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9882 - val_loss: 0.0641 - val_accuracy: 0.9798\n",
            "Epoch 724/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9886 - val_loss: 0.0641 - val_accuracy: 0.9811\n",
            "Epoch 725/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9886 - val_loss: 0.0641 - val_accuracy: 0.9823\n",
            "Epoch 726/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9895 - val_loss: 0.0635 - val_accuracy: 0.9811\n",
            "Epoch 727/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 0.0642 - val_accuracy: 0.9785\n",
            "Epoch 728/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9886 - val_loss: 0.0644 - val_accuracy: 0.9811\n",
            "Epoch 729/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9891 - val_loss: 0.0641 - val_accuracy: 0.9798\n",
            "Epoch 730/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9891 - val_loss: 0.0641 - val_accuracy: 0.9798\n",
            "Epoch 731/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.0650 - val_accuracy: 0.9785\n",
            "Epoch 732/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9886 - val_loss: 0.0645 - val_accuracy: 0.9773\n",
            "Epoch 733/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9886 - val_loss: 0.0662 - val_accuracy: 0.9773\n",
            "Epoch 734/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.0642 - val_accuracy: 0.9798\n",
            "Epoch 735/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9882 - val_loss: 0.0643 - val_accuracy: 0.9798\n",
            "Epoch 736/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.0643 - val_accuracy: 0.9798\n",
            "Epoch 737/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9891 - val_loss: 0.0652 - val_accuracy: 0.9773\n",
            "Epoch 738/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9886 - val_loss: 0.0652 - val_accuracy: 0.9785\n",
            "Epoch 739/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9882 - val_loss: 0.0649 - val_accuracy: 0.9798\n",
            "Epoch 740/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9886 - val_loss: 0.0650 - val_accuracy: 0.9785\n",
            "Epoch 741/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9895 - val_loss: 0.0644 - val_accuracy: 0.9785\n",
            "Epoch 742/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9886 - val_loss: 0.0646 - val_accuracy: 0.9798\n",
            "Epoch 743/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9886 - val_loss: 0.0645 - val_accuracy: 0.9798\n",
            "Epoch 744/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9899 - val_loss: 0.0646 - val_accuracy: 0.9798\n",
            "Epoch 745/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 0.0646 - val_accuracy: 0.9811\n",
            "Epoch 746/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9882 - val_loss: 0.0640 - val_accuracy: 0.9811\n",
            "Epoch 747/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 0.0650 - val_accuracy: 0.9785\n",
            "Epoch 748/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9891 - val_loss: 0.0649 - val_accuracy: 0.9785\n",
            "Epoch 749/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 0.0645 - val_accuracy: 0.9785\n",
            "Epoch 750/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9882 - val_loss: 0.0645 - val_accuracy: 0.9798\n",
            "Epoch 751/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 0.0645 - val_accuracy: 0.9811\n",
            "Epoch 752/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.0654 - val_accuracy: 0.9785\n",
            "Epoch 753/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9886 - val_loss: 0.0648 - val_accuracy: 0.9798\n",
            "Epoch 754/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.0650 - val_accuracy: 0.9798\n",
            "Epoch 755/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9891 - val_loss: 0.0649 - val_accuracy: 0.9798\n",
            "Epoch 756/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9891 - val_loss: 0.0641 - val_accuracy: 0.9798\n",
            "Epoch 757/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 0.0649 - val_accuracy: 0.9798\n",
            "Epoch 758/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9891 - val_loss: 0.0654 - val_accuracy: 0.9811\n",
            "Epoch 759/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9891 - val_loss: 0.0688 - val_accuracy: 0.9747\n",
            "Epoch 760/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9886 - val_loss: 0.0663 - val_accuracy: 0.9773\n",
            "Epoch 761/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9886 - val_loss: 0.0653 - val_accuracy: 0.9798\n",
            "Epoch 762/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.0649 - val_accuracy: 0.9798\n",
            "Epoch 763/800\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9886 - val_loss: 0.0654 - val_accuracy: 0.9785\n",
            "Epoch 764/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.0658 - val_accuracy: 0.9785\n",
            "Epoch 765/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.0655 - val_accuracy: 0.9785\n",
            "Epoch 766/800\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.0656 - val_accuracy: 0.9785\n",
            "Epoch 767/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9878 - val_loss: 0.0659 - val_accuracy: 0.9798\n",
            "Epoch 768/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9886 - val_loss: 0.0655 - val_accuracy: 0.9798\n",
            "Epoch 769/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9891 - val_loss: 0.0653 - val_accuracy: 0.9811\n",
            "Epoch 770/800\n",
            "75/75 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 0.0665 - val_accuracy: 0.9785\n",
            "Epoch 771/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.0661 - val_accuracy: 0.9773\n",
            "Epoch 772/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.9891 - val_loss: 0.0659 - val_accuracy: 0.9773\n",
            "Epoch 773/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9878 - val_loss: 0.0659 - val_accuracy: 0.9798\n",
            "Epoch 774/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9886 - val_loss: 0.0657 - val_accuracy: 0.9798\n",
            "Epoch 775/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9891 - val_loss: 0.0658 - val_accuracy: 0.9811\n",
            "Epoch 776/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 0.0662 - val_accuracy: 0.9785\n",
            "Epoch 777/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 0.0663 - val_accuracy: 0.9798\n",
            "Epoch 778/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 0.0658 - val_accuracy: 0.9798\n",
            "Epoch 779/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 0.0661 - val_accuracy: 0.9811\n",
            "Epoch 780/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9886 - val_loss: 0.0665 - val_accuracy: 0.9785\n",
            "Epoch 781/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9891 - val_loss: 0.0662 - val_accuracy: 0.9798\n",
            "Epoch 782/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 0.0658 - val_accuracy: 0.9798\n",
            "Epoch 783/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 0.0661 - val_accuracy: 0.9798\n",
            "Epoch 784/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9891 - val_loss: 0.0665 - val_accuracy: 0.9785\n",
            "Epoch 785/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.0663 - val_accuracy: 0.9798\n",
            "Epoch 786/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9891 - val_loss: 0.0665 - val_accuracy: 0.9798\n",
            "Epoch 787/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.9891 - val_loss: 0.0657 - val_accuracy: 0.9811\n",
            "Epoch 788/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9886 - val_loss: 0.0659 - val_accuracy: 0.9811\n",
            "Epoch 789/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9886 - val_loss: 0.0656 - val_accuracy: 0.9798\n",
            "Epoch 790/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9886 - val_loss: 0.0658 - val_accuracy: 0.9798\n",
            "Epoch 791/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9886 - val_loss: 0.0672 - val_accuracy: 0.9773\n",
            "Epoch 792/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9886 - val_loss: 0.0670 - val_accuracy: 0.9773\n",
            "Epoch 793/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9874 - val_loss: 0.0667 - val_accuracy: 0.9811\n",
            "Epoch 794/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9891 - val_loss: 0.0666 - val_accuracy: 0.9798\n",
            "Epoch 795/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9886 - val_loss: 0.0665 - val_accuracy: 0.9811\n",
            "Epoch 796/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.0678 - val_accuracy: 0.9785\n",
            "Epoch 797/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9882 - val_loss: 0.0673 - val_accuracy: 0.9798\n",
            "Epoch 798/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.9882 - val_loss: 0.0670 - val_accuracy: 0.9811\n",
            "Epoch 799/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 0.0666 - val_accuracy: 0.9798\n",
            "Epoch 800/800\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9886 - val_loss: 0.0667 - val_accuracy: 0.9798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_supp3 = model_supp3.predict(X_test_norm)\n",
        "y_pred_class_nn_supp3 = (y_pred_prob_nn_supp3 > 0.5).astype('int32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah4xjATEU2ux",
        "outputId": "2fd174f3-5b30-4e81-ae92-464ed497cf3d"
      },
      "id": "Ah4xjATEU2ux",
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_supp3[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-9gNTlAVedv",
        "outputId": "6b406c49-b40a-4898-f995-25d1c0adaced"
      },
      "id": "p-9gNTlAVedv",
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_supp3[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMTuI6otVh21",
        "outputId": "afa55fff-edc5-4d3b-d625-9473c6bbd929"
      },
      "id": "qMTuI6otVh21",
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9999905e-01],\n",
              "       [9.9905705e-01],\n",
              "       [9.9691033e-01],\n",
              "       [9.9999899e-01],\n",
              "       [9.9986291e-01],\n",
              "       [9.9948049e-01],\n",
              "       [9.9999982e-01],\n",
              "       [9.9930364e-01],\n",
              "       [2.1352344e-03],\n",
              "       [3.7764621e-06]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_hist_supp3.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2qvdjebVjAH",
        "outputId": "48d9dee7-f081-4ec3-f2fd-9346ddc6f22a"
      },
      "id": "P2qvdjebVjAH",
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_supp3.history['loss'], 'r', label = 'Train loss')\n",
        "ax.plot(run_hist_supp3.history['val_loss'], 'b', label = \"Val loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "jAbkt2wDVkSx",
        "outputId": "17d86004-6e71-444a-c01e-d35a6426192d"
      },
      "id": "jAbkt2wDVkSx",
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7b29a2eee680>"
            ]
          },
          "metadata": {},
          "execution_count": 157
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve {} for Gender Classification in Byukilmaz'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ],
      "metadata": {
        "id": "cBx5vSBkVmUv"
      },
      "id": "cBx5vSBkVmUv",
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_supp3)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_supp3)))\n",
        "plot_roc(y_test, y_pred_prob_nn_supp3, \"NN Model 3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "p3_QMktDVnr6",
        "outputId": "91295747-3b4a-4cfc-9435-59964714374a"
      },
      "id": "p3_QMktDVnr6",
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.980\n",
            "roc-auc is 0.997\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This model achieved an accuracy of 98% and a ROC-AUC score of 0.997, showcasing the effectiveness and reliability of the trained neural network."
      ],
      "metadata": {
        "id": "OOgYQarIaOiS"
      },
      "id": "OOgYQarIaOiS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "#### Conclusion"
      ],
      "id": "intimate-factory"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "This activity demonstrates how does building and training the neural network underscore the importance of meticulous data preprocessing. And, Understanding the nature of the data, handling non-numeric values, and adapting code to different data structures in ensuring a smooth and error-free machine learning workflow.  "
      ],
      "id": "broad-appointment"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZnPGF_GT0Ns"
      },
      "source": [
        "#Google Colab link\n"
      ],
      "id": "MZnPGF_GT0Ns"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ajn1SGkUHr6"
      },
      "source": [
        "#Colab Link:\n",
        "https://colab.research.google.com/drive/1Sg9sGnBQyJAroSFE4ev3ObrURD91yTRZ?usp=sharing   \n"
      ],
      "id": "5Ajn1SGkUHr6"
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter-nbconvert --to html '/content/drive/MyDrive/Colab Notebooks/Hands-on Activity 1.2 - Training Neural Networks (Figueroa).ipynb'\n"
      ],
      "metadata": {
        "id": "KaaAwWYZR05t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf24a31-d061-4855-ea02-4c0e41b3a21b"
      },
      "id": "KaaAwWYZR05t",
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/drive/MyDrive/Colab Notebooks/Hands-on Activity 1.2 - Training Neural Networks (Figueroa).ipynb to html\n",
            "[NbConvertApp] Writing 2223980 bytes to /content/drive/MyDrive/Colab Notebooks/Hands-on Activity 1.2 - Training Neural Networks (Figueroa).html\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}